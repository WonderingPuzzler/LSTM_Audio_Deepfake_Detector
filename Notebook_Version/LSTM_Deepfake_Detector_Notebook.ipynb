{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIaiLYLwBGFM",
        "outputId": "41490acb-4c3e-455f-c162-93b03cd8e433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f0R2Jy8jBIGe"
      },
      "outputs": [],
      "source": [
        "# # Create a specific directory and EXTRACT LibreSevoc there\n",
        "# !mkdir -p LibriSeVoc_extracted\n",
        "# !unzip -o '/content/drive/My Drive/CYBR_4980_Project/Dataset/LibriSeVoc.zip' -d LibriSeVoc_extracted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laq1sVF7BRAF",
        "outputId": "4b62e8f9-bde8-42d5-c0a9-961a12d468fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.2/983.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hmlxtend version: 0.23.4\n",
            "0.23.4\n"
          ]
        }
      ],
      "source": [
        "# Import standard libraries\n",
        "import time\n",
        "import os\n",
        "import os.path\n",
        "from typing import Any, Callable, cast, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "# Import pickle for object serialization\n",
        "import pickle\n",
        "\n",
        "# Import standard data science libraries\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import PyTorch and related libraries\n",
        "import torch\n",
        "\n",
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "# Import mlxtend upgraded version\n",
        "import mlxtend\n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higherfrom torchmetrics import ConfusionMatrix\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, random_split, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Import imbalanced-learn for handling imbalanced datasets if we decide to use it\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Import scikit-learn for various utilities\n",
        "import sklearn.preprocessing as preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt # Import matplotlib for plotting\n",
        "import seaborn as sns # Import seaborn for enhanced visualizations\n",
        "\n",
        "# Import scalars\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "\n",
        "\n",
        "# Import audio processing libraries\n",
        "import scipy\n",
        "from scipy.optimize import brentq\n",
        "from scipy.interpolate import interp1d\n",
        "import scipy.io.wavfile as wavfile\n",
        "import scipy.signal\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "# Import collections for Counter\n",
        "from collections import Counter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "18IOyBprBVHd"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class ClassesFilesDictionarySetUp(Dataset):\n",
        "    \"\"\"\n",
        "    A class to set up and manage dataset properties such as device, directory, classes, class counts,\n",
        "    data length, transform flag, class indices, and file dictionary.\n",
        "    If the file we're working with is a .wav file, we use librosa to load it properly and create a 2d array (spectrogram).\n",
        "    Other file types are loaded as raw byte data (works well for 1d data).\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, directory: str = '', file_extension: str = '.wav', DL_type: str = 'RNN') -> None:\n",
        "        \"\"\"\n",
        "        Initialize the dataset setup with directory and file extension.\n",
        "        All other parameters use default values from private attributes.\n",
        "\n",
        "        Parameters:\n",
        "            directory (str): The directory path of the dataset. Defaults to an empty string.\n",
        "            file_extension (str): The file extension to filter files. Defaults to '.wav'.\n",
        "            DL_type (str): The type of deep learning model to use. Defaults to 'RNN'.\n",
        "            Will eventually fully support '1DCNN' and '2DCNN' as well.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__() # Initialize the parent Dataset class\n",
        "\n",
        "        # Initialize private attributes with default values\n",
        "        self.__device: torch.device = torch.device(\"cpu\")  # Default to CPU\n",
        "        self.__directory: str = 'None' # Default to 'None' indicating no directory set\n",
        "        self.__classes: List[str] = [] # List of class names\n",
        "        self.__classes_index: Dict[str, int] = {} # Mapping of class names to indices\n",
        "        self.__class_counts: Dict[str, int] = {} # Mapping of class names to their respective counts\n",
        "\n",
        "         # Mapping of class indices to lists of file paths\n",
        "         # Example: {0: ['path/to/class0/file1.wav', 'path/to/class0/file2.wav'], 1: ['path/to/class1/file1.wav']}\n",
        "        self.__file_dictionary = {}\n",
        "\n",
        "        self.__data_length: int = 1048576 # Fixed length for data samples (in bytes) for non-.wav files\n",
        "\n",
        "        self.__sample_rate: int = 44100 # The sample rate for audio files (basically a measure of quality in Hz)\n",
        "        self.__duration: int = 8 # Duration of audio clips in seconds\n",
        "        # self.__n_mels: int = 128 # Number of Mel bands to generate (used for 2DCNN spectrograms)\n",
        "        self.__n_mfcc: int = 40 # Number of MFCCs to generate (needed if we're dealing with MFCC features)\n",
        "        self.__n_fft: int = 2048 # Size of the FFT window\n",
        "        self.__hop_length: int = 512 # Number of samples between successive frames\n",
        "\n",
        "        self.__DL_type: str = 'RNN' # Type of deep learning model to use (RNN, 1DCNN, 2DCNN)\n",
        "\n",
        "        # Add StandardScaler for feature normalization\n",
        "        self.__scaler: Optional[StandardScaler | RobustScaler] = StandardScaler()  # Default to StandardScaler\n",
        "        self.__use_scaler: bool = True  # Flag to enable/disable scaling\n",
        "\n",
        "\n",
        "        # Choose device: prefer CUDA when available\n",
        "        # Perform setup actions (these methods set the private attributes internally)\n",
        "        self.setupDevice()\n",
        "\n",
        "        # Prefer provided directory when calling set_directory\n",
        "        if directory is not None and directory != '':\n",
        "            self.set_directory(directory)\n",
        "        else:\n",
        "            self.set_directory()\n",
        "\n",
        "        # Ensure classes and counts are initialized\n",
        "        self.set_classes()\n",
        "        self.set_class_counts()\n",
        "\n",
        "        # Initialize class index mapping and create classes and counts\n",
        "        self.create_classes_and_class_counts()\n",
        "\n",
        "        # Set up file dictionary by scanning the dataset directory\n",
        "        self.setup_file_dictionary(file_extension)\n",
        "\n",
        "        # Set the deep learning model type (RNN, 1DCNN, 2DCNN)\n",
        "        self.set_DL_type(DL_type)\n",
        "\n",
        "        # Use setters to ensure our private attributes are set correctly\n",
        "        self.set_data_length(self.__data_length)\n",
        "        self.set_sample_rate(self.__sample_rate)\n",
        "        self.set_duration(self.__duration)\n",
        "        self.set_n_mfcc(self.__n_mfcc)\n",
        "        self.set_n_fft(self.__n_fft)\n",
        "        self.set_hop_length(self.__hop_length)\n",
        "\n",
        "\n",
        "    def get_device(self) -> torch.device:\n",
        "        \"\"\"\n",
        "        Get the device used for PyTorch computations.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            torch.device: The device (CPU or GPU). If not set, defaults to CPU.\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure device is set and available\n",
        "        if not self.__device or not torch.cuda.is_available():\n",
        "            self.__device = torch.device(\"cpu\")\n",
        "\n",
        "        return self.__device\n",
        "\n",
        "    def set_device(self, device: torch.device) -> None:\n",
        "        \"\"\"\n",
        "        Set the device for PyTorch computations.\n",
        "\n",
        "        Parameters:\n",
        "            device (torch.device): The device to set (CPU or GPU). If None or CUDA not available, defaults to CPU.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure device is valid and available\n",
        "        if device == None or not torch.cuda.is_available():\n",
        "            self.__device = torch.device(\"cpu\")\n",
        "\n",
        "        self.__device = device\n",
        "\n",
        "    def get_directory(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the directory path of the dataset.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            str: The directory path. If empty, raises an error.\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure directory is set\n",
        "        if not self.__directory or not os.path.isdir(self.__directory):\n",
        "            raise ValueError(\"Directory is not set or does not exist.\")\n",
        "\n",
        "        return self.__directory\n",
        "\n",
        "    def set_directory(self, directory: str = '') -> None:\n",
        "        \"\"\"\n",
        "        Set the directory path of the dataset.\n",
        "\n",
        "        Parameters:\n",
        "            directory (str): The directory path to set. If empty, raises an error.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure directory is valid by checking if it exists and is a directory\n",
        "        if not directory or not os.path.isdir(directory):\n",
        "            raise ValueError(\"Provided directory is not valid or does not exist.\")\n",
        "\n",
        "        self.__directory = directory\n",
        "\n",
        "    def get_classes(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        Get the list of classes in the dataset. If empty, raises an error.\n",
        "        e.g.: ['class0', 'class1', 'class2']\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            List[str]: The list of class names.\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure classes at least has a default value\n",
        "        if not self.__classes:\n",
        "           raise ValueError(\"Classes list is empty.\")\n",
        "\n",
        "        return self.__classes\n",
        "\n",
        "    def set_classes(self, classes: List[str] = []) -> None:\n",
        "        \"\"\"\n",
        "        Set the list of classes in the dataset by scanning the directory structure.\n",
        "        e.g.: ['class0', 'class1', 'class2']\n",
        "\n",
        "        Parameters:\n",
        "            classes (List[str], optional): The list of class names to set. If empty, raises an error.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure classes is a list of strings\n",
        "        if classes is not None:\n",
        "            self.__classes = classes\n",
        "        elif not self.__classes:\n",
        "            raise ValueError(\"Classes list is empty.\")\n",
        "\n",
        "    def get_class_counts(self) -> Dict[str, int]:\n",
        "        \"\"\"\n",
        "        Get the counts of samples per class in the dataset.\n",
        "        eg.: {'class0': 100, 'class1': 150, 'class2': 200}\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, int]: A dictionary with class names as keys and their respective counts as values.\n",
        "            If empty, raises an error.\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure class counts at least has a default value\n",
        "        if not self.__class_counts:\n",
        "            raise ValueError(\"Class counts dictionary is empty.\")\n",
        "\n",
        "        return self.__class_counts\n",
        "\n",
        "    def set_class_counts(self, class_counts: Dict[str, int] = {}) -> None:\n",
        "        \"\"\"\n",
        "        Set the counts of samples per class in the dataset by scanning the directory structure.\n",
        "        eg.: {'class0': 100, 'class1': 150, 'class2': 200}\n",
        "\n",
        "        Parameters:\n",
        "            class_counts (Dict[str, int], optional): A dictionary with class names as keys and their respective counts as values.\n",
        "            If empty, raises an error.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure class counts is a dictionary with a tuple of (string, integer)\n",
        "        if class_counts is not None:\n",
        "            self.__class_counts = class_counts\n",
        "        elif not self.__class_counts:\n",
        "            raise ValueError(\"Class counts dictionary is empty.\")\n",
        "\n",
        "    def get_data_length(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the fixed length for data samples.\n",
        "        e.g.: 1048576 (in bytes)\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "        Returns:\n",
        "            int: The fixed length for data samples.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__data_length\n",
        "\n",
        "    def set_data_length(self, data_length: int) -> None:\n",
        "        \"\"\"\n",
        "        Set the fixed length for data samples.\n",
        "        e.g.: 1048576 (in bytes)\n",
        "\n",
        "        Parameters:\n",
        "            data_length (int): The fixed length to set for data samples.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # If data_length is positive, set it; otherwise, raise an error\n",
        "        if data_length > 0:\n",
        "            self.__data_length = data_length\n",
        "        else:\n",
        "            raise ValueError(\"Data length must be a positive integer.\")\n",
        "\n",
        "    def get_classes_index(self) -> Dict[str, int]:\n",
        "        \"\"\"\n",
        "        Get the mapping of class names to their respective indices.\n",
        "        e.g.: {'class0': 0, 'class1': 1, 'class2': 2}\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, int]: A dictionary mapping class names to their respective indices.\n",
        "            If empty, raises an error.\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure classes index at least is a dictionary with a tuple of (string, integer)\n",
        "        if not self.__classes_index:\n",
        "            raise ValueError(\"Classes index dictionary is empty.\")\n",
        "\n",
        "        return self.__classes_index\n",
        "\n",
        "    def set_classes_index(self, classes_index: Dict[str, int] = {}) -> None:\n",
        "        \"\"\"\n",
        "        Set the mapping of class names to their respective indices.\n",
        "        e.g.: {'class0': 0, 'class1': 1, 'class2': 2}\n",
        "\n",
        "        Parameters:\n",
        "            classes_index (Dict[str, int], optional): A dictionary mapping class names to their respective indices.\n",
        "            If empty, raises an error.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure classes index is at least a dictionary with a tuple of (string, integer)\n",
        "        if classes_index is not None:\n",
        "            self.__classes_index = classes_index\n",
        "        elif not self.__classes_index:\n",
        "            raise ValueError(\"Classes index dictionary is empty.\")\n",
        "\n",
        "\n",
        "    def get_file_dictionary(self) -> Dict[int, List[str]]:\n",
        "        \"\"\"\n",
        "        Get the dictionary of file paths along with their corresponding class indices.\n",
        "        e.g.: {0: ['file1.wav', 'file2.wav'], 1: ['file3.wav', 'file4.wav']}\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            Dict[int, List[str]]: A dictionary mapping class indices to lists of file paths.\n",
        "            If empty, raises an error.\n",
        "        \"\"\"\n",
        "\n",
        "        # Return the file dictionary mapping class_index -> list[str].\n",
        "        # If empty, raise an error.\n",
        "        if not self.__file_dictionary:\n",
        "            raise ValueError(\"File dictionary is empty.\")\n",
        "        else:\n",
        "            return self.__file_dictionary\n",
        "\n",
        "    def set_file_dictionary(self, file_dictionary: Dict[int, List[str]]) -> None:\n",
        "        \"\"\"\n",
        "        Set the dictionary of file paths along with their corresponding class indices.\n",
        "        e.g.: {0: ['file1.wav', 'file2.wav'], 1: ['file3.wav', 'file4.wav']}\n",
        "\n",
        "        Parameters:\n",
        "            file_dictionary (Dict[int, List[str]]): A dictionary mapping class indices to lists of file paths.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Accept a dictionary mapping class_index -> list[str]\n",
        "        if file_dictionary is not None and isinstance(file_dictionary, dict):\n",
        "            self.__file_dictionary = file_dictionary\n",
        "        else:\n",
        "            raise ValueError(\"File dictionary cannot be None.\")\n",
        "\n",
        "    def get_sample_rate(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the sample rate for audio files.\n",
        "        e.g.: 44100 Hz\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            int: The sample rate in Hz.\n",
        "        \"\"\"\n",
        "        return self.__sample_rate\n",
        "\n",
        "    def set_sample_rate(self, sample_rate: int) -> None:\n",
        "        \"\"\"\n",
        "        Set the sample rate for audio files.\n",
        "        e.g.: 44100 Hz\n",
        "\n",
        "        Parameters:\n",
        "            sample_rate (int): The sample rate in Hz.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # If sample_rate is positive and reasonable, set it.\n",
        "        if sample_rate > 10000 and isinstance(sample_rate, int):\n",
        "            self.__sample_rate = sample_rate\n",
        "\n",
        "        # Otherwise, raise an error\n",
        "        else:\n",
        "            raise ValueError(\"Sample rate must be a positive integer and of a reasonable value above 10000 Hz.\")\n",
        "\n",
        "    def get_duration(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the duration of audio clips.\n",
        "        e.g.: 8 seconds\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            int: The duration in seconds.\n",
        "        \"\"\"\n",
        "        return self.__duration\n",
        "\n",
        "    def set_duration(self, duration: int) -> None:\n",
        "        \"\"\"\n",
        "        Set the duration of audio clips.\n",
        "        e.g.: 8 seconds\n",
        "\n",
        "        Parameters:\n",
        "            duration (int): The duration in seconds.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        if duration > 0 or isinstance(duration, int):\n",
        "            self.__duration = duration\n",
        "        else:\n",
        "            raise ValueError(\"Duration must be a positive integer and not a float.\")\n",
        "\n",
        "    def get_n_mfcc(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the number of MFCCs to generate.\n",
        "        e.g.: 40 MFCCs\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            int: The number of MFCCs.\n",
        "        \"\"\"\n",
        "        return self.__n_mfcc\n",
        "\n",
        "    def set_n_mfcc(self, n_mfcc: int) -> None:\n",
        "        \"\"\"\n",
        "        Set the number of MFCCs to generate.\n",
        "        e.g.: 40 MFCCs\n",
        "\n",
        "        Parameters:\n",
        "            n_mfcc (int): The number of MFCCs.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure n_mfcc is a positive integer between 1 and 40\n",
        "        if 40 >= n_mfcc > 0 and isinstance(n_mfcc, int):\n",
        "            self.__n_mfcc = n_mfcc\n",
        "        else:\n",
        "            raise ValueError(\"Number of MFCCs must be a positive integer between 1 and 40 and not a float.\")\n",
        "\n",
        "    # TODO: Implement 2DCNN get and set for n_mels\n",
        "\n",
        "    def get_n_fft(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the size of the FFT window.\n",
        "        The FFT (Fast Fourier Transform) window size determines the number of samples/points\n",
        "        in the window.\n",
        "        e.g.: 2048 samples/points\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            int: The size of the FFT window.\n",
        "        \"\"\"\n",
        "        return self.__n_fft\n",
        "\n",
        "    def set_n_fft(self, n_fft: int) -> None:\n",
        "        \"\"\"\n",
        "        Set the size of the FFT window.\n",
        "        The FFT (Fast Fourier Transform) window size determines the number of samples/points\n",
        "        in the window.\n",
        "        e.g.: 2048 samples/points\n",
        "\n",
        "        Parameters:\n",
        "            n_fft (int): The size of the FFT window.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure n_fft is a positive integer\n",
        "        if n_fft > 0 and isinstance(n_fft, int):\n",
        "            self.__n_fft = n_fft\n",
        "        else:\n",
        "            raise ValueError(\"Size of FFT window must be a positive integer and not a float.\")\n",
        "\n",
        "    def get_hop_length(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the number of samples between successive frames.\n",
        "        The hop length determines how much the window shifts between successive frames.\n",
        "        By window, we mean the segment of audio data being analyzed at a time.\n",
        "        e.g.: 512 samples\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            int: The hop length.\n",
        "        \"\"\"\n",
        "        return self.__hop_length\n",
        "\n",
        "    def set_hop_length(self, hop_length: int) -> None:\n",
        "        \"\"\"\n",
        "        Set the number of samples between successive frames.\n",
        "        The hop length determines how much the window shifts between successive frames.\n",
        "        By window, we mean the segment of audio data being analyzed at a time.\n",
        "        e.g.: 512 samples\n",
        "\n",
        "        Parameters:\n",
        "            hop_length (int): The hop length.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure hop_length is a positive integer\n",
        "        if hop_length > 0 and isinstance(hop_length, int):\n",
        "            self.__hop_length = hop_length\n",
        "        else:\n",
        "            raise ValueError(\"Hop length must be a positive integer and not a float.\")\n",
        "\n",
        "    def get_DL_type(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the type of deep learning model to use.\n",
        "        e.g.: 'RNN', '1DCNN', '2DCNN'\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            str: The deep learning model type.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__DL_type\n",
        "\n",
        "    def set_DL_type(self, DL_type: str) -> None:\n",
        "        \"\"\"\n",
        "        Set the type of deep learning model to use.\n",
        "        e.g.: 'RNN', '1DCNN', '2DCNN'\n",
        "\n",
        "        Parameters:\n",
        "            DL_type (str): The deep learning model type.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure DL_type is one of the supported types\n",
        "        if DL_type in ['RNN', '1DCNN', '2DCNN']:\n",
        "            self.__DL_type = DL_type\n",
        "        else:\n",
        "            raise ValueError(\"Deep learning model type must be one of: 'RNN', '1DCNN', '2DCNN'.\")\n",
        "\n",
        "    def get_scaler(self) -> StandardScaler | RobustScaler:\n",
        "        \"\"\"\n",
        "        Get the Scaler used for feature normalization.\n",
        "        The Scaler is used to normalize the features in the dataset.\n",
        "        e.g.: StandardScaler() or RobustScaler()\n",
        "        StandardScaler is used when the dataset does not contain or contains few outliers.\n",
        "        RobustScaler can be used when the dataset contains outliers.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            Optional[StandardScaler | RobustScaler]: The fitted StandardScaler or RobustScaler.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.__scaler is None:\n",
        "            raise ValueError(\"Scaler has not been set.\")\n",
        "\n",
        "        return self.__scaler\n",
        "\n",
        "    def set_scaler(self, scaler: StandardScaler | RobustScaler) -> None:\n",
        "        \"\"\"\n",
        "        Set the Scaler used for feature normalization.\n",
        "        The Scaler is used to normalize the features in the dataset.\n",
        "        e.g.: StandardScaler() or RobustScaler()\n",
        "        StandardScaler is used when the dataset does not contain or contains few outliers.\n",
        "        RobustScaler can be used when the dataset contains outliers.\n",
        "\n",
        "\n",
        "        Parameters:\n",
        "            scaler (StandardScaler | RobustScaler): The fitted StandardScaler or RobustScaler to set.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure scalar is either StandardScaler or RobustScaler\n",
        "        if not isinstance(scaler, (StandardScaler, RobustScaler)):\n",
        "            raise ValueError(\"Scaler must be an instance of StandardScaler or RobustScaler.\")\n",
        "\n",
        "        self.__scaler = scaler\n",
        "\n",
        "    def get_use_scaler(self) -> bool:\n",
        "        \"\"\"\n",
        "        Get whether to use Scaler for feature normalization.\n",
        "        e.g.: True or False\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            bool: Whether to use scaling.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__use_scaler\n",
        "\n",
        "    def set_use_scaler(self, use_scaler: bool) -> None:\n",
        "        \"\"\"\n",
        "        Set whether to use Scaler for feature normalization.\n",
        "        e.g.: True or False\n",
        "\n",
        "        Parameters:\n",
        "            use_scaler (bool): Whether to use scaling.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure use_scaler is a boolean\n",
        "        if not isinstance(use_scaler, bool):\n",
        "            raise ValueError(\"use_scaler must be a boolean value (True or False).\")\n",
        "\n",
        "        self.__use_scaler = use_scaler\n",
        "\n",
        "\n",
        "    def setupDevice(self) -> None:\n",
        "        \"\"\"\n",
        "        Setup device for PyTorch computations by checking for CUDA availability.\n",
        "        If CUDA is available, it sets the device to GPU; otherwise, it defaults to CPU.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\" =============================== Device Setup =============================== \\n\")\n",
        "\n",
        "        self.set_device(torch.device(\"cuda\")) # Try to set to CUDA\n",
        "        print(f\"Using device: {self.get_device()}\") # Print the device being used\n",
        "\n",
        "        # Check if CUDA is available and print relevant information (get_device will automatically default to CPU if not)\n",
        "        if self.get_device().type == \"cuda\":\n",
        "\n",
        "            try:\n",
        "                # Print basic GPU info\n",
        "                print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "                print(\"CUDA available:\", torch.cuda.is_available())\n",
        "            except Exception:\n",
        "                print(\"Error accessing CUDA device information.\")\n",
        "\n",
        "        # Otherwise, default to CPU\n",
        "        else:\n",
        "            print(\"CUDA not available, using CPU.\")\n",
        "        print (\"\\n ----------------------------- Setup Complete ------------------------------ \\n\")\n",
        "\n",
        "\n",
        "    def create_classes_and_class_counts(self) -> None:\n",
        "        \"\"\"\n",
        "        This function sets up the logic needed to not only find the classes in the dataset directory\n",
        "        and find their counts, but also to create a mapping from class names to indices.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\" \\n=============================== Creating Classes, Class Counts, and Class Indices =============================== \\n\")\n",
        "\n",
        "        # Go through the dataset directory, finding the name of each file within the directory, and ensure it is a directory\n",
        "        # If it is, add it to the classes list\n",
        "        classes: List[str] = sorted([d for d in os.listdir(self.get_directory()) if os.path.isdir(os.path.join(self.get_directory(), d))])\n",
        "\n",
        "        # Set the classes found and print them\n",
        "        self.set_classes(classes)\n",
        "        print (\" Classes found: \", list(self.get_classes()))\n",
        "\n",
        "        # Now, create the class counts and class indices\n",
        "        class_counts: Dict[str, int] = {}\n",
        "        classes_index: Dict[str, int] = {}\n",
        "\n",
        "        # For each class found, count the number of files in its directory and assign an index\n",
        "        for index, class_name in enumerate(self.get_classes()):\n",
        "\n",
        "            # Get the directory path for the current class by joining the base directory with the class name\n",
        "            class_dir: str = os.path.join(self.get_directory(), class_name)\n",
        "\n",
        "            # The class count is simply the number of files in that directory,\n",
        "            # which can be found by getting a length of the list of files in a directory\n",
        "            class_counts[class_name] = len(os.listdir(class_dir))\n",
        "\n",
        "            # The index is simply the enumeration order (0, 1, 2, ...)\n",
        "            # Basically we're saying: key: class_name -> value: index\n",
        "            classes_index[class_name] = index\n",
        "\n",
        "        # Store the class counts and indices and print them\n",
        "        self.set_class_counts(class_counts)\n",
        "        self.set_classes_index(classes_index)\n",
        "        print (\" Class counts: \", self.get_class_counts())\n",
        "        print (\" Class indices: \", self.get_classes_index())\n",
        "\n",
        "        print (\" \\n----------------------------- Creation of Classes, Class Counts, and Class Indices Complete ------------------------------ \\n\")\n",
        "\n",
        "\n",
        "    def setup_file_dictionary(self, file_type) -> None:\n",
        "        \"\"\"\n",
        "        This function sets up the file lists by scanning the dataset directory\n",
        "        and pairing each file path with its corresponding class index.\n",
        "        Basically, it creates a dictionary mapping (int) class index -> ([str]) list of file paths for that class.\n",
        "\n",
        "        Parameters:\n",
        "            file_type (str): The file extension to filter files (e.g., '.wav').\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\" \\n=============================== Setting up File Dictionary =============================== \\n\")\n",
        "\n",
        "        # Placeholder to build the file dictionary\n",
        "        file_dict: Dict[int, List[str]] = {}\n",
        "\n",
        "        # Placeholder for class directory path\n",
        "        class_dir: str = ''\n",
        "\n",
        "        # Placeholder to store filenames temporarily\n",
        "        files: List[str] = []\n",
        "\n",
        "        # Placeholder to store full file paths\n",
        "        full_paths: List[str] = []\n",
        "\n",
        "        # Placeholder for class index\n",
        "        class_index: int = 0\n",
        "\n",
        "        # Build a mapping from class index -> list of full file paths for that class\n",
        "        for class_name in self.get_classes():\n",
        "\n",
        "            # Get the directory path for the current class by joining the base directory with the class name\n",
        "            class_dir: str = os.path.join(self.get_directory(), class_name)\n",
        "\n",
        "            # Get all files with the correct extension first\n",
        "            all_files = [f for f in os.listdir(class_dir) if f.endswith(file_type)]\n",
        "\n",
        "            if class_name != 'gt':\n",
        "                # Randomly sample up to 475 files from this class\n",
        "                max_samples = min(475, len(all_files))\n",
        "                sampled_files = random.sample(all_files, max_samples)\n",
        "            else:\n",
        "                # Randomly sample up to 700 files from this class\n",
        "                max_samples = min(700, len(all_files))\n",
        "                sampled_files = random.sample(all_files, max_samples)\n",
        "\n",
        "            # Sort the sampled files\n",
        "            files: List[str] = sorted(sampled_files)\n",
        "\n",
        "            # Get the full paths by joining the class directory with each filename (needed if we want to load the actual data later)\n",
        "            full_paths: List[str] = [os.path.join(class_dir, f) for f in files]\n",
        "\n",
        "            # Get the class index from the class name using the previously created mapping\n",
        "            class_index_temp: int | None = self.get_classes_index().get(class_name)\n",
        "\n",
        "            # Safety check in case class name not found in index mapping\n",
        "            if class_index_temp is None:\n",
        "                raise ValueError(f\"Class index for class '{class_name}' not found.\")\n",
        "            else:\n",
        "                class_index = class_index_temp\n",
        "\n",
        "            # Store the list of full paths under the class index\n",
        "            file_dict[class_index] = full_paths\n",
        "\n",
        "            # Print files for this class immediately with only basenames for readability\n",
        "            basenames: List[str] = [os.path.basename(p) for p in full_paths]\n",
        "            print(f\"\\n Class {class_name}: Files: {basenames}\\n\\n\")\n",
        "\n",
        "        # Store the dictionary\n",
        "        self.set_file_dictionary(file_dict)\n",
        "\n",
        "        # Update class counts to reflect actual sampled files\n",
        "        updated_class_counts: Dict[str, int] = {}\n",
        "\n",
        "        for class_name in self.get_classes():\n",
        "            class_index = self.get_classes_index()[class_name]\n",
        "            updated_class_counts[class_name] = len(file_dict[class_index])\n",
        "        self.set_class_counts(updated_class_counts)\n",
        "\n",
        "        # Print total number of files found\n",
        "        total_files: int = sum(len(v) for v in file_dict.values())\n",
        "        print(f\" Total files found: {total_files} \")\n",
        "        print(f\" Updated class counts: {self.get_class_counts()} \")\n",
        "        print (\" \\n----------------------------- File Dictionary Setup Complete ------------------------------ \\n\")\n",
        "\n",
        "\n",
        "    def setup_data(self, class_index: int, file_index_within_class: int) -> Tuple[torch.Tensor | np.ndarray, int]:\n",
        "        \"\"\"\n",
        "        This function will get a specific file in a class based on the provided class index and file index within that class,\n",
        "        process data from it, and return the data along with its class index.\n",
        "\n",
        "        Parameters:\n",
        "            class_index (int): The index of the class.\n",
        "            file_index_within_class (int): The index of the file within the specified class.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor | bytes | np.ndarray, int]: A tuple containing the processed data and its corresponding class index.\n",
        "\n",
        "            The exact format depends on DL_type:\n",
        "\n",
        "            - RNN mode (DL_type='RNN' and file_type = '.wav'):\n",
        "              Returns (torch.Tensor, int) where:\n",
        "                - Tensor shape: (time_steps, n_mfcc)\n",
        "                - time_steps = (sample_rate * duration) // hop_length + 1\n",
        "                - Features are MFCC coefficients extracted via librosa\n",
        "                - n_mfcc is the number of MFCCs, where MFCCs are Mel-Frequency Cepstral Coefficients\n",
        "                - Mel-Frequency Cepstral Coefficients (MFCCs) are a compact representation of the spectral\n",
        "                  envelope of audio signals. They capture high-frequency characteristics while being robust\n",
        "                  to pitch variations, making them effective features for distinguishing audio patterns.\n",
        "                - Audio is loaded with fixed duration and padded/truncated to exact length\n",
        "\n",
        "            TODO:\n",
        "            - 2DCNN mode (DL_type='2DCNN' and file_type = '.wav'):\n",
        "              Returns (torch.Tensor, int) where:\n",
        "                - Tensor shape: (1, n_mels, time_steps)\n",
        "                - First dimension is channel (1 for grayscale spectrogram)\n",
        "                - n_mels is the number of mel frequency bins\n",
        "                - time_steps = (sample_rate * duration) // hop_length + 1\n",
        "                - Data is mel-spectrogram in dB scale\n",
        "                - Audio is loaded with fixed duration and padded/truncated to exact length\n",
        "\n",
        "            - 1DCNN mode (DL_type='1DCNN' and file_type != '.wav'):\n",
        "              Returns (np.ndarray, int) where:\n",
        "                - Array contains raw byte data from non-.wav files\n",
        "                - Length is data_length bytes, zero-padded if file is shorter\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        signal: np.ndarray # The audio signal\n",
        "        sr: int | float # The sample rate\n",
        "\n",
        "        # Retrieve the dictionary of files\n",
        "        file_dict: Dict[int, List[str]] = self.get_file_dictionary()\n",
        "\n",
        "        # Validate class index\n",
        "        if class_index not in file_dict:\n",
        "            raise IndexError(f\"Class index {class_index} not found in file dictionary.\")\n",
        "\n",
        "        # Validate file index within the class\n",
        "        class_files: List[str] = file_dict[class_index]\n",
        "        if file_index_within_class < 0 or file_index_within_class >= len(class_files):\n",
        "            raise IndexError(f\"File index {file_index_within_class} out of range for class index {class_index}.\")\n",
        "\n",
        "        # Get the file path\n",
        "        file_path: str = class_files[file_index_within_class]\n",
        "\n",
        "        # If the file is a .wav file, use librosa to load it properly\n",
        "        if os.path.splitext(file_path)[1] == '.wav' and self.get_DL_type() in ['RNN']:\n",
        "\n",
        "            # Use librosa to load the audio file\n",
        "            try:\n",
        "                signal: np.ndarray\n",
        "                sr: int | float\n",
        "\n",
        "                signal, sr = librosa.load(file_path, sr=self.get_sample_rate(), duration=self.get_duration())\n",
        "\n",
        "            # Catch errors during audio loading\n",
        "            except Exception as e:\n",
        "\n",
        "                print(f\"\\nWarning: Failed to load audio file: {file_path}\")\n",
        "                print(f\"Error: {e}\")\n",
        "                print(\"Returning zeros as fallback.\\n\")\n",
        "\n",
        "                # Return zeros with expected shape as fallback\n",
        "                signal: np.ndarray = np.zeros(self.get_sample_rate() * self.get_duration())\n",
        "\n",
        "                # Get the sample rate for consistency\n",
        "                sr: int | float = self.get_sample_rate()\n",
        "\n",
        "            # Ensure signal has fixed length\n",
        "            target_length: int = self.get_sample_rate() * self.get_duration()\n",
        "\n",
        "            # Pad the signal to the target length\n",
        "            if len(signal) < target_length:\n",
        "                signal: np.ndarray = np.pad(signal, (0, target_length - len(signal)), mode='constant')\n",
        "\n",
        "            # Truncate the signal if it's longer than target length\n",
        "            else:\n",
        "                signal: np.ndarray = signal[:target_length]\n",
        "\n",
        "            # Extract MFCC features (output shape: (n_mfcc/features, time_steps))\n",
        "            mfccs: np.ndarray = librosa.feature.mfcc(\n",
        "                y=signal,\n",
        "                sr=sr,\n",
        "                n_mfcc=self.get_n_mfcc(),\n",
        "                n_fft=self.get_n_fft(),\n",
        "                hop_length=self.get_hop_length())\n",
        "\n",
        "            # Transpose to (time_steps, features) for RNN (RNNs expect time dimension first)\n",
        "            mfccs = mfccs.T\n",
        "\n",
        "            # Convert to tensor\n",
        "            data: torch.Tensor | bytes | np.ndarray = torch.tensor(mfccs, dtype=torch.float32)\n",
        "\n",
        "            # Apply scaling if scaler is fitted and enabled\n",
        "            if self.get_use_scaler() is True and self.get_scaler() is not None:\n",
        "                # Data is already in (time_steps, n_mfcc) format for RNN\n",
        "                data_np = data.numpy()\n",
        "                scaler = self.get_scaler()\n",
        "\n",
        "                if scaler is not None:  # Additional safety check for type checker\n",
        "                    data_scaled = scaler.transform(data_np)\n",
        "                    data = torch.tensor(data_scaled, dtype=torch.float32)\n",
        "\n",
        "        # TODO: If the file is a .wav file and we're using 2DCNN, process accordingly\n",
        "        elif os.path.splitext(file_path)[1] == '.wav' and self.get_DL_type() in ['2DCNN']:\n",
        "            data = torch.tensor([])  # Placeholder for 2DCNN processing\n",
        "\n",
        "        # If the file is not a .wav file and we're using 1DCNN, read raw bytes\n",
        "        elif os.path.splitext(file_path)[1] != '.wav' and self.get_DL_type() in ['1DCNN']:\n",
        "\n",
        "            # Load the data from the file\n",
        "            with open(file_path, 'rb') as f:\n",
        "                # Read the specified number of bytes\n",
        "                data = f.read(self.get_data_length())\n",
        "                data = np.pad(data, (0, self.get_data_length() - len(data)), 'constant')  # Pad with zeros if needed\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file type or DL_type for file: {file_path}\")\n",
        "\n",
        "\n",
        "        return data, class_index\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, int]:\n",
        "        \"\"\"\n",
        "        Uses setup_data function to retrieve a sample based on a flat index.\n",
        "        Cumulative count works as a running tally! If we have 3 classes with 5, 10, and 15 samples respectively,\n",
        "        and we look for index 12, we see that:\n",
        "        - Class 0 (5 samples): cumulative count is 5, index 12 is greater than 5, move to next class\n",
        "        - Class 1 (10 samples): cumulative count is 15, index 12 is less than 15, so it belongs to class 1\n",
        "        - File index within class 1 is 12 - 5 = 7\n",
        "        - Call setup_data with class_index=1 and file_index_within_class=7\n",
        "\n",
        "        We know we'll get a valid flat index because PyTorch's DataLoader, train_test_split (stratified splitting),\n",
        "        and our fit_scaler_on_training_data all use __len__(self) to determine valid index ranges (0 to len(self)-1),\n",
        "        and len(self) returns the sum of all class counts, ensuring indices are within bounds.\n",
        "        Therefore, we'll NEVER get the indices based on one class only - we always consider the entire dataset!\n",
        "\n",
        "        For example, train_test_split gives us stratified indices like [0, 2048, 7, 591, 20, ...] which span across classes\n",
        "        while maintaining proportional class distribution in train/validation/test splits.\n",
        "\n",
        "        Parameters:\n",
        "            index (int): The flat index of the sample.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[Any, int]: A tuple containing the data and its corresponding class index.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Placeholder for cumulative count of samples\n",
        "        cumulative_count = 0\n",
        "\n",
        "        # Iterate through classes to find the correct class for the given index\n",
        "        for class_name in self.get_classes():\n",
        "\n",
        "            # Get the count of samples in this class\n",
        "            count = self.get_class_counts()[class_name]\n",
        "\n",
        "            # Check if the index falls within this class's range (cumulative_count maintains the running total of samples)\n",
        "            if index < cumulative_count + count:\n",
        "\n",
        "                # Found the correct class\n",
        "                class_index = self.get_classes_index()[class_name]\n",
        "                file_index_within_class = index - cumulative_count # Calculate the file index within the class by subtracting cumulative count\n",
        "\n",
        "                return self.setup_data(class_index, file_index_within_class) # Retrieve the item using setup_data\n",
        "\n",
        "            # Update cumulative count for the next iteration\n",
        "            cumulative_count += count\n",
        "\n",
        "        # If we reach here, index is out of bounds\n",
        "        raise IndexError(f\"Index {index} out of range for dataset of size {cumulative_count}\")\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the total number of samples in the dataset.\n",
        "        If we have 3 classes with counts 100, 150, and 200, the total length is 450.\n",
        "        (Note: If we choose a subsample of files per class during setup, like we did in setup_file_dictionary(), this should reflect that total subsample count.)\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            int: The total number of samples across all classes.\n",
        "        \"\"\"\n",
        "\n",
        "        total_samples: int = 0\n",
        "\n",
        "        # Sum the counts of all classes to get the total number of samples\n",
        "        for count in self.get_class_counts().values():\n",
        "            total_samples += count\n",
        "\n",
        "        return total_samples\n",
        "\n",
        "    def fit_scaler_on_training_data(self, train_indices) -> None:\n",
        "        \"\"\"\n",
        "        Fit the StandardScaler on training data features using optimized sampling.\n",
        "        Uses time-step reduction for fast fitting.\n",
        "\n",
        "        Parameters:\n",
        "            train_indices: Indices of training samples to fit scaler on.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # If scaling is not enabled, skip fitting\n",
        "        if not self.get_use_scaler():\n",
        "            return\n",
        "\n",
        "\n",
        "        print( \"\\n=============================== Fitting StandardScaler on Training Data ===============================\\n\")\n",
        "\n",
        "        # Limit to a maximum of 100 samples for fitting\n",
        "        max_samples = min(100, len(train_indices))\n",
        "\n",
        "        # Calculate step size for sampling\n",
        "        sample_step = max(1, len(train_indices) // max_samples)\n",
        "\n",
        "        # Sample indices with step size (max samples serves as an upper limit)\n",
        "        sample_indices = train_indices[::sample_step][:max_samples]\n",
        "\n",
        "        print(f\"Using {len(sample_indices)} samples (out of {len(train_indices)}) for scaler fitting\")\n",
        "\n",
        "        training_features = []\n",
        "\n",
        "        # Disable scaling temporarily during feature extraction\n",
        "        # (we want raw features for fitting and if we don't disable, the scaler will try to scale data that hasn't been fitted yet...)\n",
        "        self.set_use_scaler(False)\n",
        "\n",
        "        # For each sampled index, extract features and subsample time steps\n",
        "        for idx in sample_indices:\n",
        "\n",
        "            try:\n",
        "                # Get raw data (scaling disabled)\n",
        "                # For RNN: data comes as (time_steps, features) - already in StandardScaler format\n",
        "                data, _ = self.__getitem__(idx)\n",
        "\n",
        "                # Convert to numpy array if it's a tensor (if we're dealing with RNN or 2DCNN, it should be)\n",
        "                if isinstance(data, torch.Tensor):\n",
        "                    data = data.numpy()\n",
        "\n",
        "                # Handle different data shapes\n",
        "                if self.get_DL_type() == 'RNN':\n",
        "                    # data shape: (time_steps, features)\n",
        "                    # Subsample every 7th time step to reduce data volume\n",
        "                    training_features.append(data[::7])\n",
        "\n",
        "                elif self.get_DL_type() == '2DCNN':\n",
        "                    continue  # 2DCNN - spectrograms, skip scaling for now\n",
        "\n",
        "                else:  # 1DCNN - raw bytes, no scaling needed\n",
        "                    continue\n",
        "\n",
        "            # Catch any exceptions during feature extraction\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not process sample {idx} for scaler fitting: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Re-enable scaling after feature extraction\n",
        "        self.set_use_scaler(True)\n",
        "\n",
        "        # Fit StandardScaler if we have valid features\n",
        "        if training_features:\n",
        "\n",
        "            # Concatenate all features into a single array\n",
        "            # np.concatenate stacks arrays along the first axis (rows)\n",
        "            all_features: np.ndarray = np.concatenate(training_features, axis=0)\n",
        "\n",
        "            print(f\"Fitting scaler on {all_features.shape[0]} feature vectors (shape: {all_features.shape})\")\n",
        "\n",
        "            # Create a fresh Scaler instance and fit on all collected features at once\n",
        "            if isinstance(self.get_scaler(), RobustScaler):\n",
        "                scaler: StandardScaler | RobustScaler = RobustScaler() # Use RobustScaler if previously set\n",
        "\n",
        "            elif isinstance(self.get_scaler(), StandardScaler):\n",
        "                scaler: StandardScaler | RobustScaler = StandardScaler() # Use StandardScaler if previously set\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"Scaler must be set to either StandardScaler or RobustScaler before fitting.\")\n",
        "\n",
        "            scaler.fit(all_features)  # Fit on all collected feature vectors\n",
        "            self.set_scaler(scaler)  # Store the newly fitted scaler\n",
        "\n",
        "            print(f\"StandardScaler fitted on {len(training_features)} training samples\")\n",
        "\n",
        "        # Error out if no valid features found\n",
        "        else:\n",
        "            print(\"Warning: No valid training features found for scaler fitting (disregard warning if using 1DCNN with raw byte data).\")\n",
        "            self.set_use_scaler(False)\n",
        "\n",
        "        print ( \"\\n----------------------------- StandardScaler Fitting Complete ------------------------------\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JMa9ztzIBZcx"
      },
      "outputs": [],
      "source": [
        "class BatchLossAndOptimization(ClassesFilesDictionarySetUp, nn.Module):\n",
        "    \"\"\"\n",
        "    A class to manage batch size, learning rate, and data splitting for training, validation, and testing sets,\n",
        "    as well as set up Loss and Optimization for a DeepFake Detector.\n",
        "    Inherits from ClassesFilesDictionarySetUp and nn.Module.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, directory: str = '', optim: str = 'Adam', loss: str = 'CrossEntropyLoss', file_extension: str = '.wav', DL_type: str = 'RNN') -> None:\n",
        "        \"\"\"\n",
        "        Desc:\n",
        "            Initialize the BatchLossAndOptimization class, including the class variables.\n",
        "            Also, sets up the loss function and optimizer.\n",
        "\n",
        "        Parameters:\n",
        "            directory (str): The root directory containing the dataset files.\n",
        "            optim (str): The name of the optimizer to use for training.\n",
        "            loss (str): The name of the loss function to use for training.\n",
        "            file_extension (str): The file extension of the dataset files.\n",
        "            DL_type (str): The type of deep learning model ('RNN', '1DCNN', '2DCNN').\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize parent classes, including nn.Module, also send up directory, file_extension, and DL_type to ClassesFilesDictionarySetUp\n",
        "        super(BatchLossAndOptimization, self).__init__(directory, file_extension, DL_type)\n",
        "\n",
        "        # Initialize batch size, and learning rate\n",
        "        self.__batch_size: int = 32\n",
        "        self.__learning_rate: float = 0.001\n",
        "\n",
        "        # Initialize data split proportions\n",
        "        self.__train_size: float = 0.7 # 70% for training (what the model learns from)\n",
        "        self.__valid_size: float = 0.15 # 15% for validation (tuning hyperparameters and early stopping)\n",
        "        self.__test_size: float = 0.15 # 15% for testing (final unbiased evaluation)\n",
        "\n",
        "        # Initialize DataLoaders\n",
        "        self.__training_loader: Optional[DataLoader] = None # DataLoader for training set (the model learns from this data)\n",
        "        self.__validation_loader: Optional[DataLoader] = None # DataLoader for validation set (used for hyperparameter tuning and early stopping)\n",
        "        self.__testing_loader: Optional[DataLoader] = None # DataLoader for testing set (final unbiased evaluation of the model)\n",
        "\n",
        "        # Initialize class weights for loss function\n",
        "        self.__class_weights: Optional[torch.Tensor] = None\n",
        "\n",
        "        # Set up optimizer and loss function\n",
        "        self.__optim: type[torch.optim.Optimizer] = self.set_optim(optim)\n",
        "        self.__loss_name: str = 'None'\n",
        "        self.__loss: nn.Module = self.set_loss(loss)\n",
        "\n",
        "    def get_batch_size(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the batch size, or the number of samples/files per batch\n",
        "        e.g. if batch size is 32, each batch will contain 32 samples/files.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            int: The batch size.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__batch_size\n",
        "\n",
        "    def set_batch_size(self, batch_size: int) -> None:\n",
        "        \"\"\"\n",
        "        Set the batch size, or the number of samples/files per batch.\n",
        "        e.g. if batch size is 32, each batch will contain 32 samples/files\n",
        "\n",
        "        Parameters:\n",
        "            batch_size (int): The batch size to set.\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        if batch_size <= 0:\n",
        "            self.__batch_size = 1  # Ensure batch size is positive\n",
        "        else:\n",
        "            self.__batch_size = batch_size\n",
        "\n",
        "    def get_learning_rate(self) -> float:\n",
        "        \"\"\"\n",
        "        Get the learning rate, or the step size at each iteration while moving toward a minimum of a loss function.\n",
        "        e.g. a learning rate of 0.001 means the model weights are updated by 0.1% of the value of the gradient at each step.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            float: The learning rate.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__learning_rate\n",
        "\n",
        "    def set_learning_rate(self, learning_rate: float) -> None:\n",
        "        \"\"\"\n",
        "        Set the learning rate, or the step size at each iteration while moving toward a minimum of a loss function.\n",
        "        e.g. a learning rate of 0.001 means the model weights are updated by 0.1% of the value of the gradient at each step.\n",
        "\n",
        "        Parameters:\n",
        "            learning_rate (float): The learning rate to set.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        if learning_rate <= 0.0:\n",
        "            self.__learning_rate = 0.001  # Ensure learning rate is positive\n",
        "        else:\n",
        "            self.__learning_rate = learning_rate\n",
        "\n",
        "    def get_train_size(self) -> float:\n",
        "        \"\"\"\n",
        "        Get the training set size proportion, or the proportion of the dataset used for training.\n",
        "        e.g. a train size of 0.7 means 70% of the dataset is used for training.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            float: The training set size proportion.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__train_size\n",
        "\n",
        "    def set_train_size(self, train_size: float) -> None:\n",
        "        \"\"\"\n",
        "        Set the training set size proportion, or the proportion of the dataset used for training.\n",
        "        e.g. a train size of 0.7 means 70% of the dataset is used for training.\n",
        "\n",
        "        Parameters:\n",
        "            train_size (float): The training set size proportion to set.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure training is a \"reasonable\" proportion\n",
        "        if 0.0 < train_size < 1.0:\n",
        "            self.__train_size = train_size\n",
        "        else:\n",
        "            self.__train_size = 0.7  # Default to 70% if invalid\n",
        "\n",
        "    def get_validation_size(self) -> float:\n",
        "        \"\"\"\n",
        "        Get the validation set size proportion, or the proportion of the dataset used for validation.\n",
        "        e.g. a validation size of 0.15 means 15% of the dataset is used for validation.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            float: The validation set size proportion.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__valid_size\n",
        "\n",
        "    def set_validation_size(self, validation_size: float) -> None:\n",
        "        \"\"\"\n",
        "        Set the validation set size proportion, or the proportion of the dataset used for validation.\n",
        "        e.g. a validation size of 0.15 means 15% of the dataset is used for validation.\n",
        "\n",
        "        Parameters:\n",
        "            validation_size (float): The validation set size proportion to set.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure validation is a \"reasonable\" proportion\n",
        "        if 0.0 < validation_size < 1.0:\n",
        "            self.__valid_size = validation_size\n",
        "        else:\n",
        "            self.__valid_size = 0.15  # Default to 15% if invalid\n",
        "\n",
        "    def get_test_size(self) -> float:\n",
        "        \"\"\"\n",
        "        Get the testing set size proportion, or the proportion of the dataset used for testing.\n",
        "        e.g. a test size of 0.15 means 15% of the dataset is used for testing.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            float: The testing set size proportion.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__test_size\n",
        "\n",
        "    def set_test_size(self, test_size: float) -> None:\n",
        "        \"\"\"\n",
        "        Set the testing set size proportion, or the proportion of the dataset used for testing.\n",
        "        e.g. a test size of 0.15 means 15% of the dataset is used for testing.\n",
        "\n",
        "        Parameters:\n",
        "            test_size (float): The testing set size proportion to set.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure testing is a \"reasonable\" proportion\n",
        "        if 0.0 < test_size < 1.0:\n",
        "            self.__test_size = test_size\n",
        "        else:\n",
        "            self.__test_size = 0.15  # Default to 15% if invalid\n",
        "\n",
        "\n",
        "    def get_training_loader(self) -> DataLoader:\n",
        "        \"\"\"\n",
        "        Get the training data loader, which provides batches of training data during model training.\n",
        "        The information in the DataLoader looks like: (batch_size, channels, time_steps, features) for RNN\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            DataLoader: The training data loader.\n",
        "        \"\"\"\n",
        "\n",
        "        # Check if the training loader is valid\n",
        "        if self.__training_loader is None or not isinstance(self.__training_loader, DataLoader):\n",
        "            raise ValueError(\"Training loader has not been set.\")\n",
        "\n",
        "        return self.__training_loader\n",
        "\n",
        "    def set_training_loader(self, training_loader: DataLoader) -> None:\n",
        "        \"\"\"\n",
        "        Set the training data loader, which provides batches of training data during model training.\n",
        "        The information in the DataLoader looks like: (batch_size, time_steps, features) for RNN\n",
        "\n",
        "        Parameters:\n",
        "            training_loader (DataLoader): The training data loader to set.\n",
        "            If None or not a DataLoader, raises an error.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Make sure we have a valid DataLoader\n",
        "        if training_loader is None or not isinstance(training_loader, DataLoader):\n",
        "            raise ValueError(\"Training loader cannot be None.\")\n",
        "        else:\n",
        "            self.__training_loader = training_loader\n",
        "\n",
        "    def get_validation_loader(self) -> DataLoader:\n",
        "        \"\"\"\n",
        "        Get the validation data loader, which provides batches of validation data during model training.\n",
        "        The information in the DataLoader looks like: (batch_size, time_steps, features) for RNN\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            DataLoader: The validation data loader.\n",
        "        \"\"\"\n",
        "\n",
        "        # Check if the validation loader is valid\n",
        "        if self.__validation_loader is None or not isinstance(self.__validation_loader, DataLoader):\n",
        "            raise ValueError(\"Validation loader has not been set.\")\n",
        "\n",
        "        return self.__validation_loader\n",
        "\n",
        "    def set_validation_loader(self, validation_loader: DataLoader) -> None:\n",
        "        \"\"\"\n",
        "        Set the validation data loader, which provides batches of validation data during model training.\n",
        "        The information in the DataLoader looks like: (batch_size, time_steps, features) for RNN\n",
        "\n",
        "        Parameters:\n",
        "            validation_loader (DataLoader): The validation data loader to set.\n",
        "            If None or not a DataLoader, raises an error.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Make sure we have a valid DataLoader\n",
        "        if validation_loader is None or not isinstance(validation_loader, DataLoader):\n",
        "            raise ValueError(\"Validation loader cannot be None.\")\n",
        "        else:\n",
        "            self.__validation_loader = validation_loader\n",
        "\n",
        "    def get_testing_loader(self) -> DataLoader:\n",
        "        \"\"\"\n",
        "        Get the testing data loader, which provides batches of testing data during model evaluation.\n",
        "        The information in the DataLoader looks like: (batch_size, time_steps, features) for RNN\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            DataLoader: The testing data loader.\n",
        "        \"\"\"\n",
        "\n",
        "        # Check if the testing loader is valid\n",
        "        if self.__testing_loader is None or not isinstance(self.__testing_loader, DataLoader):\n",
        "            raise ValueError(\"Testing loader has not been set.\")\n",
        "\n",
        "        return self.__testing_loader\n",
        "\n",
        "    def set_testing_loader(self, testing_loader: DataLoader) -> None:\n",
        "        \"\"\"\n",
        "        Set the testing data loader, which provides batches of testing data during model evaluation.\n",
        "        The information in the DataLoader looks like: (batch_size, time_steps, features) for RNN\n",
        "\n",
        "        Parameters:\n",
        "            testing_loader (DataLoader): The testing data loader to set.\n",
        "            If None or not a DataLoader, raises an error.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Make sure we have a valid DataLoader\n",
        "        if testing_loader is None or not isinstance(testing_loader, DataLoader):\n",
        "            raise ValueError(\"Testing loader cannot be None.\")\n",
        "        else:\n",
        "            self.__testing_loader = testing_loader\n",
        "\n",
        "    def get_optim(self) -> type[torch.optim.Optimizer]:\n",
        "        \"\"\"\n",
        "        Get the optimizer for training.\n",
        "        The optimizer updates the model weights based on the computed gradients during backpropagation.\n",
        "        Backpropagation is the process of calculating how much each weight in the network contributed to the overall error,\n",
        "        allowing efficient computation of gradients for deep networks.\n",
        "        e.g. Adam optimizer adapts the learning rate for each parameter.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            type: The optimizer class.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.__optim\n",
        "\n",
        "    def set_optim(self, optimizer_name: str) -> type[torch.optim.Optimizer]:\n",
        "        \"\"\"\n",
        "        Lets the user decide what optimizer they wish to use for training.\n",
        "        The optimizer updates the model weights based on the computed gradients during backpropagation.\n",
        "        Backpropagation is the process of calculating how much each weight in the network contributed to the overall error,\n",
        "        allowing efficient computation of gradients for deep networks.\n",
        "        e.g. Adam optimizer adapts the learning rate for each parameter.\n",
        "\n",
        "        Parameters:\n",
        "            optimizer_name (str): The name of the optimizer. Includes 'SGD, 'Adam, 'NAdam', 'RAdam', 'AdamW', 'Adagrad', 'Adamax, 'Rprop', 'Rmsprop', and 'ASGD'.\n",
        "            (Adam likely is the best choice for deep fake detection due to its adaptive learning rate capabilities.)\n",
        "\n",
        "        Returns:\n",
        "            type[torch.optim.Optimizer]: The chosen optimizer class.\n",
        "        \"\"\"\n",
        "\n",
        "        # Define available optimizers\n",
        "        optimizers: dict[str, type] = {\n",
        "            'SGD': optim.SGD,\n",
        "            'Adam': optim.Adam,\n",
        "            'NAdam': optim.NAdam,\n",
        "            'RAdam': optim.RAdam,\n",
        "            'AdamW': optim.AdamW,\n",
        "            'Adagrad': optim.Adagrad,\n",
        "            'Adamax': optim.Adamax,\n",
        "            'Rprop': optim.Rprop,\n",
        "            'RMSprop': optim.RMSprop,\n",
        "            'ASGD': optim.ASGD,\n",
        "        }\n",
        "\n",
        "        # If we do not have a valid optimizer, raise an error\n",
        "        if optimizer_name not in optimizers:\n",
        "            raise ValueError(f\"Optimizer '{optimizer_name}' is not supported. Choose from: {list(optimizers.keys())}\")\n",
        "        else:\n",
        "            return optimizers[optimizer_name]\n",
        "\n",
        "    def get_class_weights(self) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Get the class weights tensor for loss function.\n",
        "        Class weights are used to balance the importance of different classes in the loss function.\n",
        "        It is a tensor where each element corresponds to the weight for a specific class.\n",
        "        e.g. torch.tensor([1.0, 2.0, 0.5]) means class 0 has weight 1.0, class 1 has weight 2.0, and class 2 has weight 0.5.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            Optional[torch.Tensor]: The class weights tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure class weights are valid\n",
        "        if self.__class_weights is None or not isinstance(self.__class_weights, torch.Tensor):\n",
        "            raise ValueError(\"Class weights have not been set.\")\n",
        "\n",
        "        return self.__class_weights\n",
        "\n",
        "    def set_class_weights(self, class_weights: torch.Tensor) -> None:\n",
        "        \"\"\"\n",
        "        Set the class weights tensor for loss function.\n",
        "        Class weights are used to balance the importance of different classes in the loss function.\n",
        "        It is a tensor where each element corresponds to the weight for a specific class.\n",
        "        e.g. torch.tensor([1.0, 2.0, 0.5]) means class 0 has weight 1.0, class 1 has weight 2.0, and class 2 has weight 0.5.\n",
        "\n",
        "        Parameters:\n",
        "            class_weights (Optional[torch.Tensor]): The class weights tensor to set.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure class weights are valid\n",
        "        if class_weights is None and not isinstance(class_weights, torch.Tensor):\n",
        "            raise ValueError(\"Class weights have not been set.\")\n",
        "\n",
        "        self.__class_weights = class_weights\n",
        "\n",
        "    def get_loss_name(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the name of the loss function.\n",
        "        e.g. 'CrossEntropyLoss' is commonly used for multi-class classification tasks.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            str: The name of the loss function.\n",
        "        \"\"\"\n",
        "        return self.__loss_name\n",
        "\n",
        "    def get_loss(self) -> nn.Module:\n",
        "        \"\"\"\n",
        "        Get the loss function for training.\n",
        "        The loss function measures how well the model's predictions match the true labels.\n",
        "        The higher the loss, the worse the model is performing.\n",
        "        For example, 2.0 is usually worse, while 0.3 is usually good\n",
        "        e.g. CrossEntropyLoss is commonly used for multi-class classification tasks.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            nn.Module: The loss function instance.\n",
        "        \"\"\"\n",
        "        return self.__loss\n",
        "\n",
        "    def set_loss(self, loss_name: str, class_weights: Optional[torch.Tensor] = None) -> nn.Module:\n",
        "        \"\"\"\n",
        "        Lets the user decide what loss function they wish to use for training.\n",
        "        The loss function measures how well the model's predictions match the true labels.\n",
        "        The higher the loss, the worse the model is performing.\n",
        "        For example, 2.0 is usually worse, while 0.3 is usually\n",
        "        e.g. CrossEntropyLoss is commonly used for multi-class classification tasks.\n",
        "\n",
        "        Parameters:\n",
        "            loss_name (str): The name of the loss function. Includes 'L1Loss', 'MSELoss', 'CrossEntropyLoss', 'NLLLoss', 'BCELoss', 'BCEWithLogitsLoss', 'HingeEmbeddingLoss', and 'SmoothL1Loss'.\n",
        "            class_weights (Optional[torch.Tensor]): Class weights for CrossEntropyLoss. Ignored for other loss functions.\n",
        "\n",
        "        Returns:\n",
        "            nn.Module: The chosen loss function.\n",
        "        \"\"\"\n",
        "\n",
        "        # Define available loss functions\n",
        "        losses: dict[str, nn.Module] = {\n",
        "            'L1Loss': nn.L1Loss(),\n",
        "            'MSELoss': nn.MSELoss(),\n",
        "            'CrossEntropyLoss': nn.CrossEntropyLoss(weight=class_weights) if class_weights is not None else nn.CrossEntropyLoss(),\n",
        "            'NLLLoss': nn.NLLLoss(),\n",
        "            'BCELoss': nn.BCELoss(),\n",
        "            'BCEWithLogitsLoss': nn.BCEWithLogitsLoss(),\n",
        "            'HingeEmbeddingLoss': nn.HingeEmbeddingLoss(),\n",
        "            'SmoothL1Loss': nn.SmoothL1Loss(),\n",
        "        }\n",
        "\n",
        "        if loss_name not in losses:\n",
        "            raise ValueError(f\"Loss function '{loss_name}' is not supported. Choose from: {list(losses.keys())}\")\n",
        "\n",
        "        # Store the loss name and return the loss function\n",
        "        self.__loss_name = loss_name\n",
        "        self.__loss = losses[loss_name]\n",
        "        return self.__loss\n",
        "\n",
        "\n",
        "    def split_data(self, train_size: float = 0.7, validation_size: float = 0.15, test_size: float = 0.15) -> None:\n",
        "        \"\"\"\n",
        "        Split the dataset into training, validation, and testing sets.\n",
        "\n",
        "        Parameters:\n",
        "            train_size (float): Proportion of the dataset to include in the training set.\n",
        "            validation_size (float): Proportion of the dataset to include in the validation set.\n",
        "            test_size (float): Proportion of the dataset to include in the testing set.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure the sizes sum to 1.0\n",
        "        total_size: float = train_size + validation_size + test_size\n",
        "        if total_size != 1.0:\n",
        "            raise ValueError(\"Train, validation, and test sizes must sum to 1.0\")\n",
        "\n",
        "        # Store the sizes\n",
        "        self.set_train_size(train_size)\n",
        "        self.set_validation_size(validation_size)\n",
        "        self.set_test_size(test_size)\n",
        "\n",
        "    def setup_data_loaders(self) -> None:\n",
        "        \"\"\"\n",
        "        Set up the data loaders for training, validation, and testing datasets.\n",
        "        Uses sklearn's train_test_split for stratified splitting to ensure balanced classes.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Setting Up Data Loaders ===============================\\n\")\n",
        "\n",
        "\n",
        "        # Initialize DataLoader temporaries\n",
        "        training_loader: DataLoader\n",
        "        validation_loader: DataLoader\n",
        "        testing_loader: DataLoader\n",
        "\n",
        "        # Get total dataset size\n",
        "        dataset_size: int = len(self)\n",
        "        print(f\"Total dataset size: {dataset_size} samples\")\n",
        "        print(f\"Split ratios - Train: {self.get_train_size()}, Valid: {self.get_validation_size()}, Test: {self.get_test_size()}\\n\")\n",
        "\n",
        "        # Build label mapping for all samples in the dataset\n",
        "        # This creates a list where labels[i] = class_index for dataset sample i\n",
        "        all_labels: list[int] = []\n",
        "        all_indices: list[int] = list(range(dataset_size))\n",
        "\n",
        "\n",
        "        # The end result of this loop is that all_labels contains the class index for each sample in the dataset\n",
        "        # e.g. all_labels = [0, 0, 1, 1, 2, 0, 1, ...] where each number corresponds to the class index of the sample at that position\n",
        "        for class_name in self.get_classes():\n",
        "            # Get the count and index for the current class\n",
        "            count: int = self.get_class_counts()[class_name]\n",
        "            class_index: int = self.get_classes_index()[class_name]\n",
        "\n",
        "            print(f\"Class '{class_name}' (index {class_index}) has {count} samples.\")\n",
        "\n",
        "            # Extend the labels list with the class index repeated 'count' times\n",
        "            all_labels.extend([class_index] * count)\n",
        "\n",
        "\n",
        "        # Now we need to split the data into train, validation, and test sets and try to keep the class distribution similar in each set\n",
        "\n",
        "        # First split: Train vs Temp (Validation + Test)\n",
        "        # By giving it all the indices and labels, we can stratify the split to maintain class distribution\n",
        "        # Stratifiying means we try to keep the same proportion of each class in each split as in the overall dataset\n",
        "\n",
        "        train_indices: list[int] = [0]  # Initialize variables\n",
        "        temp_indices: list[int] = [0]\n",
        "        train_labels: list[int] = [0]\n",
        "        temp_labels: list[int] = [0]\n",
        "\n",
        "        train_indices, temp_indices, train_labels, temp_labels = train_test_split(\n",
        "            all_indices,\n",
        "            all_labels,\n",
        "            train_size=self.get_train_size(),\n",
        "            stratify=all_labels,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "\n",
        "        # Second split: Validation vs Test\n",
        "        # We need to calculate the proportion of validation size relative to the temp size\n",
        "\n",
        "        # We need to calculate the size of temp relative to the whole dataset\n",
        "        test_val_size: float = self.get_validation_size() + self.get_test_size()\n",
        "\n",
        "        # valid_size / (valid_size + test_size)\n",
        "        val_prop: float = self.get_validation_size() / test_val_size\n",
        "\n",
        "        # Initialize variables\n",
        "        val_indices: list[int] = [0]\n",
        "        test_indices: list[int] = [0]\n",
        "        val_labels: list[int] = [0]\n",
        "        test_labels: list[int] = [0]\n",
        "\n",
        "        # This time, we use temp_indices and temp_labels (what's left after the first split) to split into validation and test sets\n",
        "        # We stratifiy again to maintain class distribution\n",
        "        val_indices, test_indices, val_labels, test_labels = train_test_split(\n",
        "            temp_indices,\n",
        "            temp_labels,\n",
        "            train_size=val_prop,\n",
        "            stratify=temp_labels,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        print(f\"\\nSplit sizes - Train: {len(train_indices)}, Valid: {len(val_indices)}, Test: {len(test_indices)}\")\n",
        "        print(f\"Training labels distribution: {np.bincount(train_labels)}\")\n",
        "        print(f\"Validation labels distribution: {np.bincount(val_labels)}\")\n",
        "        print(f\"Testing labels distribution: {np.bincount(test_labels)}\\n\")\n",
        "\n",
        "        # Create Subsets\n",
        "        train_dataset: Subset = Subset(self, train_indices)\n",
        "        valid_dataset: Subset = Subset(self, val_indices)\n",
        "        test_dataset: Subset = Subset(self, test_indices)\n",
        "\n",
        "        # Manually set class weights to try and get model to better understand class 1 (real) samples\n",
        "        class_weights: list[float] = [0.866667, 1.3, 1.05, 1.05, 0.866667, 1.0, 0.866666]\n",
        "\n",
        "        class_weights_tensor: torch.Tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
        "        class_weights_tensor = class_weights_tensor.to(self.get_device())  # Move to the same device as the model\n",
        "\n",
        "        print(f\"Class weights for loss function: {class_weights}\\n\")\n",
        "\n",
        "        # Store class weights\n",
        "        self.set_class_weights(class_weights_tensor)\n",
        "\n",
        "        # Set loss function with class weights (set_loss updates both __loss and __loss_name)\n",
        "        self.set_loss(self.get_loss_name(), class_weights_tensor)\n",
        "\n",
        "        # Fit StandardScaler on training data before creating DataLoaders\n",
        "        self.fit_scaler_on_training_data(train_indices)\n",
        "\n",
        "        # Create DataLoaders\n",
        "        training_loader: DataLoader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.get_batch_size(),\n",
        "            shuffle=True,  # Shuffle training data\n",
        "        )\n",
        "\n",
        "        self.set_training_loader(training_loader)\n",
        "\n",
        "        validation_loader: DataLoader = DataLoader(\n",
        "            valid_dataset,\n",
        "            batch_size=self.get_batch_size(),\n",
        "            shuffle=False,  # Don't shuffle validation\n",
        "        )\n",
        "\n",
        "        self.set_validation_loader(validation_loader)\n",
        "\n",
        "        testing_loader: DataLoader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=self.get_batch_size(),\n",
        "            shuffle=False,  # Don't shuffle test\n",
        "        )\n",
        "\n",
        "        self.set_testing_loader(testing_loader)\n",
        "\n",
        "        # Validate our DataLoaders and make sure our logic worked correctly\n",
        "        if not isinstance(self.get_training_loader(), DataLoader) or not isinstance(self.get_validation_loader(), DataLoader) or not isinstance(self.get_testing_loader(), DataLoader) or any(loader is None for loader in [self.get_training_loader(), self.get_validation_loader(), self.get_testing_loader()]):\n",
        "            raise ValueError(\"One or more DataLoaders were not set up correctly.\")\n",
        "\n",
        "        # Print summary if it worked\n",
        "        else:\n",
        "            print(f\"DataLoaders created successfully!\")\n",
        "            print(f\"  Training batches: {len(training_loader)}\")\n",
        "            print(f\"  Validation batches: {len(validation_loader)}\")\n",
        "            print(f\"  Testing batches: {len(testing_loader)}\")\n",
        "            print(\"\\n----------------------------- Data Loaders Setup Complete -----------------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rONSvjIqBhih"
      },
      "outputs": [],
      "source": [
        "class PyTorchDeepFakeDetectorLSTM(BatchLossAndOptimization):\n",
        "    \"\"\"\n",
        "    Creates, trains, and tests a DeepFake Detector using an LSTM architecture.\n",
        "    Inherits from BatchLossAndOptimization, nn.Module, Dataset, and ClassesFilesDictionarySetUp.\n",
        "    \"\"\"\n",
        "    def __init__(self, directory: str = '', optim: str = 'Adam', loss: str = 'CrossEntropyLoss', file_extension: str = '.wav', DL_type: str = 'RNN') -> None:\n",
        "        \"\"\"\n",
        "        Initialize the PyTorchDeepFakeDetectorLSTM class.\n",
        "        Sets up the LSTM model architecture and initializes the parent class.\n",
        "        Also sends the parent the directory, file extension, loss function, optimizer, and DL type.\n",
        "\n",
        "        Parameters:\n",
        "            directory (str): Directory containing the dataset.\n",
        "            optim (str): Optimizer to use for training (default: 'Adam').\n",
        "            loss (str): Loss function to use for training (default: 'CrossEntropyLoss').\n",
        "            file_extension (str): File extension of audio files (default: '.wav').\n",
        "            DL_type (str): Type of deep learning model (default: 'RNN').\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        super(PyTorchDeepFakeDetectorLSTM, self).__init__(directory, file_extension, loss, optim, DL_type)\n",
        "\n",
        "        self.LSTM_model()\n",
        "\n",
        "        # Move model to device (GPU if available)\n",
        "        self.to(self.get_device())\n",
        "\n",
        "    def LSTM_model(self) -> nn.Module:\n",
        "        \"\"\"\n",
        "        Define our Long Short-Term Memory (LSTM) model architecture for DeepFake detection.\n",
        "        Returns the constructed LSTM model.\n",
        "        e.g. the LSTM model architecture consists of:\n",
        "        - Two LSTM layers with dropout\n",
        "        - Fully connected layer for final classification\n",
        "\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            nn.Module: The LSTM model.\n",
        "        \"\"\"\n",
        "\n",
        "        # First LSTM layer for initial feature extraction\n",
        "        self.lstm_1: nn.LSTM = nn.LSTM(\n",
        "            input_size=self.get_n_mfcc(),  # Number of MFCC features\n",
        "            hidden_size=256,                # Number of features in hidden state\n",
        "            num_layers=1,                   # Number of stacked LSTM layers\n",
        "            batch_first=True,                # Input/output tensors have shape (batch, seq, feature)\n",
        "            bidirectional=True,              # Bidirectional LSTM for better context\n",
        "        )\n",
        "\n",
        "        # By doing a 0.5 dropout, we make 50% of the neurons inactive during each training iteration\n",
        "        self.dropout1: nn.Dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Second LSTM layer for deeper feature extraction\n",
        "        self.lstm_2: nn.LSTM = nn.LSTM(\n",
        "            input_size=512,                 # 256 * 2 (bidirectional)\n",
        "            hidden_size=1024,                # Number of features in hidden state\n",
        "            num_layers=1,                   # Number of stacked LSTM layers\n",
        "            batch_first=True,                # Input/output tensors have shape (batch, seq, feature)\n",
        "            bidirectional=True,              # Bidirectional LSTM for better context\n",
        "        )\n",
        "\n",
        "        # By doing a 0.5 dropout, we make 50% of the neurons inactive during each training iteration\n",
        "        self.dropout2: nn.Dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Final fully connected layer for classification\n",
        "        self.fc: nn.Linear = nn.Linear(2048, len(self.get_classes()))  # 1024 * 2 (bidirectional)\n",
        "        return self\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of the LSTM model.\n",
        "        Returns the output logits for each class.\n",
        "        e.g. if we have 2 classes (Real, Fake), output shape is (batch_size, 2)\n",
        "        If we have 7 classes (real, various DeepFake methods), output shape is (batch_size, 7)\n",
        "\n",
        "        Parameters:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, time_steps, n_mfcc).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output logits of shape (batch_size, num_classes).\n",
        "        \"\"\"\n",
        "\n",
        "        out: torch.Tensor = x\n",
        "\n",
        "        # Pass through first LSTM layer\n",
        "        out, _ = self.lstm_1(x)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        # Pass through second LSTM layer\n",
        "        out, _ = self.lstm_2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        # Take the output from the last time step\n",
        "        out = out[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        # Pass through the final fully connected layer\n",
        "        out = self.fc(out)  # Shape: (batch_size, num_classes)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def extract_features(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Extract features from the LSTM model before the final classification layer.\n",
        "\n",
        "        Parameters:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, time_steps, n_mfcc).\n",
        "        Returns:\n",
        "            torch.Tensor: Extracted features of shape (batch_size, hidden_size).\n",
        "        \"\"\"\n",
        "\n",
        "        out: torch.Tensor = x\n",
        "\n",
        "        # Pass through first LSTM layer\n",
        "        out, _ = self.lstm_1(x)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        # Pass through second LSTM layer\n",
        "        out, _ = self.lstm_2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        # Take the output from the last time step\n",
        "        out = out[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "    def train_LSTM(self, num_epochs: int = 20) -> None:\n",
        "        \"\"\"\n",
        "        Train the LSTM using our pre-chosen optimizer and loss function:\n",
        "\n",
        "        Parameters:\n",
        "            num_epochs (int): Number of training epochs.\n",
        "            optimizer_name (str): Name of the optimizer to use.\n",
        "            loss_name (str): Name of the loss function to use.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure DataLoaders are set up\n",
        "        if self.get_training_loader() is None or self.get_validation_loader() is None:\n",
        "            print(\"DataLoaders were not set up. Calling setup_data_loaders() before training.\")\n",
        "            self.setup_data_loaders()\n",
        "\n",
        "            self.get_training_loader()\n",
        "            self.get_validation_loader()\n",
        "\n",
        "        # Initialize lists to track metrics\n",
        "        self.train_loss_list: list[float] = []\n",
        "        self.train_acc_list: list[torch.Tensor] = []\n",
        "        self.val_loss_list: list[float] = []\n",
        "        self.val_acc_list: list[torch.Tensor] = []\n",
        "\n",
        "         # Set up optimizer and loss function\n",
        "        optimizer_class: type = self.get_optim()\n",
        "        optimizer: torch.optim.Optimizer = optimizer_class(params=self.parameters(), lr=self.get_learning_rate())\n",
        "        loss: torch.nn.Module = self.get_loss()\n",
        "\n",
        "        print(\"\\n=============================== Starting LSTM Training ===============================\\n\")\n",
        "\n",
        "        # Get DataLoaders\n",
        "        training_loader: torch.utils.data.DataLoader = self.get_training_loader()\n",
        "        validation_loader: torch.utils.data.DataLoader = self.get_validation_loader()\n",
        "\n",
        "        # Check if DataLoaders are available\n",
        "        if training_loader is None or validation_loader is None:\n",
        "            raise ValueError(\"DataLoaders are not available.\")\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            self.train()  # Set model to training mode\n",
        "            epoch_loss: float = 0.0 # Accumulate loss over the epoch\n",
        "            num_batches: int = 0 # Number of batches processed in the epoch\n",
        "\n",
        "            train_correct: torch.Tensor = torch.tensor(0, dtype=torch.int32) # Number of correct predictions in training\n",
        "            train_total: int = 0 # Total number of samples in training\n",
        "\n",
        "            # Training loop with tqdm progress bar\n",
        "            train_pbar: tqdm = tqdm(training_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Training]\", leave=False)\n",
        "\n",
        "            for batch_idx, (data, labels) in enumerate(train_pbar):\n",
        "\n",
        "                # Move data to device\n",
        "                data: torch.Tensor = data.to(self.get_device())\n",
        "                labels: torch.Tensor = labels.to(self.get_device())\n",
        "\n",
        "                # Zero the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs: torch.Tensor = self.forward(data)\n",
        "\n",
        "                # Compute loss\n",
        "                batch_loss: torch.Tensor = loss(outputs, labels)\n",
        "\n",
        "                # Backward pass\n",
        "                batch_loss.backward()\n",
        "\n",
        "                # Clip gradients to prevent exploding gradients\n",
        "                torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)\n",
        "\n",
        "                # Update weights\n",
        "                optimizer.step()\n",
        "\n",
        "                # Accumulate loss and accuracy\n",
        "                epoch_loss += batch_loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "                # Calculate training accuracy\n",
        "                _, predicted = torch.max(outputs.data, dim=1)\n",
        "\n",
        "                train_total += labels.size(0)\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                # Update progress bar with current loss\n",
        "                train_pbar.set_postfix({'loss': f'{batch_loss.item():.4f}'})\n",
        "\n",
        "            # Calculate average loss and accuracy for the epoch\n",
        "            avg_loss: float = epoch_loss / num_batches\n",
        "\n",
        "            train_accuracy: torch.Tensor = 100 * train_correct / train_total\n",
        "\n",
        "            # Validation phase\n",
        "            self.eval()  # Set model to evaluation mode\n",
        "            val_loss: float = 0.0 # Accumulate validation loss\n",
        "            val_correct: torch.Tensor = torch.tensor(0, dtype=torch.int32) # Number of correct predictions in validation\n",
        "            val_total: int = 0 # Total number of samples in validation\n",
        "\n",
        "            # Track per-class accuracy for validation\n",
        "            num_classes: int = len(self.get_classes())\n",
        "            val_class_correct: list[int] = [0] * num_classes\n",
        "            val_class_total: list[int] = [0] * num_classes\n",
        "\n",
        "            # Validation loop with tqdm progress bar\n",
        "            val_pbar: tqdm = tqdm(validation_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Validation]\", leave=False)\n",
        "            with torch.no_grad():\n",
        "                for data, labels in val_pbar:\n",
        "\n",
        "                    # Move data to device\n",
        "                    data: torch.Tensor = data.to(self.get_device())\n",
        "                    labels: torch.Tensor = labels.to(self.get_device())\n",
        "\n",
        "                    # Forward pass\n",
        "                    outputs: torch.Tensor = self.forward(data)\n",
        "\n",
        "                    # Compute loss\n",
        "                    batch_loss: torch.Tensor = loss(outputs, labels)\n",
        "\n",
        "                    # Accumulate validation loss\n",
        "                    val_loss += batch_loss.item()\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    _, predicted = torch.max(outputs.data, dim=1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    # Track per-class accuracy\n",
        "                    for i in range(len(labels)):\n",
        "                        # Get the true label\n",
        "                        label: int = int(labels[i].item())\n",
        "\n",
        "                        # Update total count for this class\n",
        "                        val_class_total[label] += 1\n",
        "\n",
        "                        # Update correct count for this class if the prediction is correct\n",
        "                        if predicted[i] == labels[i]:\n",
        "                            val_class_correct[label] += 1\n",
        "\n",
        "                    # Update progress bar\n",
        "                    val_pbar.set_postfix({'val_loss': f'{batch_loss.item():.4f}'})\n",
        "\n",
        "            # Calculate average validation loss and accuracy\n",
        "            avg_val_loss: float = val_loss / len(validation_loader)\n",
        "            val_accuracy: torch.Tensor = 100 * val_correct / val_total\n",
        "\n",
        "            # Store metrics for plotting\n",
        "            self.train_loss_list.append(avg_loss)\n",
        "            self.train_acc_list.append(train_accuracy)\n",
        "            self.val_loss_list.append(avg_val_loss)\n",
        "            self.val_acc_list.append(val_accuracy)\n",
        "\n",
        "\n",
        "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "            # Print per-class validation accuracy\n",
        "            print(f\"  Per-Class Validation Accuracy:\")\n",
        "\n",
        "            class_names: list[str] = self.get_classes()\n",
        "            # Iterate over each class to print accuracy\n",
        "            for i, class_name in enumerate(class_names):\n",
        "\n",
        "                # Calculate and print accuracy for this class\n",
        "                if val_class_total[i] > 0:\n",
        "\n",
        "                    # Calculate accuracy for this class\n",
        "                    class_acc: float = 100 * val_class_correct[i] / val_class_total[i]\n",
        "                    # Print accuracy for this class\n",
        "                    print(f\"    {class_name}: {class_acc:.2f}% ({val_class_correct[i]}/{val_class_total[i]})\")\n",
        "\n",
        "                # Handle case with no samples for this class\n",
        "                else:\n",
        "                    print(f\"    {class_name}: No samples in validation set\")\n",
        "\n",
        "            # Early stopping if validation loss is below threshold\n",
        "            if avg_val_loss < 0.40:\n",
        "                print(f\"\\n*** Early stopping triggered: Validation loss {avg_val_loss:.4f} < 0.40 ***\")\n",
        "                print(f\"*** Training completed at epoch {epoch + 1}/{num_epochs} ***\\n\")\n",
        "                break\n",
        "\n",
        "        print(\"\\n---------------------------- LSTM Training Complete ----------------------------\\n\")\n",
        "\n",
        "\n",
        "    def evaluate_model(self, past_model: str = 'None') -> None:\n",
        "        \"\"\"\n",
        "        Evaluate the trained model on the test set and report accuracy, loss, and per-class metrics.\n",
        "\n",
        "        Parameters:\n",
        "            past_model (str): Path to a saved model to load before evaluation. Defaults to 'None'.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Evaluating Model on Test Set ===============================\\n\")\n",
        "\n",
        "        # Load past model if specified\n",
        "        if past_model != 'None':\n",
        "            print(f\"Loading model from: {past_model}\")\n",
        "            self.load_state_dict(torch.load(past_model, map_location=self.get_device()), strict=False)\n",
        "            print(\"Model loaded successfully.\\n\")\n",
        "\n",
        "        # Get testing DataLoader\n",
        "        testing_loader: torch.utils.data.DataLoader = self.get_testing_loader()\n",
        "\n",
        "        # Ensure testing DataLoader is available\n",
        "        if testing_loader is None:\n",
        "            print(\"Testing DataLoader not found. Setting up data loaders now.\")\n",
        "            self.setup_data_loaders()\n",
        "            testing_loader = self.get_testing_loader()\n",
        "\n",
        "        self.eval()  # Set model to evaluation mode\n",
        "        test_loss: float = 0.0\n",
        "        test_correct: torch.Tensor = torch.tensor(0, dtype=torch.int32)\n",
        "        test_total: int = 0\n",
        "\n",
        "        # Track per-class accuracy\n",
        "        num_classes: int = len(self.get_classes())\n",
        "        class_correct: list[int] = [0] * num_classes\n",
        "        class_total: list[int] = [0] * num_classes\n",
        "\n",
        "        # Get loss function\n",
        "        loss_fn: torch.nn.Module = self.get_loss()\n",
        "\n",
        "        # Final check if testing DataLoader is available\n",
        "        if testing_loader is None:\n",
        "            raise ValueError(\"Testing DataLoader is not available.\")\n",
        "\n",
        "        with torch.no_grad():  # No gradient computation during evaluation\n",
        "            test_pbar: tqdm = tqdm(testing_loader, desc=f\"[Testing]\", leave=False)\n",
        "            for data, labels in test_pbar:\n",
        "\n",
        "                # Move data to device\n",
        "                data: torch.Tensor = data.to(self.get_device())\n",
        "                labels: torch.Tensor = labels.to(self.get_device())\n",
        "\n",
        "                # Forward pass\n",
        "                outputs: torch.Tensor = self(data)\n",
        "                batch_loss: torch.Tensor = loss_fn(outputs, labels)\n",
        "                test_loss += batch_loss.item()\n",
        "\n",
        "                # Calculate predictions\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                # Per-class accuracy tracking\n",
        "                for label, prediction in zip(labels, predicted):\n",
        "                    # Update total count for this class\n",
        "                    class_total[label] += 1\n",
        "\n",
        "                    # Update correct count for this class if prediction is correct\n",
        "                    if label == prediction:\n",
        "                        class_correct[label] += 1\n",
        "\n",
        "                # Update progress bar\n",
        "                test_pbar.set_postfix({'test_loss': f'{batch_loss.item():.4f}'})\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        avg_test_loss: float = test_loss / len(testing_loader)\n",
        "        test_accuracy: torch.Tensor = 100 * test_correct / test_total\n",
        "\n",
        "        # Print overall test results\n",
        "        print(f\"\\nTest Results:\")\n",
        "        print(f\"  Average Loss: {avg_test_loss:.4f}\")\n",
        "        print(f\"  Overall Accuracy: {test_accuracy:.2f}% ({test_correct}/{test_total})\")\n",
        "\n",
        "        # Print per-class accuracy\n",
        "        print(f\"\\nPer-Class Accuracy:\")\n",
        "\n",
        "        # Get class names\n",
        "        class_names: list[str] = self.get_classes()\n",
        "\n",
        "        # Iterate over each class to print accuracy\n",
        "        for i, class_name in enumerate(class_names):\n",
        "\n",
        "            # Calculate and print accuracy for this class\n",
        "            if class_total[i] > 0:\n",
        "\n",
        "                # Calculate accuracy for this class\n",
        "                class_acc: float = 100 * class_correct[i] / class_total[i]\n",
        "\n",
        "                # Print accuracy for this class\n",
        "                print(f\"  {class_name}: {class_acc:.2f}% ({class_correct[i]}/{class_total[i]})\")\n",
        "\n",
        "            # Handle case with no samples for this class\n",
        "            else:\n",
        "                print(f\"  {class_name}: No samples in test set\")\n",
        "\n",
        "        print(\"\\n---------------------------- Model Evaluation Complete ----------------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLO4p78VBlc6"
      },
      "outputs": [],
      "source": [
        "class DeepFakeDetectorGraphsAndStats(PyTorchDeepFakeDetectorLSTM):\n",
        "    \"\"\"\n",
        "    A class to generate graphs and statistics for the DeepFake Detector.\n",
        "    Inherits from BatchLossAndOptimization, nn.Module, Dataset, and ClassesFilesDictionarySetUp.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, directory: str = '', file_extension: str = '.wav', loss: str = 'CrossEntropyLoss', optim: str = 'Adam', DL_type: str = 'RNN') -> None:\n",
        "        \"\"\"\n",
        "        Initialize the DeepFakeDetectorGraphsAndStats class.\n",
        "        Also send directory, file_extension, loss, optim, and DL_type to the parent class.\n",
        "\n",
        "        Parameters:\n",
        "            directory (str): Directory containing the dataset.\n",
        "            file_extension (str): File extension of the audio files.\n",
        "            loss (str): Loss function to use.\n",
        "            optim (str): Optimizer to use.\n",
        "            DL_type (str): Type of deep learning model to use.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize the parent class and send parameters up the chain\n",
        "        super(DeepFakeDetectorGraphsAndStats, self).__init__(directory, file_extension, loss, optim, DL_type)\n",
        "\n",
        "        # Initialize attributes for storing testing data and predictions\n",
        "        self.all_labels: List[int] = []\n",
        "        self.all_predictions: List[int] = []\n",
        "        self.all_probabilities: np.ndarray = np.array([])\n",
        "\n",
        "\n",
        "    def plot_training_curves(self) -> None:\n",
        "        \"\"\"\n",
        "        Plot training and validation loss and accuracy curves in 4 subplots.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Plotting Training Curves ===============================\\n\")\n",
        "\n",
        "        # Check if training metrics exist\n",
        "        if not hasattr(self, 'train_loss_list') or not self.train_loss_list:\n",
        "            print(\"No training metrics found. Please train the model first.\")\n",
        "            return\n",
        "\n",
        "        epochs: range = range(1, len(self.train_loss_list) + 1)\n",
        "\n",
        "        # Create figure with 4 subplots (2x2 grid)\n",
        "        plt.figure(figsize=(14, 10))\n",
        "\n",
        "        # Subplot 1: Training Loss\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.plot(epochs, self.train_loss_list, label='Training Loss', color='blue')\n",
        "        plt.title('Training Loss', fontsize=18, fontweight='bold')\n",
        "        plt.xlabel('Epoch', fontsize=14)\n",
        "        plt.ylabel('Loss', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Subplot 2: Validation Loss\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(epochs, self.val_loss_list, label='Validation Loss', color='orange')\n",
        "        plt.title('Validation Loss', fontsize=18, fontweight='bold')\n",
        "        plt.xlabel('Epoch', fontsize=14)\n",
        "        plt.ylabel('Loss', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Subplot 3: Training Accuracy\n",
        "        plt.subplot(2, 2, 3)\n",
        "        plt.plot(epochs, self.train_acc_list, label='Training Accuracy', color='green')\n",
        "        plt.title('Training Accuracy', fontsize=18, fontweight='bold')\n",
        "        plt.xlabel('Epoch', fontsize=14)\n",
        "        plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Subplot 4: Validation Accuracy\n",
        "        plt.subplot(2, 2, 4)\n",
        "        plt.plot(epochs, self.val_acc_list, label='Validation Accuracy', color='red')\n",
        "        plt.title('Validation Accuracy', fontsize=18, fontweight='bold')\n",
        "        plt.xlabel('Epoch', fontsize=14)\n",
        "        plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Adjust layout and show plot\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\n---------------------------- Training Curves Plotted ----------------------------\\n\")\n",
        "\n",
        "    def plot_class_counts(self) -> None:\n",
        "        \"\"\"\n",
        "        Plot the distribution of samples per class in the dataset.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\" \\n=============================== Sample Count Diagramming =============================== \\n\")\n",
        "\n",
        "        # Get class counts\n",
        "        class_counts: Dict[str, int] = self.get_class_counts()\n",
        "\n",
        "        # Plotting the class distribution\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        # Make sure the classes are the x-axis labels, and the values are the heights of the bars in the y-axis\n",
        "        plt.bar(list(class_counts.keys()), list(class_counts.values()))\n",
        "        plt.xlabel(\"Classes\")\n",
        "        plt.ylabel(\"Number of Samples\")\n",
        "        plt.title(\"Class Distribution\", fontsize=18, fontweight='bold')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\" \\n---------------------------- Sample Count Diagramming Complete ---------------------------- \\n\")\n",
        "\n",
        "\n",
        "    def test_batch_equality(self, num_batches_to_test: int) -> None:\n",
        "        \"\"\"\n",
        "        Test function to verify that a subset of batches from the training DataLoader are balanced by showing class distributions.\n",
        "\n",
        "        Parameters:\n",
        "            num_batches_to_test (int): The number of batches to test for balance.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Testing Batch Equality ===============================\\n\")\n",
        "\n",
        "        # Get the training DataLoader\n",
        "        training_loader: DataLoader = self.get_training_loader()\n",
        "\n",
        "        # Ensure the training loader is available\n",
        "        if training_loader is None:\n",
        "            raise ValueError(\"Training loader is not set up.\")\n",
        "\n",
        "        # Iterate through the specified number of batches\n",
        "        for batch_idx, (_, labels) in enumerate(training_loader):\n",
        "\n",
        "            # Limit to the specified number of batches\n",
        "            if batch_idx >= num_batches_to_test:\n",
        "                break\n",
        "\n",
        "            # Count class distribution in this batch\n",
        "            label_counts: Counter = Counter(labels.tolist())\n",
        "\n",
        "            print(f\"\\nBatch {batch_idx + 1}:\")\n",
        "            print(f\"  Total samples: {len(labels)}\")\n",
        "            print(f\"  Class distribution:\")\n",
        "\n",
        "            # Print counts and percentages for each class\n",
        "            for class_idx in sorted(label_counts.keys()):\n",
        "\n",
        "                # Get count and percentage for this class\n",
        "                count: int = label_counts[class_idx]\n",
        "                percentage: float = (count / len(labels)) * 100\n",
        "                print(f\"    Class {class_idx}: {count:3d} samples ({percentage:5.1f}%)\")\n",
        "\n",
        "            # Create a bar plot for this batch's class distribution\n",
        "            plt.figure(figsize=(8, 4))\n",
        "\n",
        "            # Only plot if class indices are integers\n",
        "            if len(label_counts) > 0 and isinstance(next(iter(label_counts.keys())), int):\n",
        "                # Make sure the class indices are the x-axis labels, and the values are the heights of the bars in the y-axis\n",
        "                plt.bar(list(label_counts.keys()), list(label_counts.values()))\n",
        "\n",
        "            plt.xlabel(\"Class Index\", fontsize=16, fontweight='bold')\n",
        "            plt.ylabel(\"Number of Samples\", fontsize=16, fontweight='bold')\n",
        "            plt.title(f\"Class Distribution in Batch {batch_idx + 1}\")\n",
        "            plt.show()\n",
        "\n",
        "        print(\"\\n---------------------------- Batch Equality Test Complete ----------------------------\\n\")\n",
        "\n",
        "\n",
        "    def plot_random_mfcc_samples(self, samples: int = 3) -> None:\n",
        "        \"\"\"\n",
        "        Plot random MFCC samples from each class using raw audio files.\n",
        "\n",
        "        Parameters:\n",
        "            samples (int): Number of random samples to plot for each class. Defaults to 3.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Plotting Random MFCC Samples ===============================\\n\")\n",
        "\n",
        "        # Get the file dictionary\n",
        "        file_dict: dict[int, list[str]] = self.get_file_dictionary()\n",
        "\n",
        "        # Iterate through each class\n",
        "        for class_name in self.get_classes():\n",
        "\n",
        "            # Get class index and corresponding files\n",
        "            class_index: int = self.get_classes_index()[class_name]\n",
        "            class_files: list[str] = file_dict[class_index]\n",
        "\n",
        "            # Randomly sample files from this class\n",
        "            num_samples: int = min(samples, len(class_files))\n",
        "            random_indices: np.ndarray = np.random.choice(len(class_files), size=num_samples, replace=False)\n",
        "\n",
        "            print(f\"\\nPlotting {num_samples} MFCC samples from class '{class_name}'...\")\n",
        "\n",
        "            # For each randomly selected file\n",
        "            for i, file_idx in enumerate(random_indices):\n",
        "\n",
        "                # Get the file path\n",
        "                file_path: str = class_files[file_idx]\n",
        "\n",
        "                try:\n",
        "                    # Load audio file\n",
        "                    signal, sr = librosa.load(file_path, sr=self.get_sample_rate(), duration=self.get_duration())\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"\\nWarning: Failed to load audio file: {file_path}\")\n",
        "                    print(f\"Error: {e}\")\n",
        "                    print(\"Returning zeros as fallback.\\n\")\n",
        "\n",
        "                    # Return zeros with expected shape as fallback\n",
        "                    signal: np.ndarray = np.zeros(self.get_sample_rate() * self.get_duration())\n",
        "\n",
        "                    sr: int | float = self.get_sample_rate()\n",
        "\n",
        "                # Ensure fixed length\n",
        "                target_length: int = self.get_sample_rate() * self.get_duration()\n",
        "\n",
        "                # If wave is shorter than target length, pad it; if longer, truncate it\n",
        "                if len(signal) < target_length:\n",
        "                    signal = np.pad(signal, (0, target_length - len(signal)), 'constant')\n",
        "                else:\n",
        "                    signal = signal[:target_length]\n",
        "\n",
        "                # Compute MFCCs\n",
        "                mfccs: np.ndarray = librosa.feature.mfcc(\n",
        "                    y=signal,\n",
        "                    sr=sr,\n",
        "                    n_mfcc=self.get_n_mfcc(),\n",
        "                    n_fft=self.get_n_fft(),\n",
        "                    hop_length=self.get_hop_length()\n",
        "                )\n",
        "\n",
        "                # Plot MFCCs\n",
        "                fig, ax = plt.subplots(figsize=(10, 4))\n",
        "                img = librosa.display.specshow(\n",
        "                    mfccs,\n",
        "                    x_axis='time',\n",
        "                    ax=ax\n",
        "                )\n",
        "\n",
        "                # Add color bar\n",
        "                fig.colorbar(img, ax=ax)\n",
        "                ax.set(title=f'MFCC - Class: {class_name} - Sample {i+1}', ylabel='MFCC Coefficients')\n",
        "                ax.title.set_fontsize(18)\n",
        "                ax.title.set_fontweight('bold')\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "        print(\"\\n---------------------------- MFCC Plotting Complete ----------------------------\\n\")\n",
        "\n",
        "    def mean_and_std_stats(self) -> None:\n",
        "        \"\"\"\n",
        "        Calculate and print the mean and standard deviation of not just the raw data,\n",
        "        but also the scaled data if scaling is applied.\n",
        "        Finally, we print out the mean and std for a set of 5 batches from the training DataLoader.\n",
        "\n",
        "        Parameters:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Calculating Mean and Standard Deviation Statistics ===============================\\n\")\n",
        "\n",
        "        # Collect raw data (before scaling and batching) from 100 random samples\n",
        "        raw_data: List[np.ndarray] = []\n",
        "        scaled_data: List[np.ndarray] = []\n",
        "        num_samples: int = min(100, len(self))\n",
        "        sample_indices: np.ndarray = np.random.choice(len(self), size=num_samples, replace=False)\n",
        "\n",
        "        # Temporarily disable scaling to get raw data\n",
        "        use_scaler_original: bool = self.get_use_scaler()\n",
        "        self.set_use_scaler(False)\n",
        "\n",
        "        # For each randomly selected sample\n",
        "        for idx in sample_indices:\n",
        "            # Get data without scaling\n",
        "            data, _ = self.__getitem__(idx)\n",
        "\n",
        "            # If data is a tensor, convert to numpy and flatten\n",
        "            if isinstance(data, torch.Tensor):\n",
        "                raw_data.append(data.numpy().flatten())\n",
        "\n",
        "        # Re-enable scaling to get scaled data\n",
        "        self.set_use_scaler(use_scaler_original)\n",
        "\n",
        "        # For each randomly selected sample, if scaling is enabled\n",
        "        if use_scaler_original and self.get_scaler() is not None:\n",
        "            for idx in sample_indices:\n",
        "\n",
        "                # Get data with scaling\n",
        "                data, _ = self.__getitem__(idx)\n",
        "\n",
        "                # If data is a tensor, convert to numpy and flatten\n",
        "                if isinstance(data, torch.Tensor):\n",
        "                    scaled_data.append(data.numpy().flatten())\n",
        "\n",
        "        # Print raw data stats\n",
        "        if raw_data:\n",
        "            raw_concat: np.ndarray = np.concatenate(raw_data)\n",
        "            print(f\"Raw Data Stats ({len(raw_data)} samples):\")\n",
        "            print(f\"  Mean: {np.mean(raw_concat):.6f}\")\n",
        "            print(f\"  Std:  {np.std(raw_concat):.6f}\\n\")\n",
        "\n",
        "        # Print scaled data stats\n",
        "        if scaled_data:\n",
        "            scaled_concat: np.ndarray = np.concatenate(scaled_data)\n",
        "            print(f\"Scaled Data Stats ({len(scaled_data)} samples):\")\n",
        "            print(f\"  Mean: {np.mean(scaled_concat):.6f}\")\n",
        "            print(f\"  Std:  {np.std(scaled_concat):.6f}\\n\")\n",
        "\n",
        "        # Collect data from first 5 batches\n",
        "        training_loader: DataLoader = self.get_training_loader()\n",
        "\n",
        "        # Ensure the training loader is available\n",
        "        if training_loader is not None:\n",
        "            batch_data = []\n",
        "\n",
        "            # Iterate through first 5 batches\n",
        "            for batch_idx, (data, _) in enumerate(training_loader):\n",
        "\n",
        "                # If we've collected 5 batches, stop\n",
        "                if batch_idx >= 5:\n",
        "                    break\n",
        "\n",
        "                # If data is a tensor, convert to numpy\n",
        "                if isinstance(data, torch.Tensor):\n",
        "                    batch_data.append(data.numpy())\n",
        "\n",
        "            # If we have batch data, compute and print stats\n",
        "            if batch_data is not None and len(batch_data) > 0:\n",
        "                # Concatenate all batch data\n",
        "                all_data: np.ndarray = np.concatenate([b.reshape(b.shape[0], -1) for b in batch_data], axis=0)\n",
        "\n",
        "                # Show the length and shape of the data\n",
        "                print(f\"Batched Data Stats ({len(batch_data)} batches, {all_data.shape[0]} samples):\")\n",
        "\n",
        "                # Print mean and std\n",
        "                print(f\"  Mean: {np.mean(all_data):.6f}\")\n",
        "                print(f\"  Std:  {np.std(all_data):.6f}\")\n",
        "\n",
        "        print(\"\\n---------------------------- Statistics Complete ----------------------------\\n\")\n",
        "\n",
        "    def print_optimizer_loss_architecture(self, past_model: str = 'None') -> None:\n",
        "        \"\"\"\n",
        "        Print the chosen optimizer, loss function, and model architecture.\n",
        "\n",
        "        Parameters:\n",
        "            past_model (str): Path to a saved model to load before evaluation. Defaults to 'None'.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Optimizer, Loss Function, and Model Architecture ===============================\\n\")\n",
        "\n",
        "        # Load past model if provided\n",
        "        if past_model != 'None':\n",
        "            print(f\"Loading model from: {past_model}\")\n",
        "            self.load_state_dict(torch.load(past_model, map_location=self.get_device()), strict=False)\n",
        "            print(\"Model loaded successfully.\\n\")\n",
        "\n",
        "        # If we don't have optimizer or loss set, set them to defaults\n",
        "        if self.get_optim() is None or not isinstance(self.get_optim(), torch.optim.Optimizer) or self.get_loss() is None or not isinstance(self.get_loss(), nn.Module):\n",
        "            optimizer: type[torch.optim.Optimizer] = self.set_optim('Adam')\n",
        "            loss_function: nn.Module = self.set_loss('CrossEntropyLoss')\n",
        "\n",
        "        # Otherwise, get the current optimizer and loss\n",
        "        else:\n",
        "            optimizer: type[torch.optim.Optimizer] = self.get_optim()\n",
        "            loss_function: nn.Module = self.get_loss()\n",
        "\n",
        "\n",
        "        print(f\"Chosen Optimizer: {optimizer}\")\n",
        "        print(f\"Chosen Loss Function: {loss_function}\\n\")\n",
        "\n",
        "        # Print model architecture\n",
        "        print(f\"Model Architecture: {self}\")\n",
        "\n",
        "\n",
        "        print(\"\\n---------------------------- Optimizer, Loss Function, and Architecture Complete ----------------------------\\n\")\n",
        "\n",
        "\n",
        "    def create_confusion_matrix(self, past_model: str = 'None') -> None:\n",
        "        \"\"\"\n",
        "        Create and display a confusion matrix for the model's predictions on the test set.\n",
        "\n",
        "        Parameters:\n",
        "            past_model (str): Path to a saved model to load before evaluation. Defaults to 'None'.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Creating Confusion Matrix ===============================\\n\")\n",
        "\n",
        "        # Load past model and use it if provided\n",
        "        if past_model != 'None':\n",
        "            print(f\"Loading model from: {past_model}\")\n",
        "            self.load_state_dict(torch.load(past_model, map_location=self.get_device()), strict=False)\n",
        "            print(\"Model loaded successfully.\\n\")\n",
        "\n",
        "\n",
        "        # Generate predictions if not already done and if a past model is provided\n",
        "        if (self.get_testing_loader() is None or len(self.all_labels) == 0 or len(self.all_predictions) == 0) and past_model != 'None':\n",
        "            self.setup_data_loaders()\n",
        "\n",
        "            # Ensure the testing loader is available\n",
        "            if self.get_testing_loader() is None:\n",
        "                raise ValueError(\"Testing DataLoader is not available. Please call setup_data_loaders() first.\")\n",
        "\n",
        "            self.eval()  # Set model to evaluation mode\n",
        "\n",
        "            self.all_labels: list[int] = []\n",
        "            self.all_predictions: list[int] = []\n",
        "\n",
        "            # Generate predictions\n",
        "            with torch.no_grad() :\n",
        "\n",
        "                # Iterate through the testing data\n",
        "                for data, labels in tqdm(self.get_testing_loader(), desc=\"Generating Confusion Matrix\", unit=\"batch\"):\n",
        "\n",
        "                    # Move data to the appropriate device\n",
        "                    data: torch.Tensor = data.to(self.get_device())\n",
        "                    labels: torch.Tensor = labels.to(self.get_device())\n",
        "\n",
        "                    # Get model outputs\n",
        "                    outputs: torch.Tensor = self(data)\n",
        "\n",
        "                    # Get predicted classes\n",
        "                    _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "                    # Store true labels and predictions\n",
        "                    self.all_labels.extend(labels.cpu().numpy())\n",
        "                    self.all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm: np.ndarray = confusion_matrix(self.all_labels, self.all_predictions)\n",
        "\n",
        "        # Create figure with two subplots side by side\n",
        "        _, (ax_counts, ax_percentage) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "        # Plot raw counts confusion matrix\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=self.get_classes(), yticklabels=self.get_classes(), ax=ax_counts)\n",
        "        ax_counts.set_xlabel('Predicted Label')\n",
        "        ax_counts.set_ylabel('True Label')\n",
        "        ax_counts.set_title('Confusion Matrix (Counts)', fontsize=18, fontweight='bold')\n",
        "\n",
        "        # Create percentage-based confusion matrix\n",
        "        cm_percentage: np.ndarray = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        # Plot percentage-based confusion matrix\n",
        "        sns.heatmap(cm_percentage, annot=True, fmt='.2%', cmap='Greens',\n",
        "                    xticklabels=self.get_classes(), yticklabels=self.get_classes(), ax=ax_percentage)\n",
        "        ax_percentage.set_xlabel('Predicted Label')\n",
        "        ax_percentage.set_ylabel('True Label')\n",
        "        ax_percentage.set_title('Confusion Matrix (Percentage)', fontsize=18, fontweight='bold')\n",
        "\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(left=0.1) # Add extra margin on the left to prevent labels from being cut off\n",
        "        plt.show()\n",
        "\n",
        "        print (\"\\n---------------------------- Confusion Matrix Creation Complete ----------------------------\\n\")\n",
        "\n",
        "\n",
        "    def create_classification_report(self, past_model: str = 'None') -> None:\n",
        "        \"\"\"\n",
        "        Create and display a classification report for the model's predictions on the test set.\n",
        "\n",
        "        Parameters:\n",
        "            past_model (str): Path to a saved model to load before evaluation. Defaults to 'None'.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Creating Classification Report ===============================\\n\")\n",
        "\n",
        "        # Load past model if provided\n",
        "        if past_model != 'None':\n",
        "            print(f\"Loading model from: {past_model}\")\n",
        "            self.load_state_dict(torch.load(past_model, map_location=self.get_device()), strict=False)\n",
        "            print(\"Model loaded successfully.\\n\")\n",
        "\n",
        "        # Check if predictions are already generated and generate them if not\n",
        "        if (self.get_testing_loader() is None or len(self.all_labels) == 0 or len(self.all_predictions) == 0) and past_model != 'None':\n",
        "\n",
        "            # Generate predictions if not already done\n",
        "            self.setup_data_loaders()\n",
        "\n",
        "            # Ensure the testing loader is available\n",
        "            if self.get_testing_loader() is None:\n",
        "                raise ValueError(\"Testing DataLoader is not available. Please call setup_data_loaders() first.\")\n",
        "\n",
        "            self.eval()  # Set model to evaluation mode\n",
        "\n",
        "            # Set up lists to store true labels and predictions\n",
        "            self.all_labels: list[int] = []\n",
        "            self.all_predictions: list[int] = []\n",
        "\n",
        "            # Generate predictions\n",
        "            with torch.no_grad():\n",
        "\n",
        "                # For each batch in the testing loader\n",
        "                for data, labels in tqdm(self.get_testing_loader(), desc=\"Generating Classification Report\", unit=\"batch\"):\n",
        "\n",
        "                    # Move data to the appropriate device\n",
        "                    data: torch.Tensor = data.to(self.get_device())\n",
        "                    labels: torch.Tensor = labels.to(self.get_device())\n",
        "\n",
        "                    # Get model outputs and predicted classes\n",
        "                    outputs: torch.Tensor = self(data)\n",
        "                    _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "                    # Store true labels and predictions\n",
        "                    self.all_labels.extend(labels.cpu().numpy())\n",
        "                    self.all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "        # Generate classification report\n",
        "        report: str | Dict[str, float] = classification_report(self.all_labels, self.all_predictions, target_names=self.get_classes())\n",
        "        print(\"Classification Report:\\n\")\n",
        "        print(report)\n",
        "\n",
        "        # Make classification report into matplotlib table\n",
        "        report_dict: str | Dict[str, float] = classification_report(self.all_labels, self.all_predictions, target_names=self.get_classes(), output_dict=True)\n",
        "        report_df: pd.DataFrame = pd.DataFrame(report_dict).transpose()\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        plt.axis('off')\n",
        "        # Create table with formatted font sizes and weights\n",
        "        table = plt.table(cellText=np.round(report_df.values, 2), colLabels=report_df.columns, rowLabels=report_df.index, loc='center')\n",
        "        table.scale(1.1, 1.1)\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(14)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        print (\"\\n---------------------------- Classification Report Creation Complete ----------------------------\\n\")\n",
        "\n",
        "\n",
        "    def sns_scatter_plot(self, past_model: str = 'None') -> None:\n",
        "        \"\"\"\n",
        "        Create and display a seaborn scatter plot using t-SNE for the model's predictions on the test set.\n",
        "\n",
        "        Parameters:\n",
        "            past_model (str): Path to a saved model to load before evaluation. Defaults to 'None'.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Creating t-SNE Scatter Plot ===============================\\n\")\n",
        "\n",
        "        # Load past model if provided\n",
        "        if past_model != 'None':\n",
        "            print(f\"Loading model from: {past_model}\")\n",
        "            self.load_state_dict(torch.load(past_model, map_location=self.get_device()), strict=False)\n",
        "            print(\"Model loaded successfully.\\n\")\n",
        "\n",
        "        # Check if testing loader is available\n",
        "        if self.get_testing_loader() is None:\n",
        "            self.setup_data_loaders()\n",
        "\n",
        "            # If not, raise error\n",
        "            if self.get_testing_loader() is None:\n",
        "                self.setup_data_loaders()\n",
        "                raise ValueError(\"Testing DataLoader is not available. Please call setup_data_loaders() first.\")\n",
        "\n",
        "        # Start evaluation of model\n",
        "        self.eval()  # Set model to evaluation mode\n",
        "\n",
        "        # Set up separate lists to store batches of features and labels\n",
        "        features_list: list = []\n",
        "        labels_list: list = []\n",
        "\n",
        "\n",
        "        # Generate features and calculate accuracy\n",
        "        with torch.no_grad():\n",
        "            # Iterates through data\n",
        "            for samples, labels in tqdm(self.get_testing_loader(), desc=\"Generating Features for t-SNE Plot\", unit=\"batch\"):\n",
        "\n",
        "                # Move data to the appropriate device\n",
        "                samples: torch.Tensor = samples.to(self.get_device())\n",
        "                labels: torch.Tensor = labels.to(self.get_device())\n",
        "\n",
        "                # Forward pass to calculate accuracy\n",
        "                outputs: torch.Tensor = self(samples)\n",
        "\n",
        "                # Extract features using the model's feature extractor\n",
        "                features: torch.Tensor = self.extract_features(samples)\n",
        "\n",
        "                # Store features and labels (move to CPU)\n",
        "                labels_list.extend(labels.cpu().numpy())\n",
        "                features_list.extend(features.cpu().numpy())\n",
        "\n",
        "\n",
        "        # Concatenate all feature outputs and labels\n",
        "        X_output: np.ndarray = np.concatenate(features_list)\n",
        "        y_output: np.ndarray = np.concatenate(labels_list)\n",
        "\n",
        "        print(f\"Feature shape: {X_output.shape}\")\n",
        "        print(f\"Applying t-SNE to reduce {X_output.shape[1]} dimensions to 2D...\")\n",
        "\n",
        "        # Initialize t-SNE\n",
        "        tsne: TSNE = TSNE(n_components=2, perplexity=30, random_state=42, init='pca')\n",
        "\n",
        "        # Fit and transform the feature outputs\n",
        "        X_embedded: np.ndarray = tsne.fit_transform(X_output)\n",
        "\n",
        "        # Create the plot\n",
        "        plt.figure(figsize=(10, 8))\n",
        "\n",
        "        # Use seaborn's colorblind-friendly palette\n",
        "        scatter = sns.scatterplot(x=X_embedded[:, 0], y=X_embedded[:, 1], hue=y_output, palette='colorblind', s=60)\n",
        "\n",
        "        # Set plot titles and labels\n",
        "        plt.title(\"t-SNE Clustering of DeepFake Samples (Feature Space)\", fontsize=16, fontweight='bold')\n",
        "        plt.xlabel(\"t-SNE Component 1\", fontsize=12)\n",
        "        plt.ylabel(\"t-SNE Component 2\", fontsize=12)\n",
        "\n",
        "        # Update legend with class names\n",
        "        handles, _ = scatter.get_legend_handles_labels()\n",
        "        class_names: list[str] = self.get_classes()\n",
        "        plt.legend(handles, class_names, title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\n---------------------------- t-SNE Scatter Plot Creation Complete ----------------------------\\n\")\n",
        "\n",
        "\n",
        "    def plot_roc_curve_with_eer(self, past_model: str = 'None') -> None:\n",
        "        \"\"\"\n",
        "        Plot ROC curve for binary classification (gt vs deepfake) and compute Equal Error Rate (EER).\n",
        "        Combines all 6 deepfake classes into one 'deepfake' category vs ground truth 'real' category.\n",
        "\n",
        "        Parameters:\n",
        "            past_model (str): Path to a saved model to load before evaluation. Defaults to 'None'.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n=============================== Plotting ROC Curve with EER ===============================\\n\")\n",
        "\n",
        "        # Load past model if specified\n",
        "        if past_model != 'None':\n",
        "            print(f\"Loading model from: {past_model}\")\n",
        "            self.load_state_dict(torch.load(past_model, map_location=self.get_device()), strict=False)\n",
        "            print(\"Model loaded successfully.\\n\")\n",
        "\n",
        "        # Check if predictions are already generated and generate them if not (Note: we need probabilities here so we regenerate if needed)\n",
        "        if (self.get_testing_loader() is None or len(self.all_labels) == 0 or self.all_probabilities.size == 0) and past_model != 'None':\n",
        "            \n",
        "            # Generate predictions if not already done\n",
        "            self.setup_data_loaders()\n",
        "\n",
        "            # Ensure the testing loader is available\n",
        "            if self.get_testing_loader() is None:\n",
        "                raise ValueError(\"Testing DataLoader is not available. Please call setup_data_loaders() first.\")\n",
        "\n",
        "            self.eval()  # Set model to evaluation mode\n",
        "\n",
        "            # Set up lists to store true labels\n",
        "            self.all_labels: List[int] = []\n",
        "\n",
        "            # Store probability scores for ROC curve\n",
        "            all_probabilities: List[np.ndarray] = []\n",
        "\n",
        "            # Generate predictions\n",
        "            with torch.no_grad():\n",
        "\n",
        "                # For each batch in the testing loader\n",
        "                for data, labels in tqdm(self.get_testing_loader(), desc=\"Generating ROC Predictions\", unit=\"batch\"):\n",
        "\n",
        "                    # Move data to the appropriate device\n",
        "                    data: torch.Tensor = data.to(self.get_device())\n",
        "                    labels: torch.Tensor = labels.to(self.get_device())\n",
        "\n",
        "                    # Get model outputs and predicted classes\n",
        "                    outputs: torch.Tensor = self(data)\n",
        "\n",
        "                    # Apply softmax to get probabilities\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "                    # Store true labels, predictions, and probabilities\n",
        "                    self.all_labels.extend(labels.cpu().numpy())\n",
        "                    all_probabilities.append(probabilities.cpu().numpy())\n",
        "\n",
        "            # Concatenate all probabilities\n",
        "            self.all_probabilities = np.concatenate(all_probabilities, axis=0)\n",
        "\n",
        "        # Get the index for 'gt' class (ground truth/real)\n",
        "        gt_class_index: int | None = self.get_classes_index().get('gt')\n",
        "\n",
        "        # If it doesn't exist, raise error\n",
        "        if gt_class_index is None:\n",
        "            raise ValueError(\"Ground truth class 'gt' not found in classes.\")\n",
        "\n",
        "        # Prepare binary labels and deepfake probabilities\n",
        "        all_labels_binary: np.ndarray = np.array([])\n",
        "\n",
        "        # Convert multi-class labels to binary: gt (real) = 0, all others (deepfake) = 1\n",
        "        for label in self.all_labels:\n",
        "            if label == gt_class_index:\n",
        "                all_labels_binary = np.append(all_labels_binary, [0])\n",
        "            else:\n",
        "                all_labels_binary = np.append(all_labels_binary, [1])\n",
        "\n",
        "        # Get deepfake probability scores: P(deepfake) = 1 - P(gt)\n",
        "        deepfake_probabilities: np.ndarray = 1.0 - self.all_probabilities[:, gt_class_index]\n",
        "\n",
        "        # Set up variables for ROC computation\n",
        "        fpr: np.ndarray = np.ndarray([])\n",
        "        tpr: np.ndarray = np.ndarray([])\n",
        "        thresholds: np.ndarray = np.ndarray([])\n",
        "\n",
        "        # Compute ROC curve and AUC\n",
        "        fpr, tpr, thresholds = roc_curve(all_labels_binary, deepfake_probabilities)\n",
        "        roc_auc: float = float(auc(fpr, tpr))\n",
        "\n",
        "        # Compute EER and ERR threshold using the two-line approach (Thanks to Changjiang at https://yangcha.github.io/EER-ROC/)!\n",
        "        eer: tuple = (brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.))\n",
        "        eer_threshold: float = float(interp1d(fpr, thresholds)(eer))\n",
        "\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
        "        plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
        "        plt.title('ROC Curve: Real vs Deepfake Classification', fontsize=18, fontweight='bold')\n",
        "        plt.legend(loc=\"lower right\", fontsize=12)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Print ROC and EER statistics\n",
        "        print(f\"ROC Curve Statistics:\")\n",
        "        print(f\"--------------------------------------------\")\n",
        "        print(f\"  Area Under Curve (AUC): {roc_auc:.4f}\")\n",
        "        print(f\"  Equal Error Rate (EER): {eer:.4f} ({eer*100:.2f}%)\")\n",
        "        print(f\"  EER Threshold: {eer_threshold:.4f}\")\n",
        "        print(f\"--------------------------------------------\")\n",
        "\n",
        "        print(\"\\n---------------------------- ROC Curve with EER Complete ----------------------------\\n\")\n",
        "\n",
        "\n",
        "    def save_model(self, save_path: str = '/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V10.pth') -> None:\n",
        "        \"\"\"\n",
        "        Save the trained model to disk or Google Drive.\n",
        "\n",
        "        Parameters:\n",
        "            save_path (str): Path where the model should be saved.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\n=============================== Saving Model ===============================\\n\")\n",
        "\n",
        "        # Save the model state dictionary\n",
        "        torch.save(self.state_dict(), save_path)\n",
        "        print(f\"Model saved successfully to: {save_path}\")\n",
        "\n",
        "        print(\"\\n---------------------------- Model Save Complete ----------------------------\\n\")\n",
        "\n",
        "# For testing\n",
        "# if __name__ == \"__main__\":\n",
        "#     detector = DeepFakeDetectorGraphsAndStats(directory='/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/LibriSeVoc', file_extension='.wav', loss='CrossEntropyLoss', optim='Adam', DL_type='RNN')\n",
        "#     detector.set_batch_size(16) # Make it 16 samples per batch\n",
        "#     detector.set_learning_rate(0.001) # Set learning rate to 0.001\n",
        "#     detector.setup_data_loaders()\n",
        "#     detector.plot_class_counts()\n",
        "\n",
        "#     detector.mean_and_std_stats()\n",
        "#     detector.test_batch_equality(8)\n",
        "#     detector.plot_random_mfcc_samples(samples=2) # Plot 2 random MFCC samples per class\n",
        "\n",
        "#     detector.print_optimizer_loss_architecture('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')\n",
        "#     detector.sns_scatter_plot('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')\n",
        "#     detector.create_confusion_matrix('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')\n",
        "#     detector.create_classification_report('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')\n",
        "#     detector.plot_roc_curve_with_eer('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9fdf4d0614844da4aa76f5f9a740a648",
            "372500a941a54048ad32bca0acfff0af",
            "44be0e478b0c4a77925fbff9324c794e",
            "fc46f8f811a84b8899000a364940dab3",
            "e3615020852143a1b0b438179510e6a2",
            "19c439d07fa743b09bfc48ffb224960a",
            "ba9cef4ebf9648e6aaa96dafa28cccf1",
            "d7807bc768334fa0b6d53e744096bd2f",
            "0bb6e82cd7e446d1974a340fe06655d9",
            "4d6d2ed705c94661891f9907d36d199a",
            "5fc8b0ac423d45329bb789eaeac3296e"
          ]
        },
        "id": "cjcBiyMLBqtX",
        "outputId": "89662a82-33ed-4913-ea53-e591d51cea8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " =============================== Device Setup =============================== \n",
            "\n",
            "Using device: cpu\n",
            "CUDA not available, using CPU.\n",
            "\n",
            " ----------------------------- Setup Complete ------------------------------ \n",
            "\n",
            " \n",
            "=============================== Creating Classes, Class Counts, and Class Indices =============================== \n",
            "\n",
            " Classes found:  ['diffwave', 'gt', 'melgan', 'parallel_wave_gan', 'wavegrad', 'wavenet', 'wavernn']\n",
            " Class counts:  {'diffwave': 13201, 'gt': 13201, 'melgan': 13201, 'parallel_wave_gan': 13201, 'wavegrad': 13201, 'wavenet': 13201, 'wavernn': 13201}\n",
            " Class indices:  {'diffwave': 0, 'gt': 1, 'melgan': 2, 'parallel_wave_gan': 3, 'wavegrad': 4, 'wavenet': 5, 'wavernn': 6}\n",
            " \n",
            "----------------------------- Creation of Classes, Class Counts, and Class Indices Complete ------------------------------ \n",
            "\n",
            " \n",
            "=============================== Setting up File Dictionary =============================== \n",
            "\n",
            "\n",
            " Class diffwave: Files: ['1040_133433_000075_000002_gen.wav', '1040_133433_000138_000001_gen.wav', '1069_133699_000033_000000_gen.wav', '1088_129236_000007_000012_gen.wav', '1088_129236_000009_000002_gen.wav', '1088_129236_000026_000004_gen.wav', '1088_129236_000026_000009_gen.wav', '1088_129236_000027_000000_gen.wav', '1088_134315_000056_000003_gen.wav', '1088_134315_000095_000000_gen.wav', '1098_133695_000031_000002_gen.wav', '1116_132851_000045_000000_gen.wav', '1116_137572_000001_000001_gen.wav', '1116_137572_000003_000000_gen.wav', '1116_137572_000016_000003_gen.wav', '1116_137572_000038_000000_gen.wav', '1116_137572_000042_000001_gen.wav', '1183_133255_000050_000000_gen.wav', '1183_133256_000022_000001_gen.wav', '1183_133256_000042_000000_gen.wav', '1235_135884_000004_000004_gen.wav', '1246_124548_000007_000004_gen.wav', '1246_124548_000013_000004_gen.wav', '1246_124548_000027_000002_gen.wav', '1246_135815_000005_000003_gen.wav', '1246_135815_000010_000000_gen.wav', '1246_135815_000015_000000_gen.wav', '1263_138246_000018_000000_gen.wav', '1263_138246_000031_000000_gen.wav', '1263_139804_000005_000004_gen.wav', '1263_139804_000015_000002_gen.wav', '1263_139804_000030_000002_gen.wav', '1263_141777_000015_000000_gen.wav', '1355_39947_000009_000005_gen.wav', '1355_39947_000012_000001_gen.wav', '1355_39947_000017_000002_gen.wav', '1355_39947_000018_000000_gen.wav', '1355_39947_000018_000003_gen.wav', '1355_39947_000019_000007_gen.wav', '1355_39947_000020_000007_gen.wav', '1355_39947_000022_000002_gen.wav', '1355_39947_000023_000003_gen.wav', '1363_139304_000011_000001_gen.wav', '1502_122619_000003_000003_gen.wav', '1553_140047_000004_000000_gen.wav', '1553_140047_000006_000001_gen.wav', '1553_140048_000059_000002_gen.wav', '1624_142933_000002_000000_gen.wav', '1737_142397_000030_000003_gen.wav', '1737_148989_000005_000001_gen.wav', '1743_142912_000016_000001_gen.wav', '1743_142912_000025_000002_gen.wav', '1743_142914_000008_000009_gen.wav', '1841_150351_000002_000000_gen.wav', '1841_150351_000010_000003_gen.wav', '1841_159771_000070_000000_gen.wav', '1867_154071_000030_000001_gen.wav', '1867_154075_000080_000002_gen.wav', '1926_147979_000005_000001_gen.wav', '1926_147987_000004_000005_gen.wav', '1963_142776_000013_000003_gen.wav', '1963_142776_000041_000001_gen.wav', '196_122152_000008_000000_gen.wav', '196_122152_000009_000001_gen.wav', '196_122159_000001_000007_gen.wav', '1970_26100_000057_000000_gen.wav', '198_209_000019_000003_gen.wav', '200_124139_000015_000001_gen.wav', '200_124140_000036_000002_gen.wav', '200_126784_000034_000002_gen.wav', '200_126784_000039_000003_gen.wav', '200_126784_000073_000000_gen.wav', '200_126784_000074_000000_gen.wav', '200_126784_000091_000001_gen.wav', '201_122255_000050_000003_gen.wav', '2092_145706_000003_000000_gen.wav', '2092_145706_000012_000000_gen.wav', '2092_145706_000012_000004_gen.wav', '2092_145706_000019_000000_gen.wav', '2136_5140_000025_000000_gen.wav', '2136_5143_000002_000000_gen.wav', '2182_181173_000002_000001_gen.wav', '2182_181173_000008_000003_gen.wav', '2182_181173_000015_000000_gen.wav', '2182_181183_000002_000000_gen.wav', '2196_170151_000007_000005_gen.wav', '2196_170151_000009_000002_gen.wav', '2196_170379_000004_000001_gen.wav', '226_122538_000009_000001_gen.wav', '2289_152257_000013_000004_gen.wav', '2289_152258_000006_000002_gen.wav', '250_142276_000003_000002_gen.wav', '250_142276_000003_000008_gen.wav', '250_142276_000006_000008_gen.wav', '250_142276_000015_000012_gen.wav', '250_142286_000011_000007_gen.wav', '250_142286_000035_000002_gen.wav', '2514_149482_000005_000006_gen.wav', '2514_149482_000005_000008_gen.wav', '2514_149482_000024_000007_gen.wav', '2518_154826_000019_000000_gen.wav', '254_145458_000013_000001_gen.wav', '254_27760_000013_000006_gen.wav', '254_27760_000018_000001_gen.wav', '2691_156755_000009_000000_gen.wav', '26_495_000029_000001_gen.wav', '26_495_000035_000005_gen.wav', '26_496_000024_000000_gen.wav', '27_124992_000059_000001_gen.wav', '27_124992_000148_000001_gen.wav', '27_124992_000174_000001_gen.wav', '2836_5354_000006_000002_gen.wav', '2836_5355_000029_000001_gen.wav', '2836_5355_000061_000001_gen.wav', '2836_5355_000067_000000_gen.wav', '2836_5355_000095_000001_gen.wav', '2836_5355_000096_000000_gen.wav', '2843_152918_000000_000003_gen.wav', '2843_152918_000006_000002_gen.wav', '2843_152918_000006_000011_gen.wav', '2843_152918_000025_000003_gen.wav', '2893_139310_000038_000007_gen.wav', '2910_131096_000006_000002_gen.wav', '2910_131096_000009_000004_gen.wav', '2910_131096_000018_000000_gen.wav', '2910_131096_000020_000001_gen.wav', '2910_131096_000028_000001_gen.wav', '2910_131096_000036_000000_gen.wav', '298_126791_000040_000001_gen.wav', '302_123516_000031_000000_gen.wav', '302_123523_000031_000001_gen.wav', '3112_9555_000020_000007_gen.wav', '3235_11599_000012_000003_gen.wav', '3235_28433_000007_000003_gen.wav', '3235_28452_000015_000003_gen.wav', '3240_131231_000021_000002_gen.wav', '3240_131231_000041_000005_gen.wav', '3240_131231_000044_000000_gen.wav', '3242_67153_000016_000007_gen.wav', '3259_158083_000004_000001_gen.wav', '3259_158083_000076_000001_gen.wav', '3259_158083_000083_000010_gen.wav', '3259_158083_000128_000003_gen.wav', '32_21634_000004_000000_gen.wav', '32_4137_000006_000004_gen.wav', '3374_298025_000013_000011_gen.wav', '3374_298026_000004_000006_gen.wav', '3436_172162_000008_000000_gen.wav', '3436_172162_000011_000011_gen.wav', '3436_172162_000012_000000_gen.wav', '3436_172171_000005_000010_gen.wav', '3526_176653_000001_000004_gen.wav', '3526_176653_000002_000010_gen.wav', '3526_176653_000019_000001_gen.wav', '3526_176653_000034_000000_gen.wav', '3526_176653_000080_000004_gen.wav', '3607_29116_000033_000000_gen.wav', '3607_29116_000040_000001_gen.wav', '3664_178355_000018_000000_gen.wav', '3664_178355_000022_000001_gen.wav', '3664_178355_000023_000004_gen.wav', '3664_178366_000019_000001_gen.wav', '3664_178366_000020_000003_gen.wav', '3723_171631_000016_000001_gen.wav', '374_180298_000009_000003_gen.wav', '3830_12530_000039_000001_gen.wav', '3830_12530_000044_000000_gen.wav', '3830_12530_000054_000000_gen.wav', '3830_12531_000024_000001_gen.wav', '3830_12531_000041_000000_gen.wav', '3830_12535_000013_000001_gen.wav', '3857_180923_000021_000000_gen.wav', '3857_182315_000026_000002_gen.wav', '3857_182315_000032_000004_gen.wav', '3857_182317_000019_000001_gen.wav', '3879_173592_000033_000008_gen.wav', '3879_173592_000035_000004_gen.wav', '3879_174923_000019_000005_gen.wav', '3879_174923_000030_000001_gen.wav', '3879_174923_000032_000002_gen.wav', '4018_103416_000009_000002_gen.wav', '4051_11218_000007_000007_gen.wav', '4051_11218_000019_000000_gen.wav', '4051_11218_000035_000000_gen.wav', '405_130894_000085_000002_gen.wav', '405_130895_000003_000002_gen.wav', '405_130895_000020_000000_gen.wav', '405_130895_000069_000000_gen.wav', '40_121026_000052_000001_gen.wav', '40_121026_000190_000002_gen.wav', '40_121026_000227_000003_gen.wav', '40_121026_000235_000002_gen.wav', '40_222_000014_000000_gen.wav', '412_126975_000005_000001_gen.wav', '412_126975_000022_000000_gen.wav', '412_126975_000058_000001_gen.wav', '412_126975_000066_000002_gen.wav', '412_126975_000087_000004_gen.wav', '4137_11702_000005_000000_gen.wav', '4137_11702_000007_000000_gen.wav', '4137_11702_000015_000002_gen.wav', '4160_11550_000011_000002_gen.wav', '4160_11550_000045_000001_gen.wav', '4160_14187_000032_000000_gen.wav', '4195_17507_000070_000000_gen.wav', '426_122821_000030_000003_gen.wav', '4297_13006_000012_000004_gen.wav', '4406_16882_000024_000006_gen.wav', '4406_16883_000005_000000_gen.wav', '4406_16883_000016_000008_gen.wav', '4406_16883_000016_000013_gen.wav', '446_123501_000019_000002_gen.wav', '446_123501_000019_000003_gen.wav', '446_123501_000032_000000_gen.wav', '460_172357_000005_000000_gen.wav', '460_172357_000007_000000_gen.wav', '460_172359_000006_000000_gen.wav', '460_172359_000008_000000_gen.wav', '460_172359_000056_000003_gen.wav', '4640_19188_000021_000025_gen.wav', '4680_16026_000013_000000_gen.wav', '4680_16026_000048_000000_gen.wav', '4788_91208_000009_000004_gen.wav', '4788_94904_000008_000004_gen.wav', '4813_248638_000016_000002_gen.wav', '4813_248638_000021_000001_gen.wav', '4813_248641_000016_000003_gen.wav', '4830_25898_000006_000002_gen.wav', '5104_33406_000019_000004_gen.wav', '5104_33407_000034_000000_gen.wav', '5163_18515_000059_000000_gen.wav', '5163_39921_000050_000001_gen.wav', '5322_7678_000006_000014_gen.wav', '5322_7678_000006_000022_gen.wav', '5322_7678_000006_000026_gen.wav', '5322_7678_000006_000029_gen.wav', '5322_7679_000021_000001_gen.wav', '5339_14134_000018_000002_gen.wav', '5339_14134_000041_000002_gen.wav', '5339_14134_000070_000000_gen.wav', '5339_14134_000097_000002_gen.wav', '5390_24512_000004_000001_gen.wav', '5390_24512_000046_000003_gen.wav', '5393_19219_000015_000006_gen.wav', '5393_19219_000019_000005_gen.wav', '5393_19219_000047_000083_gen.wav', '5463_39173_000062_000002_gen.wav', '5514_19193_000008_000002_gen.wav', '5514_19193_000023_000000_gen.wav', '5561_39621_000071_000000_gen.wav', '5561_39621_000078_000000_gen.wav', '5561_41615_000018_000001_gen.wav', '5652_39938_000015_000004_gen.wav', '5678_43302_000061_000002_gen.wav', '5750_100289_000007_000001_gen.wav', '5750_100289_000017_000002_gen.wav', '5750_100289_000017_000004_gen.wav', '5750_100289_000038_000001_gen.wav', '5778_12761_000002_000000_gen.wav', '5778_12761_000015_000000_gen.wav', '5778_54535_000002_000002_gen.wav', '5778_54535_000010_000001_gen.wav', '5778_54535_000012_000001_gen.wav', '5778_54535_000012_000005_gen.wav', '5778_54535_000017_000005_gen.wav', '5808_54425_000026_000000_gen.wav', '5808_54425_000032_000000_gen.wav', '5808_54425_000049_000000_gen.wav', '5867_48852_000046_000000_gen.wav', '587_54108_000058_000000_gen.wav', '6019_3185_000012_000003_gen.wav', '6019_3185_000022_000007_gen.wav', '6019_3185_000024_000002_gen.wav', '6019_3185_000031_000007_gen.wav', '6064_56168_000016_000001_gen.wav', '6078_54007_000027_000000_gen.wav', '6078_54007_000050_000000_gen.wav', '6078_54013_000027_000001_gen.wav', '6078_54013_000059_000002_gen.wav', '6081_41997_000035_000000_gen.wav', '60_121082_000027_000000_gen.wav', '6147_34605_000009_000020_gen.wav', '6181_216552_000005_000001_gen.wav', '6181_216552_000015_000001_gen.wav', '6209_34599_000018_000000_gen.wav', '6209_34600_000010_000003_gen.wav', '6209_34601_000093_000001_gen.wav', '625_132112_000014_000015_gen.wav', '6272_70168_000037_000002_gen.wav', '6367_65536_000003_000000_gen.wav', '6367_65536_000006_000006_gen.wav', '6367_65536_000006_000011_gen.wav', '6367_65536_000007_000005_gen.wav', '6367_65536_000030_000000_gen.wav', '6367_65536_000039_000006_gen.wav', '6385_220959_000003_000005_gen.wav', '6385_34655_000023_000002_gen.wav', '6415_100596_000071_000000_gen.wav', '6415_111615_000021_000003_gen.wav', '6415_116629_000031_000000_gen.wav', '6415_116629_000036_000007_gen.wav', '6437_66172_000014_000001_gen.wav', '6437_66172_000021_000003_gen.wav', '6437_66173_000027_000001_gen.wav', '6437_66173_000029_000002_gen.wav', '6454_120342_000009_000000_gen.wav', '6454_120342_000015_000005_gen.wav', '6476_57446_000017_000001_gen.wav', '6476_57446_000062_000000_gen.wav', '6476_57446_000075_000000_gen.wav', '6476_96661_000015_000002_gen.wav', '6529_62554_000015_000000_gen.wav', '6529_62554_000016_000000_gen.wav', '6529_62554_000021_000000_gen.wav', '6529_62556_000019_000000_gen.wav', '6818_76332_000034_000002_gen.wav', '6836_61804_000031_000000_gen.wav', '6836_61804_000042_000000_gen.wav', '6848_252322_000049_000000_gen.wav', '6848_76049_000024_000003_gen.wav', '6848_76049_000024_000004_gen.wav', '6880_216547_000020_000002_gen.wav', '6880_216547_000035_000001_gen.wav', '696_93314_000061_000003_gen.wav', '7059_77897_000024_000002_gen.wav', '7059_77900_000017_000000_gen.wav', '7059_77900_000041_000001_gen.wav', '7059_88364_000015_000001_gen.wav', '7067_76048_000044_000001_gen.wav', '7078_271888_000006_000000_gen.wav', '7078_271888_000060_000002_gen.wav', '7078_271888_000063_000001_gen.wav', '7078_271888_000065_000000_gen.wav', '7113_86041_000029_000000_gen.wav', '7178_34644_000056_000001_gen.wav', '7178_34645_000011_000000_gen.wav', '7178_34645_000012_000019_gen.wav', '7190_90542_000002_000001_gen.wav', '7190_90543_000005_000000_gen.wav', '7278_91083_000025_000004_gen.wav', '7302_86814_000004_000002_gen.wav', '7302_86814_000054_000000_gen.wav', '7367_86737_000049_000000_gen.wav', '7367_86737_000050_000001_gen.wav', '7367_86737_000062_000001_gen.wav', '7367_86737_000074_000000_gen.wav', '7367_86737_000118_000012_gen.wav', '7367_86737_000119_000005_gen.wav', '7367_86737_000119_000010_gen.wav', '7367_86737_000132_000001_gen.wav', '7402_59171_000010_000010_gen.wav', '7402_59171_000011_000005_gen.wav', '7402_90848_000001_000000_gen.wav', '7402_90848_000006_000001_gen.wav', '7402_90848_000007_000002_gen.wav', '7402_90848_000041_000000_gen.wav', '7402_90848_000048_000001_gen.wav', '7447_91186_000007_000000_gen.wav', '7447_91186_000015_000004_gen.wav', '7447_91186_000018_000006_gen.wav', '7447_91186_000018_000007_gen.wav', '7505_258958_000031_000008_gen.wav', '7505_258958_000033_000004_gen.wav', '7505_83618_000006_000003_gen.wav', '7505_83618_000009_000002_gen.wav', '7505_83618_000015_000005_gen.wav', '7511_102420_000013_000000_gen.wav', '7511_102420_000013_000001_gen.wav', '7517_100442_000004_000002_gen.wav', '7517_100442_000006_000002_gen.wav', '7780_274562_000008_000001_gen.wav', '7780_274562_000011_000003_gen.wav', '7794_295947_000007_000000_gen.wav', '7794_295948_000009_000000_gen.wav', '7794_295955_000002_000001_gen.wav', '7794_295955_000004_000007_gen.wav', '7800_283492_000042_000001_gen.wav', '7800_283492_000052_000000_gen.wav', '7800_283493_000067_000000_gen.wav', '7859_102519_000025_000000_gen.wav', '7859_102521_000013_000002_gen.wav', '78_368_000003_000001_gen.wav', '78_368_000007_000000_gen.wav', '78_369_000005_000000_gen.wav', '78_369_000013_000011_gen.wav', '78_369_000017_000001_gen.wav', '78_369_000021_000000_gen.wav', '8014_112602_000001_000001_gen.wav', '8014_280382_000005_000001_gen.wav', '8051_118101_000010_000000_gen.wav', '8051_118101_000012_000004_gen.wav', '8051_295385_000016_000002_gen.wav', '8088_284756_000001_000003_gen.wav', '8088_284756_000005_000001_gen.wav', '8088_284756_000107_000001_gen.wav', '8088_284756_000109_000002_gen.wav', '8095_274348_000010_000001_gen.wav', '8098_278252_000017_000000_gen.wav', '8098_278252_000030_000007_gen.wav', '8098_278278_000019_000003_gen.wav', '8108_274318_000017_000000_gen.wav', '8108_274318_000021_000004_gen.wav', '8108_280354_000015_000000_gen.wav', '8108_280359_000002_000000_gen.wav', '8108_280359_000010_000003_gen.wav', '8123_275193_000004_000005_gen.wav', '8123_275193_000016_000000_gen.wav', '8123_275209_000012_000002_gen.wav', '8123_275209_000021_000000_gen.wav', '8123_275209_000036_000001_gen.wav', '8123_275216_000022_000001_gen.wav', '8123_275216_000039_000002_gen.wav', '8226_274369_000035_000001_gen.wav', '8226_274371_000025_000003_gen.wav', '8238_274553_000008_000008_gen.wav', '8238_274553_000009_000002_gen.wav', '8238_274553_000027_000002_gen.wav', '8238_274553_000028_000005_gen.wav', '8238_283452_000022_000010_gen.wav', '8238_283452_000025_000001_gen.wav', '8238_283452_000026_000009_gen.wav', '8238_283452_000028_000001_gen.wav', '8312_279790_000002_000004_gen.wav', '8312_279790_000002_000008_gen.wav', '8312_279790_000005_000000_gen.wav', '8312_279791_000005_000001_gen.wav', '8312_279791_000014_000000_gen.wav', '8312_279791_000014_000002_gen.wav', '8312_279791_000019_000001_gen.wav', '8312_279791_000032_000000_gen.wav', '8312_279791_000038_000004_gen.wav', '831_130739_000009_000002_gen.wav', '831_130746_000036_000002_gen.wav', '831_130746_000038_000007_gen.wav', '8324_286682_000006_000003_gen.wav', '8324_286682_000020_000002_gen.wav', '8324_286683_000008_000003_gen.wav', '8468_286673_000019_000000_gen.wav', '8468_286673_000020_000001_gen.wav', '8468_286673_000024_000001_gen.wav', '8468_295198_000024_000003_gen.wav', '8580_287363_000004_000000_gen.wav', '8580_287363_000004_000001_gen.wav', '8580_287363_000024_000001_gen.wav', '8580_287363_000037_000000_gen.wav', '8580_287363_000040_000000_gen.wav', '8629_261139_000033_000006_gen.wav', '8629_261139_000039_000001_gen.wav', '8630_305212_000006_000007_gen.wav', '8630_305212_000013_000001_gen.wav', '8630_305213_000010_000003_gen.wav', '8630_305213_000010_000006_gen.wav', '8630_305213_000012_000004_gen.wav', '8630_305213_000012_000006_gen.wav', '8630_305213_000026_000000_gen.wav', '8747_293952_000003_000005_gen.wav', '8747_293952_000081_000001_gen.wav', '8747_293952_000088_000002_gen.wav', '8747_293952_000097_000003_gen.wav', '8797_294123_000004_000005_gen.wav', '87_121553_000018_000000_gen.wav', '87_121553_000081_000000_gen.wav', '87_121553_000116_000000_gen.wav', '87_121553_000186_000000_gen.wav', '87_121553_000246_000000_gen.wav', '87_121553_000247_000000_gen.wav', '8838_298545_000016_000003_gen.wav', '8838_298545_000023_000000_gen.wav', '8838_298545_000051_000001_gen.wav', '8838_298546_000045_000001_gen.wav', '887_123289_000014_000000_gen.wav', '887_123289_000038_000000_gen.wav', '887_123289_000041_000000_gen.wav', '887_123290_000007_000000_gen.wav', '8975_270782_000019_000009_gen.wav']\n",
            "\n",
            "\n",
            "\n",
            " Class gt: Files: ['1040_133433_000129_000000.wav', '1069_133699_000035_000001.wav', '1069_133699_000051_000000.wav', '1088_129236_000019_000005.wav', '1088_129236_000022_000000.wav', '1088_134315_000019_000002.wav', '1088_134318_000002_000006.wav', '1098_133695_000003_000009.wav', '1098_133695_000006_000018.wav', '1098_133695_000013_000008.wav', '1116_132847_000071_000000.wav', '1116_132851_000029_000000.wav', '1116_137572_000000_000002.wav', '1183_124566_000011_000001.wav', '1183_133255_000065_000001.wav', '118_47824_000025_000000.wav', '1246_124548_000007_000005.wav', '1246_124548_000008_000002.wav', '1246_124548_000013_000004.wav', '1246_124550_000012_000001.wav', '1246_124550_000017_000000.wav', '1246_135815_000005_000000.wav', '1246_135815_000008_000003.wav', '1246_135815_000017_000003.wav', '1246_135815_000026_000001.wav', '125_121124_000027_000001.wav', '125_121124_000098_000000.wav', '1263_138246_000009_000000.wav', '1263_141777_000037_000001.wav', '1334_135589_000007_000000.wav', '1334_135589_000014_000001.wav', '1334_135589_000018_000000.wav', '1334_135589_000019_000001.wav', '1334_135589_000062_000004.wav', '1334_135589_000069_000000.wav', '1334_135589_000073_000000.wav', '1355_39947_000003_000006.wav', '1355_39947_000005_000017.wav', '1355_39947_000010_000001.wav', '1355_39947_000016_000004.wav', '1355_39947_000016_000007.wav', '1355_39947_000019_000006.wav', '1355_39947_000019_000008.wav', '1355_39947_000022_000006.wav', '1355_39947_000024_000008.wav', '1355_39947_000024_000011.wav', '1363_139304_000009_000006.wav', '1363_139304_000014_000000.wav', '1363_139304_000017_000000.wav', '1363_139304_000017_000001.wav', '1363_139304_000017_000002.wav', '1447_17506_000051_000000.wav', '1502_122619_000010_000001.wav', '1502_122619_000013_000000.wav', '1553_140048_000057_000000.wav', '1553_140048_000059_000001.wav', '1578_140045_000012_000001.wav', '1594_135914_000016_000003.wav', '1594_135914_000032_000005.wav', '1624_168623_000003_000004.wav', '1624_168623_000024_000000.wav', '1737_146161_000005_000000.wav', '1743_142912_000024_000001.wav', '1743_142913_000013_000000.wav', '1743_142914_000003_000002.wav', '1743_142914_000019_000002.wav', '1743_142914_000023_000005.wav', '1841_150351_000010_000001.wav', '1841_159771_000021_000001.wav', '1841_159771_000041_000002.wav', '1841_159771_000044_000000.wav', '1841_179183_000022_000002.wav', '1867_148436_000012_000000.wav', '1867_148436_000072_000001.wav', '1963_142393_000007_000004.wav', '1963_142393_000012_000001.wav', '196_122150_000003_000002.wav', '196_122150_000006_000004.wav', '196_122159_000002_000002.wav', '196_122159_000014_000025.wav', '1970_28415_000008_000003.wav', '1970_28415_000067_000000.wav', '198_209_000012_000001.wav', '1992_141719_000016_000013.wav', '2002_139469_000017_000009.wav', '2002_139469_000019_000007.wav', '2002_139469_000019_000009.wav', '200_124139_000040_000000.wav', '200_124140_000013_000001.wav', '200_126784_000039_000003.wav', '200_126784_000086_000000.wav', '201_122255_000015_000000.wav', '201_122255_000019_000000.wav', '201_122255_000049_000000.wav', '2092_145706_000004_000001.wav', '2092_145706_000025_000002.wav', '2092_145706_000046_000000.wav', '2092_145706_000055_000000.wav', '2092_145706_000055_000001.wav', '2092_145709_000006_000002.wav', '2092_145709_000009_000001.wav', '2092_145709_000010_000002.wav', '2092_145709_000015_000001.wav', '2136_5143_000011_000007.wav', '2136_5147_000021_000000.wav', '2136_5147_000030_000001.wav', '2136_5147_000037_000000.wav', '2182_181183_000002_000002.wav', '2182_181183_000002_000005.wav', '2182_181183_000044_000000.wav', '2196_170151_000002_000001.wav', '2196_170151_000010_000000.wav', '2196_170379_000008_000004.wav', '2196_170379_000011_000000.wav', '2196_170379_000016_000001.wav', '226_122538_000012_000001.wav', '2289_152253_000019_000000.wav', '2289_152254_000029_000001.wav', '2289_152257_000015_000000.wav', '2289_152258_000005_000000.wav', '2289_152258_000015_000001.wav', '2416_152139_000061_000002.wav', '2416_152139_000089_000005.wav', '2436_2481_000018_000002.wav', '250_140277_000004_000004.wav', '250_142276_000003_000011.wav', '250_142276_000013_000001.wav', '250_142276_000015_000003.wav', '250_142286_000003_000004.wav', '2514_149482_000004_000001.wav', '2514_149482_000010_000000.wav', '2514_149482_000025_000009.wav', '254_145458_000012_000003.wav', '254_27760_000004_000000.wav', '254_27760_000008_000000.wav', '254_27760_000020_000001.wav', '254_27760_000020_000003.wav', '2691_156755_000024_000000.wav', '26_495_000059_000004.wav', '26_496_000004_000000.wav', '26_496_000019_000004.wav', '26_496_000021_000005.wav', '26_496_000022_000008.wav', '26_496_000024_000000.wav', '27_123349_000006_000006.wav', '27_124992_000000_000002.wav', '2817_142371_000039_000000.wav', '2836_5354_000008_000000.wav', '2836_5355_000018_000000.wav', '2836_5355_000051_000000.wav', '2836_5355_000089_000000.wav', '2843_152918_000010_000001.wav', '2843_152918_000025_000005.wav', '2843_152918_000026_000001.wav', '2893_139322_000003_000007.wav', '2893_139322_000005_000005.wav', '2893_139322_000008_000001.wav', '2910_131096_000026_000001.wav', '2910_131096_000026_000003.wav', '2910_131096_000039_000000.wav', '2911_12359_000008_000001.wav', '2911_15045_000002_000001.wav', '298_126791_000081_000000.wav', '302_123504_000019_000002.wav', '302_123516_000025_000000.wav', '302_123516_000028_000000.wav', '3112_9554_000002_000005.wav', '3112_9555_000005_000002.wav', '3112_9555_000017_000001.wav', '3112_9555_000021_000001.wav', '3112_9555_000021_000013.wav', '3168_173564_000014_000004.wav', '3235_11599_000009_000003.wav', '3235_11599_000013_000001.wav', '3235_28433_000003_000001.wav', '3235_28433_000003_000003.wav', '3235_28433_000020_000000.wav', '3235_28452_000016_000001.wav', '3240_131231_000018_000005.wav', '3240_131231_000020_000000.wav', '3240_131231_000070_000000.wav', '3240_131231_000076_000001.wav', '3240_131231_000080_000000.wav', '3240_131232_000008_000000.wav', '3240_131232_000043_000000.wav', '3240_131232_000075_000000.wav', '3242_67153_000015_000000.wav', '3242_67153_000016_000007.wav', '3242_67168_000005_000000.wav', '3242_67168_000010_000000.wav', '3259_158083_000013_000001.wav', '3259_158083_000028_000002.wav', '3259_158083_000083_000010.wav', '32_21631_000014_000000.wav', '3374_298026_000004_000000.wav', '3374_298026_000004_000007.wav', '3374_298032_000004_000004.wav', '3436_172162_000011_000002.wav', '3436_172162_000012_000002.wav', '3436_172162_000014_000009.wav', '3436_172171_000005_000003.wav', '3436_172171_000006_000008.wav', '3436_172171_000010_000001.wav', '3526_175658_000011_000009.wav', '3526_176651_000013_000003.wav', '3664_11714_000018_000000.wav', '3664_11714_000037_000000.wav', '3664_178355_000019_000002.wav', '3664_178355_000021_000001.wav', '3664_178366_000008_000001.wav', '3664_178366_000015_000000.wav', '3664_178366_000016_000001.wav', '3699_175950_000008_000000.wav', '3699_47246_000006_000002.wav', '374_180298_000013_000001.wav', '374_180298_000027_000000.wav', '374_180299_000020_000000.wav', '374_180299_000024_000000.wav', '374_180299_000033_000003.wav', '3830_12529_000014_000000.wav', '3830_12529_000032_000000.wav', '3830_12529_000044_000000.wav', '3830_12530_000012_000000.wav', '3830_12531_000024_000000.wav', '3830_12531_000030_000003.wav', '3830_12535_000003_000002.wav', '3857_180923_000013_000000.wav', '3857_180923_000025_000000.wav', '3857_182317_000007_000004.wav', '3857_182317_000010_000002.wav', '3857_182317_000012_000000.wav', '3857_182317_000012_000001.wav', '3879_173592_000012_000002.wav', '3879_173592_000018_000003.wav', '3879_173592_000032_000000.wav', '3879_173592_000033_000003.wav', '3879_174923_000014_000000.wav', '3879_174923_000019_000001.wav', '3879_174923_000019_000005.wav', '3982_178459_000028_000002.wav', '3982_178459_000032_000000.wav', '3982_178459_000040_000000.wav', '3982_178459_000052_000001.wav', '3982_178459_000056_000023.wav', '3982_182255_000018_000000.wav', '3982_182255_000049_000006.wav', '3983_5331_000045_000001.wav', '3983_5371_000007_000001.wav', '3983_5371_000062_000000.wav', '4018_103416_000067_000004.wav', '4018_107338_000013_000003.wav', '4051_10927_000012_000000.wav', '4051_10927_000029_000004.wav', '4051_11217_000004_000002.wav', '4051_11217_000005_000000.wav', '4051_11217_000007_000002.wav', '4051_11217_000008_000000.wav', '4051_11217_000023_000004.wav', '4051_11218_000000_000000.wav', '4051_11218_000030_000001.wav', '405_130894_000064_000001.wav', '405_130895_000067_000002.wav', '4088_158077_000060_000000.wav', '4088_158077_000103_000005.wav', '4088_158077_000111_000001.wav', '40_121026_000006_000000.wav', '40_121026_000008_000000.wav', '40_121026_000026_000000.wav', '40_121026_000184_000001.wav', '40_121026_000201_000001.wav', '40_121026_000212_000001.wav', '40_121026_000225_000003.wav', '40_121026_000227_000006.wav', '40_222_000011_000005.wav', '40_222_000011_000006.wav', '40_222_000027_000000.wav', '412_126975_000055_000001.wav', '412_126975_000056_000000.wav', '412_126975_000057_000002.wav', '412_126975_000080_000002.wav', '412_126975_000085_000004.wav', '4137_11701_000019_000000.wav', '4137_11701_000022_000002.wav', '4137_11701_000049_000000.wav', '4137_11702_000005_000000.wav', '4137_11702_000007_000000.wav', '4137_11702_000008_000001.wav', '4137_11702_000012_000001.wav', '4137_11702_000032_000000.wav', '4137_11702_000057_000001.wav', '4160_11549_000033_000007.wav', '4160_11549_000038_000001.wav', '4160_11550_000009_000003.wav', '4160_14187_000023_000000.wav', '4160_14187_000047_000007.wav', '4195_17507_000047_000000.wav', '4195_186236_000035_000003.wav', '4195_186238_000053_000003.wav', '4214_7146_000028_000012.wav', '4214_7146_000059_000001.wav', '4267_287369_000031_000000.wav', '4267_287369_000051_000002.wav', '4267_72637_000013_000002.wav', '4267_72637_000024_000007.wav', '4267_78186_000002_000002.wav', '4267_78186_000007_000014.wav', '4297_13006_000007_000002.wav', '4297_13006_000013_000000.wav', '4297_13006_000014_000004.wav', '4297_13006_000065_000000.wav', '4297_13006_000065_000003.wav', '4362_15663_000035_000000.wav', '4397_15668_000010_000000.wav', '4397_15668_000011_000000.wav', '4397_15678_000009_000003.wav', '4406_16882_000007_000008.wav', '4406_16882_000019_000004.wav', '4406_16882_000024_000012.wav', '4406_16883_000016_000007.wav', '4406_16883_000016_000009.wav', '4406_16883_000027_000000.wav', '446_123501_000015_000000.wav', '446_123502_000017_000001.wav', '460_172357_000004_000006.wav', '460_172357_000005_000002.wav', '460_172357_000007_000003.wav', '460_172359_000026_000004.wav', '460_172359_000064_000002.wav', '4640_19187_000037_000000.wav', '4640_19187_000043_000001.wav', '4680_16026_000062_000001.wav', '4680_16026_000135_000000.wav', '4680_16041_000005_000000.wav', '4788_91208_000010_000006.wav', '4788_91208_000012_000004.wav', '4788_94904_000004_000003.wav', '4788_94904_000005_000008.wav', '4788_94904_000008_000004.wav', '4788_94904_000008_000010.wav', '4813_248638_000020_000004.wav', '4813_248641_000009_000005.wav', '4813_248641_000021_000000.wav', '4830_25898_000030_000002.wav', '5049_25947_000018_000006.wav', '5104_33407_000016_000000.wav', '5163_18515_000005_000000.wav', '5163_18515_000030_000001.wav', '5163_39921_000026_000002.wav', '5322_7678_000006_000005.wav', '5322_7678_000006_000016.wav', '5322_7679_000002_000015.wav', '5322_7680_000060_000003.wav', '5339_14133_000017_000000.wav', '5339_14133_000018_000000.wav', '5339_14134_000031_000000.wav', '5339_14134_000039_000002.wav', '5339_14134_000058_000001.wav', '5390_24512_000046_000000.wav', '5390_24512_000049_000001.wav', '5393_19218_000005_000000.wav', '5393_19218_000044_000000.wav', '5393_19218_000045_000000.wav', '5393_19219_000009_000001.wav', '5393_19219_000015_000002.wav', '5393_19219_000015_000009.wav', '5393_19219_000053_000000.wav', '5456_62043_000028_000002.wav', '5456_62043_000032_000000.wav', '5514_19192_000013_000004.wav', '5561_41615_000002_000002.wav', '5561_41615_000024_000000.wav', '5652_19215_000026_000031.wav', '5678_43302_000044_000001.wav', '5703_47198_000012_000000.wav', '5703_47212_000021_000000.wav', '5750_100289_000002_000000.wav', '5750_100289_000028_000004.wav', '5778_12761_000005_000000.wav', '5778_54535_000007_000002.wav', '5778_54535_000016_000001.wav', '5789_57158_000055_000001.wav', '5808_54425_000024_000001.wav', '5808_54425_000024_000002.wav', '5808_54425_000032_000000.wav', '5867_48852_000024_000004.wav', '5867_48852_000072_000000.wav', '587_54108_000020_000000.wav', '587_54108_000057_000000.wav', '587_54108_000073_000000.wav', '587_54108_000073_000001.wav', '587_54108_000091_000000.wav', '6019_3185_000024_000003.wav', '6019_3185_000027_000005.wav', '6064_300880_000069_000001.wav', '6064_56165_000003_000004.wav', '6064_56165_000012_000000.wav', '6064_56165_000048_000000.wav', '6064_56168_000018_000001.wav', '6064_56168_000020_000000.wav', '6064_56168_000028_000000.wav', '6078_54007_000040_000001.wav', '6078_54007_000041_000004.wav', '6078_54013_000035_000000.wav', '6078_54013_000043_000000.wav', '6078_54013_000059_000002.wav', '6081_41997_000005_000001.wav', '6081_41997_000009_000000.wav', '6081_41998_000001_000000.wav', '6081_41998_000039_000000.wav', '6147_34605_000003_000000.wav', '6147_34605_000003_000007.wav', '6147_34607_000011_000010.wav', '6181_216552_000012_000004.wav', '6181_216552_000017_000000.wav', '6181_216552_000021_000000.wav', '6181_216552_000056_000000.wav', '6209_34599_000004_000000.wav', '6209_34599_000008_000003.wav', '6209_34599_000018_000000.wav', '6209_34600_000004_000000.wav', '6272_70168_000037_000002.wav', '6272_70168_000038_000001.wav', '6272_70171_000005_000003.wav', '6272_70171_000005_000007.wav', '6272_70191_000031_000001.wav', '6367_65536_000003_000000.wav', '6367_65536_000003_000002.wav', '6367_65536_000005_000003.wav', '6367_65536_000016_000000.wav', '6367_65536_000041_000004.wav', '6367_74004_000019_000002.wav', '6385_220959_000007_000004.wav', '6385_220959_000007_000006.wav', '6385_34655_000008_000000.wav', '6385_34669_000017_000008.wav', '6385_34669_000022_000001.wav', '6385_34669_000023_000007.wav', '6385_34669_000029_000000.wav', '6415_100596_000005_000000.wav', '6415_100596_000056_000000.wav', '6415_100596_000069_000000.wav', '6415_111615_000008_000006.wav', '6415_111615_000012_000005.wav', '6415_111615_000019_000009.wav', '6415_111615_000020_000000.wav', '6415_111615_000022_000002.wav', '6415_111615_000022_000003.wav', '6415_116629_000015_000003.wav', '6415_116629_000017_000003.wav', '6415_116629_000017_000012.wav', '6415_116629_000017_000015.wav', '6437_66172_000005_000000.wav', '6437_66172_000014_000001.wav', '6437_66173_000026_000000.wav', '6437_66173_000045_000001.wav', '6454_107462_000022_000000.wav', '6454_120342_000012_000001.wav', '6454_120342_000012_000003.wav', '6454_120342_000019_000000.wav', '6454_120342_000038_000002.wav', '6454_93938_000030_000000.wav', '6476_57446_000005_000000.wav', '6476_57446_000023_000000.wav', '6476_96661_000005_000003.wav', '6529_62554_000021_000000.wav', '6529_62554_000025_000001.wav', '6818_76332_000011_000002.wav', '6836_61803_000008_000000.wav', '6836_61804_000006_000000.wav', '6836_61804_000023_000000.wav', '6836_61804_000033_000000.wav', '6836_61804_000048_000000.wav', '6836_76549_000002_000005.wav', '6848_252322_000039_000003.wav', '6880_216547_000018_000000.wav', '6880_216547_000025_000001.wav', '6880_216547_000035_000000.wav', '6880_216547_000050_000005.wav', '6880_216547_000051_000001.wav', '6880_216547_000054_000002.wav', '696_92939_000007_000000.wav', '696_93314_000044_000003.wav', '696_93314_000067_000000.wav', '7059_77897_000019_000000.wav', '7059_77897_000020_000003.wav', '7059_77897_000023_000001.wav', '7059_88364_000003_000004.wav', '7059_88364_000014_000002.wav', '7067_76047_000008_000000.wav', '7067_76047_000030_000000.wav', '7067_76048_000026_000000.wav', '7067_76048_000058_000002.wav', '7067_76048_000062_000002.wav', '7067_76048_000064_000003.wav', '7067_76048_000071_000000.wav', '7067_76048_000074_000003.wav', '7067_76048_000076_000000.wav', '7067_76048_000076_000002.wav', '7078_271888_000010_000002.wav', '7078_271888_000030_000007.wav', '7078_271888_000082_000000.wav', '7078_271888_000109_000002.wav', '7113_86041_000041_000001.wav', '7113_86041_000058_000000.wav', '7178_34644_000010_000000.wav', '7178_34645_000012_000000.wav', '7178_34645_000013_000004.wav', '7178_34645_000022_000001.wav', '7178_34645_000023_000002.wav', '7178_34645_000035_000021.wav', '7190_90542_000001_000001.wav', '7190_90542_000065_000000.wav', '7190_90543_000005_000000.wav', '7190_90543_000009_000003.wav', '7190_90543_000041_000003.wav', '7190_90543_000058_000002.wav', '7278_91083_000007_000002.wav', '7278_91083_000013_000000.wav', '7278_91083_000027_000007.wav', '7302_86814_000033_000001.wav', '7302_86815_000016_000007.wav', '7302_86815_000021_000004.wav', '7302_86815_000050_000001.wav', '730_359_000016_000001.wav', '7312_92432_000006_000000.wav', '7367_86737_000049_000000.wav', '7367_86737_000093_000000.wav', '7367_86737_000122_000006.wav', '7367_86737_000122_000010.wav', '7367_86737_000125_000001.wav', '7402_59171_000011_000012.wav', '7402_59171_000020_000000.wav', '7402_90848_000043_000002.wav', '7447_91186_000009_000002.wav', '7447_91186_000010_000000.wav', '7447_91186_000011_000000.wav', '7447_91186_000034_000006.wav', '7447_91187_000006_000001.wav', '7447_91187_000008_000000.wav', '7447_91187_000009_000003.wav', '7447_91187_000016_000000.wav', '7505_258958_000006_000004.wav', '7505_258958_000006_000008.wav', '7505_258958_000008_000008.wav', '7505_258958_000015_000005.wav', '7505_258958_000019_000003.wav', '7505_258958_000033_000004.wav', '7505_83618_000013_000002.wav', '7511_102419_000014_000001.wav', '7511_102419_000031_000004.wav', '7511_102420_000009_000004.wav', '7511_102420_000009_000007.wav', '7511_102420_000030_000000.wav', '7517_100429_000005_000001.wav', '7517_100429_000006_000006.wav', '7517_100429_000006_000011.wav', '7517_100437_000007_000006.wav', '7517_100442_000004_000004.wav', '7635_105409_000019_000000.wav', '7635_105409_000078_000000.wav', '7635_105409_000109_000000.wav', '7780_274562_000006_000006.wav', '7780_274562_000008_000020.wav', '7794_295947_000021_000002.wav', '7794_295947_000040_000002.wav', '7794_295955_000002_000015.wav', '7794_295955_000002_000017.wav', '7794_295955_000003_000004.wav', '7800_283478_000023_000001.wav', '7800_283478_000026_000000.wav', '7800_283478_000045_000000.wav', '7800_283492_000010_000000.wav', '7800_283492_000021_000000.wav', '7800_283492_000024_000001.wav', '7800_283492_000036_000003.wav', '7800_283492_000039_000001.wav', '7859_102518_000023_000000.wav', '7859_102519_000013_000005.wav', '7859_102519_000014_000002.wav', '7859_102519_000016_000001.wav', '78_368_000003_000000.wav', '78_369_000011_000001.wav', '78_369_000016_000004.wav', '78_369_000068_000004.wav', '78_369_000073_000001.wav', '8014_112586_000010_000002.wav', '8014_112602_000001_000001.wav', '8014_112602_000006_000000.wav', '8014_112602_000013_000002.wav', '8051_118101_000019_000002.wav', '8051_295385_000006_000004.wav', '8051_295385_000009_000002.wav', '8063_274116_000035_000002.wav', '8088_284756_000005_000001.wav', '8088_284756_000022_000002.wav', '8088_284756_000129_000000.wav', '8088_284756_000130_000002.wav', '8088_284756_000132_000001.wav', '8088_284756_000136_000001.wav', '8088_284756_000166_000001.wav', '8095_274348_000003_000000.wav', '8098_275181_000020_000006.wav', '8098_278252_000018_000002.wav', '8098_278252_000028_000002.wav', '8108_274318_000001_000003.wav', '8108_274318_000005_000002.wav', '8108_274318_000005_000003.wav', '8108_274318_000010_000001.wav', '8108_274318_000021_000002.wav', '8108_280354_000004_000001.wav', '8108_280354_000007_000001.wav', '8108_280354_000015_000000.wav', '8108_280354_000018_000001.wav', '8108_280359_000006_000001.wav', '8108_280359_000009_000010.wav', '8123_275193_000010_000000.wav', '8123_275193_000016_000004.wav', '8123_275209_000004_000006.wav', '8123_275209_000005_000000.wav', '8123_275209_000013_000002.wav', '8123_275216_000009_000001.wav', '8123_275216_000046_000004.wav', '8123_275216_000055_000002.wav', '8226_274369_000012_000001.wav', '8226_274371_000020_000006.wav', '8226_274371_000036_000005.wav', '8238_274553_000011_000007.wav', '8238_274553_000012_000002.wav', '8238_283452_000026_000007.wav', '8312_279791_000024_000000.wav', '8312_279791_000029_000001.wav', '8312_279791_000030_000001.wav', '8312_279791_000032_000000.wav', '8312_279791_000039_000002.wav', '8312_279791_000051_000001.wav', '8312_279791_000055_000000.wav', '831_130746_000035_000002.wav', '831_130746_000076_000000.wav', '8324_286681_000001_000004.wav', '8324_286682_000012_000000.wav', '8324_286683_000005_000000.wav', '8465_246943_000022_000000.wav', '8468_286673_000012_000002.wav', '8468_286673_000022_000000.wav', '8468_286673_000022_000002.wav', '8468_294887_000006_000001.wav', '8468_294887_000021_000000.wav', '8468_294887_000023_000003.wav', '8468_295198_000027_000002.wav', '8468_295198_000035_000002.wav', '8468_295198_000042_000000.wav', '8580_287363_000020_000000.wav', '8580_287363_000029_000001.wav', '8580_287363_000034_000000.wav', '8580_287364_000010_000000.wav', '8580_287364_000014_000002.wav', '8580_287364_000015_000002.wav', '8609_283227_000011_000001.wav', '8609_283227_000027_000000.wav', '8629_261139_000008_000000.wav', '8629_261139_000008_000002.wav', '8629_261139_000015_000005.wav', '8629_261139_000026_000000.wav', '8629_261140_000008_000003.wav', '8629_261140_000017_000001.wav', '8630_305212_000013_000003.wav', '8630_305213_000005_000000.wav', '8630_305213_000008_000001.wav', '8630_305213_000012_000005.wav', '8630_305213_000018_000001.wav', '8630_305213_000019_000003.wav', '8630_305213_000025_000001.wav', '8747_293952_000016_000000.wav', '8747_293952_000111_000000.wav', '8770_295462_000042_000000.wav', '8770_295462_000059_000002.wav', '8770_295463_000022_000000.wav', '8770_295463_000031_000000.wav', '8770_295465_000008_000001.wav', '8770_295465_000017_000003.wav', '87_121553_000024_000000.wav', '87_121553_000028_000000.wav', '87_121553_000078_000000.wav', '87_121553_000124_000000.wav', '87_121553_000173_000000.wav', '87_121553_000185_000000.wav', '87_121553_000211_000000.wav', '87_121553_000218_000000.wav', '87_121553_000230_000000.wav', '87_121553_000253_000000.wav', '8838_298545_000070_000001.wav', '8838_298546_000001_000002.wav', '887_123289_000038_000000.wav', '887_123289_000041_000000.wav', '887_123290_000025_000004.wav', '887_123290_000027_000003.wav', '887_123291_000011_000000.wav', '8975_270782_000006_000006.wav', '8975_270782_000021_000004.wav', '89_218_000014_000007.wav']\n",
            "\n",
            "\n",
            "\n",
            " Class melgan: Files: ['103_1241_000004_000002_gen.wav', '1088_129236_000007_000002_gen.wav', '1088_129236_000019_000003_gen.wav', '1088_129236_000030_000001_gen.wav', '1088_134315_000042_000000_gen.wav', '1088_134315_000096_000001_gen.wav', '1098_133695_000006_000011_gen.wav', '1098_133695_000015_000004_gen.wav', '1098_133695_000035_000000_gen.wav', '1116_132847_000004_000000_gen.wav', '1116_132851_000028_000000_gen.wav', '1116_137572_000010_000000_gen.wav', '118_47824_000025_000000_gen.wav', '1246_124548_000018_000000_gen.wav', '1263_138246_000004_000000_gen.wav', '1263_138246_000020_000000_gen.wav', '1263_138246_000031_000001_gen.wav', '1263_141777_000006_000001_gen.wav', '1263_141777_000013_000000_gen.wav', '1263_141777_000014_000000_gen.wav', '1334_135589_000038_000000_gen.wav', '1334_135589_000065_000000_gen.wav', '1355_39947_000011_000002_gen.wav', '1355_39947_000017_000004_gen.wav', '1355_39947_000020_000004_gen.wav', '1355_39947_000026_000008_gen.wav', '1363_139304_000018_000000_gen.wav', '1502_122615_000006_000002_gen.wav', '1502_122615_000034_000000_gen.wav', '1502_122615_000036_000007_gen.wav', '1502_122619_000004_000002_gen.wav', '1502_122619_000024_000002_gen.wav', '1502_122619_000032_000002_gen.wav', '1502_122619_000054_000003_gen.wav', '1502_122619_000063_000001_gen.wav', '1553_140047_000004_000001_gen.wav', '1553_140047_000005_000002_gen.wav', '1578_140045_000048_000000_gen.wav', '1624_142933_000007_000000_gen.wav', '1624_142933_000007_000001_gen.wav', '1743_142912_000002_000000_gen.wav', '1743_142914_000007_000003_gen.wav', '1743_142914_000014_000005_gen.wav', '1841_150351_000010_000000_gen.wav', '1841_159771_000008_000001_gen.wav', '1841_179183_000012_000004_gen.wav', '1841_179183_000019_000007_gen.wav', '1867_148436_000072_000001_gen.wav', '1867_148436_000073_000000_gen.wav', '1867_154071_000011_000002_gen.wav', '1867_154071_000012_000002_gen.wav', '1867_154071_000015_000000_gen.wav', '1898_145702_000025_000001_gen.wav', '196_122150_000001_000000_gen.wav', '196_122152_000003_000002_gen.wav', '198_209_000023_000000_gen.wav', '1992_141719_000012_000009_gen.wav', '2002_139469_000016_000003_gen.wav', '2002_139469_000021_000000_gen.wav', '2002_139469_000022_000001_gen.wav', '2007_149877_000008_000000_gen.wav', '200_124139_000051_000001_gen.wav', '200_124140_000031_000002_gen.wav', '200_126784_000013_000001_gen.wav', '200_126784_000016_000000_gen.wav', '200_126784_000090_000000_gen.wav', '2092_145706_000022_000000_gen.wav', '2092_145706_000054_000001_gen.wav', '2092_145706_000056_000001_gen.wav', '2092_145709_000006_000000_gen.wav', '2136_5143_000011_000003_gen.wav', '2182_181173_000021_000004_gen.wav', '2182_181183_000034_000000_gen.wav', '2196_170151_000018_000002_gen.wav', '226_122538_000020_000000_gen.wav', '2289_152253_000015_000002_gen.wav', '2289_152253_000019_000000_gen.wav', '2289_152257_000018_000003_gen.wav', '2289_152257_000021_000001_gen.wav', '2416_152139_000061_000004_gen.wav', '2436_2476_000039_000002_gen.wav', '2436_2481_000040_000003_gen.wav', '250_140277_000005_000002_gen.wav', '250_142276_000004_000003_gen.wav', '250_142276_000007_000005_gen.wav', '250_142276_000015_000017_gen.wav', '2514_149482_000008_000000_gen.wav', '2514_149482_000009_000008_gen.wav', '2518_154826_000006_000001_gen.wav', '2518_154826_000011_000001_gen.wav', '2518_154826_000031_000000_gen.wav', '254_27760_000006_000008_gen.wav', '254_27760_000013_000004_gen.wav', '26_496_000008_000000_gen.wav', '26_496_000010_000002_gen.wav', '26_496_000022_000008_gen.wav', '27_124992_000093_000001_gen.wav', '2817_142371_000017_000000_gen.wav', '2817_142371_000027_000000_gen.wav', '2817_142380_000003_000002_gen.wav', '2817_142380_000027_000000_gen.wav', '2836_5354_000016_000000_gen.wav', '2836_5354_000076_000002_gen.wav', '2836_5355_000035_000001_gen.wav', '2836_5355_000037_000001_gen.wav', '2836_5355_000046_000001_gen.wav', '2836_5355_000050_000000_gen.wav', '2836_5355_000094_000003_gen.wav', '2843_152918_000001_000003_gen.wav', '2843_152918_000002_000002_gen.wav', '2843_152918_000003_000010_gen.wav', '2843_152918_000018_000004_gen.wav', '2893_139310_000037_000019_gen.wav', '2893_139322_000009_000002_gen.wav', '2893_139322_000022_000004_gen.wav', '2893_139322_000023_000001_gen.wav', '2910_131096_000006_000003_gen.wav', '2910_131096_000013_000003_gen.wav', '2910_131096_000014_000001_gen.wav', '2910_131096_000028_000001_gen.wav', '2911_12359_000017_000001_gen.wav', '298_126791_000030_000002_gen.wav', '302_123523_000008_000000_gen.wav', '3112_9555_000021_000012_gen.wav', '3168_173564_000028_000000_gen.wav', '3168_173565_000003_000008_gen.wav', '3168_173565_000027_000004_gen.wav', '3235_28452_000010_000002_gen.wav', '3240_131231_000022_000000_gen.wav', '3240_131231_000048_000000_gen.wav', '3240_131232_000065_000001_gen.wav', '3240_131232_000076_000000_gen.wav', '3242_67153_000016_000007_gen.wav', '3242_8112_000036_000003_gen.wav', '3259_158083_000020_000000_gen.wav', '3259_158083_000022_000002_gen.wav', '3259_158083_000028_000002_gen.wav', '3259_158083_000038_000000_gen.wav', '3259_158083_000070_000000_gen.wav', '3259_158083_000107_000002_gen.wav', '3259_158083_000118_000001_gen.wav', '32_21625_000030_000000_gen.wav', '32_21634_000016_000000_gen.wav', '332_128985_000005_000004_gen.wav', '3374_298026_000004_000004_gen.wav', '3436_172162_000008_000000_gen.wav', '3436_172162_000011_000009_gen.wav', '3436_172162_000012_000004_gen.wav', '3436_172171_000008_000005_gen.wav', '3440_171009_000109_000000_gen.wav', '3486_166446_000016_000002_gen.wav', '3526_176651_000012_000017_gen.wav', '3526_176653_000002_000001_gen.wav', '3526_176653_000002_000006_gen.wav', '3526_176653_000071_000000_gen.wav', '3526_176653_000083_000002_gen.wav', '3664_11714_000012_000000_gen.wav', '3699_175950_000009_000000_gen.wav', '374_180298_000014_000001_gen.wav', '374_180299_000020_000002_gen.wav', '374_180299_000033_000003_gen.wav', '3807_4923_000029_000001_gen.wav', '3830_12529_000021_000000_gen.wav', '3830_12530_000020_000002_gen.wav', '3830_12531_000012_000003_gen.wav', '3830_12531_000024_000000_gen.wav', '3830_12531_000030_000003_gen.wav', '3830_12535_000010_000001_gen.wav', '3857_180923_000008_000001_gen.wav', '3857_180923_000023_000001_gen.wav', '3857_182317_000003_000000_gen.wav', '3857_182317_000025_000004_gen.wav', '3879_173592_000007_000001_gen.wav', '3879_173592_000007_000003_gen.wav', '3879_173592_000008_000001_gen.wav', '3879_173592_000014_000001_gen.wav', '3879_173592_000017_000002_gen.wav', '3879_173592_000021_000002_gen.wav', '3879_174923_000033_000005_gen.wav', '3982_178459_000018_000001_gen.wav', '3982_182255_000049_000006_gen.wav', '3982_182255_000067_000002_gen.wav', '3983_5371_000013_000005_gen.wav', '4014_186183_000021_000001_gen.wav', '4018_103416_000067_000004_gen.wav', '4018_107312_000015_000001_gen.wav', '4018_107338_000020_000002_gen.wav', '4018_107338_000033_000000_gen.wav', '403_126855_000017_000001_gen.wav', '4051_11218_000019_000000_gen.wav', '405_130894_000073_000001_gen.wav', '405_130895_000037_000000_gen.wav', '405_130895_000037_000005_gen.wav', '405_130895_000038_000001_gen.wav', '4088_158077_000085_000002_gen.wav', '40_222_000009_000000_gen.wav', '40_222_000012_000001_gen.wav', '40_222_000017_000000_gen.wav', '412_126975_000022_000000_gen.wav', '412_126975_000051_000007_gen.wav', '412_126975_000055_000001_gen.wav', '412_126975_000080_000003_gen.wav', '412_126975_000083_000001_gen.wav', '4137_11702_000058_000000_gen.wav', '4160_11550_000047_000002_gen.wav', '4195_17507_000016_000000_gen.wav', '4195_17507_000065_000001_gen.wav', '4195_186236_000017_000000_gen.wav', '4195_186238_000025_000000_gen.wav', '4195_186238_000062_000001_gen.wav', '4267_287369_000046_000000_gen.wav', '4267_72637_000034_000000_gen.wav', '4267_78186_000006_000002_gen.wav', '4267_78186_000006_000003_gen.wav', '4267_78186_000007_000013_gen.wav', '4297_13006_000065_000005_gen.wav', '4362_15663_000037_000003_gen.wav', '4397_15678_000008_000003_gen.wav', '4397_15678_000010_000002_gen.wav', '4406_16882_000017_000010_gen.wav', '4406_16882_000024_000000_gen.wav', '4406_16882_000024_000005_gen.wav', '4406_16882_000027_000004_gen.wav', '4406_16883_000002_000005_gen.wav', '4406_16883_000005_000008_gen.wav', '4406_16883_000013_000002_gen.wav', '4406_16883_000014_000002_gen.wav', '4406_16883_000019_000020_gen.wav', '446_123502_000009_000001_gen.wav', '446_123502_000018_000001_gen.wav', '446_123502_000030_000003_gen.wav', '460_172357_000003_000001_gen.wav', '460_172359_000056_000003_gen.wav', '460_172359_000064_000002_gen.wav', '4640_19189_000014_000039_gen.wav', '4680_16041_000014_000000_gen.wav', '4788_294466_000019_000001_gen.wav', '4788_91208_000007_000007_gen.wav', '4788_94904_000004_000008_gen.wav', '4788_94904_000005_000008_gen.wav', '4788_94904_000008_000012_gen.wav', '481_123720_000038_000001_gen.wav', '4830_25898_000030_000002_gen.wav', '4830_25898_000034_000001_gen.wav', '5022_29411_000101_000001_gen.wav', '5104_33406_000015_000003_gen.wav', '5104_33407_000034_000000_gen.wav', '5163_39921_000025_000004_gen.wav', '5322_7678_000006_000012_gen.wav', '5322_7679_000001_000002_gen.wav', '5322_7679_000002_000007_gen.wav', '5322_7679_000018_000002_gen.wav', '5322_7679_000032_000000_gen.wav', '5322_7680_000044_000000_gen.wav', '5322_7680_000061_000002_gen.wav', '5339_14133_000004_000000_gen.wav', '5339_14133_000020_000005_gen.wav', '5339_14134_000014_000000_gen.wav', '5393_19218_000029_000005_gen.wav', '5393_19218_000041_000001_gen.wav', '5393_19219_000054_000009_gen.wav', '5456_24741_000008_000000_gen.wav', '5456_24741_000016_000005_gen.wav', '5514_19192_000013_000006_gen.wav', '5514_19193_000008_000002_gen.wav', '5561_41615_000003_000001_gen.wav', '5561_41616_000025_000001_gen.wav', '5561_41616_000031_000000_gen.wav', '5652_19215_000026_000052_gen.wav', '5652_39938_000015_000004_gen.wav', '5652_39938_000021_000004_gen.wav', '5652_39938_000022_000001_gen.wav', '5703_47198_000048_000002_gen.wav', '5750_100289_000020_000002_gen.wav', '5778_12761_000002_000001_gen.wav', '5778_12761_000013_000008_gen.wav', '5778_54535_000007_000002_gen.wav', '5778_54535_000008_000007_gen.wav', '5789_70653_000033_000008_gen.wav', '5808_48608_000005_000001_gen.wav', '5808_54425_000010_000014_gen.wav', '5867_48852_000006_000000_gen.wav', '5867_48852_000011_000001_gen.wav', '5867_48852_000035_000001_gen.wav', '587_54108_000006_000000_gen.wav', '587_54108_000057_000000_gen.wav', '6000_55211_000007_000005_gen.wav', '6019_3185_000014_000003_gen.wav', '6064_56165_000078_000000_gen.wav', '6078_54007_000046_000001_gen.wav', '6078_54007_000059_000000_gen.wav', '6081_41997_000043_000003_gen.wav', '6081_42010_000029_000001_gen.wav', '60_121082_000017_000000_gen.wav', '6147_34605_000007_000004_gen.wav', '6147_34605_000032_000001_gen.wav', '6147_34606_000021_000000_gen.wav', '6181_216552_000007_000006_gen.wav', '6181_216552_000017_000000_gen.wav', '6181_216552_000078_000000_gen.wav', '6209_34600_000012_000005_gen.wav', '6209_34601_000093_000001_gen.wav', '625_132112_000004_000009_gen.wav', '6272_70168_000021_000000_gen.wav', '6272_70168_000027_000009_gen.wav', '6272_70191_000024_000007_gen.wav', '6367_65536_000006_000006_gen.wav', '6367_74004_000030_000001_gen.wav', '6415_100596_000044_000000_gen.wav', '6415_111615_000011_000000_gen.wav', '6415_116629_000025_000002_gen.wav', '6437_66172_000004_000001_gen.wav', '6437_66172_000021_000003_gen.wav', '6437_66173_000057_000000_gen.wav', '6454_107462_000023_000000_gen.wav', '6454_120342_000020_000000_gen.wav', '6454_120342_000028_000000_gen.wav', '6454_93938_000031_000005_gen.wav', '6476_96661_000016_000000_gen.wav', '6476_96661_000019_000000_gen.wav', '6476_96661_000021_000001_gen.wav', '6529_62554_000036_000001_gen.wav', '6818_68772_000038_000001_gen.wav', '6818_76332_000015_000004_gen.wav', '6818_76332_000016_000001_gen.wav', '6818_76332_000046_000000_gen.wav', '6836_61803_000014_000001_gen.wav', '6848_76049_000016_000000_gen.wav', '6880_216547_000016_000000_gen.wav', '6880_216547_000029_000000_gen.wav', '696_92939_000014_000001_gen.wav', '696_93314_000023_000006_gen.wav', '696_93314_000027_000000_gen.wav', '696_93314_000029_000000_gen.wav', '7059_77897_000013_000003_gen.wav', '7059_77897_000021_000000_gen.wav', '7059_88364_000005_000005_gen.wav', '7067_76047_000028_000008_gen.wav', '7067_76047_000037_000000_gen.wav', '7067_76047_000054_000000_gen.wav', '7067_76047_000059_000001_gen.wav', '7067_76048_000050_000006_gen.wav', '7067_76048_000071_000001_gen.wav', '7078_271888_000030_000007_gen.wav', '7113_86041_000034_000000_gen.wav', '7113_86041_000039_000000_gen.wav', '7178_34644_000044_000000_gen.wav', '7178_34644_000048_000005_gen.wav', '7178_34645_000009_000003_gen.wav', '7178_34645_000023_000000_gen.wav', '7178_34645_000025_000003_gen.wav', '7190_90543_000013_000000_gen.wav', '7264_92316_000029_000000_gen.wav', '7278_104730_000001_000011_gen.wav', '7278_246956_000010_000000_gen.wav', '7278_91083_000004_000001_gen.wav', '7278_91083_000023_000000_gen.wav', '7302_86814_000002_000001_gen.wav', '7302_86814_000003_000001_gen.wav', '7302_86814_000059_000000_gen.wav', '7302_86815_000056_000000_gen.wav', '730_358_000001_000002_gen.wav', '7367_86737_000079_000000_gen.wav', '7367_86737_000117_000000_gen.wav', '7367_86737_000119_000001_gen.wav', '7402_90848_000059_000000_gen.wav', '7447_91186_000018_000001_gen.wav', '7447_91187_000017_000004_gen.wav', '7447_91187_000020_000000_gen.wav', '7447_91187_000020_000003_gen.wav', '7505_258958_000027_000012_gen.wav', '7505_258958_000031_000007_gen.wav', '7505_258964_000004_000002_gen.wav', '7505_258964_000030_000003_gen.wav', '7511_102419_000006_000005_gen.wav', '7511_102419_000008_000000_gen.wav', '7511_102419_000020_000000_gen.wav', '7511_102419_000021_000005_gen.wav', '7511_102420_000009_000001_gen.wav', '7511_102420_000013_000005_gen.wav', '7511_102420_000015_000000_gen.wav', '7511_102420_000019_000002_gen.wav', '7517_100429_000005_000004_gen.wav', '7517_100429_000006_000000_gen.wav', '7517_100437_000004_000001_gen.wav', '7517_100437_000007_000003_gen.wav', '7517_100437_000008_000000_gen.wav', '7517_100442_000004_000004_gen.wav', '7517_100442_000004_000005_gen.wav', '7780_274562_000005_000002_gen.wav', '7780_274562_000006_000000_gen.wav', '7780_274562_000006_000003_gen.wav', '7780_274562_000008_000010_gen.wav', '7780_274562_000012_000000_gen.wav', '7794_295947_000038_000000_gen.wav', '7794_295947_000044_000001_gen.wav', '7794_295955_000002_000045_gen.wav', '7800_283492_000003_000001_gen.wav', '7800_283493_000034_000001_gen.wav', '78_368_000006_000013_gen.wav', '78_368_000017_000005_gen.wav', '78_369_000007_000000_gen.wav', '78_369_000029_000001_gen.wav', '78_369_000058_000000_gen.wav', '78_369_000061_000006_gen.wav', '78_369_000066_000009_gen.wav', '78_369_000075_000002_gen.wav', '8014_112586_000010_000002_gen.wav', '8051_118101_000018_000002_gen.wav', '8051_119902_000011_000001_gen.wav', '8051_295385_000013_000001_gen.wav', '8051_295385_000016_000001_gen.wav', '8088_284756_000021_000003_gen.wav', '8088_284756_000074_000002_gen.wav', '8088_284756_000081_000000_gen.wav', '8088_284756_000089_000001_gen.wav', '8088_284756_000138_000001_gen.wav', '8088_284756_000183_000001_gen.wav', '8095_274348_000010_000000_gen.wav', '8098_278252_000018_000002_gen.wav', '8098_278252_000026_000003_gen.wav', '8098_278252_000031_000000_gen.wav', '8108_280359_000006_000001_gen.wav', '8108_280359_000010_000005_gen.wav', '8123_275193_000016_000003_gen.wav', '8123_275209_000036_000000_gen.wav', '8123_275216_000034_000003_gen.wav', '8123_275216_000041_000000_gen.wav', '8238_274553_000011_000001_gen.wav', '8238_274553_000022_000001_gen.wav', '8238_283452_000023_000003_gen.wav', '8238_283452_000025_000007_gen.wav', '8238_283452_000033_000009_gen.wav', '8312_279790_000046_000001_gen.wav', '8312_279791_000029_000001_gen.wav', '8312_279791_000038_000002_gen.wav', '8312_279791_000038_000005_gen.wav', '8312_279791_000039_000002_gen.wav', '831_130739_000015_000008_gen.wav', '831_130739_000032_000004_gen.wav', '831_130739_000034_000000_gen.wav', '8324_286681_000008_000003_gen.wav', '8324_286682_000006_000002_gen.wav', '8324_286682_000012_000001_gen.wav', '8324_286682_000016_000001_gen.wav', '8465_246943_000022_000000_gen.wav', '8468_294887_000008_000000_gen.wav', '8580_287363_000004_000001_gen.wav', '8580_287364_000021_000003_gen.wav', '8609_283227_000010_000004_gen.wav', '8629_261139_000015_000003_gen.wav', '8630_305212_000006_000002_gen.wav', '8630_305212_000013_000006_gen.wav', '8630_305213_000008_000003_gen.wav', '8630_305213_000009_000001_gen.wav', '8630_305213_000018_000000_gen.wav', '8630_305213_000025_000000_gen.wav', '8747_293952_000127_000001_gen.wav', '8770_295462_000027_000000_gen.wav', '8770_295463_000008_000002_gen.wav', '8797_294123_000016_000004_gen.wav', '8797_294123_000016_000007_gen.wav', '8797_294123_000036_000000_gen.wav', '87_121553_000007_000000_gen.wav', '87_121553_000109_000000_gen.wav', '87_121553_000118_000000_gen.wav', '87_121553_000186_000000_gen.wav', '87_121553_000218_000000_gen.wav', '8838_298545_000016_000003_gen.wav', '8838_298545_000023_000000_gen.wav', '8838_298545_000077_000001_gen.wav', '887_123291_000017_000005_gen.wav', '8975_270782_000015_000002_gen.wav', '8975_270782_000023_000002_gen.wav', '89_218_000014_000017_gen.wav']\n",
            "\n",
            "\n",
            "\n",
            " Class parallel_wave_gan: Files: ['1069_133699_000056_000001_gen.wav', '1088_129236_000006_000005_gen.wav', '1088_129236_000007_000005_gen.wav', '1088_129236_000031_000000_gen.wav', '1088_134315_000005_000001_gen.wav', '1088_134315_000014_000000_gen.wav', '1088_134315_000038_000000_gen.wav', '1088_134315_000056_000001_gen.wav', '1088_134318_000019_000001_gen.wav', '1088_134318_000037_000000_gen.wav', '1116_137572_000024_000001_gen.wav', '1116_137572_000038_000000_gen.wav', '1116_137572_000043_000002_gen.wav', '1183_133255_000050_000000_gen.wav', '118_47824_000070_000000_gen.wav', '118_47824_000083_000010_gen.wav', '125_121124_000046_000000_gen.wav', '125_121124_000049_000001_gen.wav', '1334_135589_000053_000000_gen.wav', '1355_39947_000003_000002_gen.wav', '1355_39947_000010_000001_gen.wav', '1355_39947_000010_000006_gen.wav', '1502_122615_000006_000002_gen.wav', '1502_122619_000004_000001_gen.wav', '1502_122619_000056_000005_gen.wav', '1502_122619_000063_000001_gen.wav', '1553_140047_000003_000000_gen.wav', '1553_140047_000028_000001_gen.wav', '1553_140048_000002_000003_gen.wav', '1578_140045_000048_000000_gen.wav', '1594_135914_000016_000003_gen.wav', '1624_142933_000013_000001_gen.wav', '1624_142933_000021_000000_gen.wav', '1737_142397_000030_000001_gen.wav', '1743_142914_000003_000008_gen.wav', '1841_150351_000017_000000_gen.wav', '1841_150351_000017_000003_gen.wav', '1841_150351_000026_000003_gen.wav', '1841_179183_000018_000003_gen.wav', '1841_179183_000024_000000_gen.wav', '1867_154075_000079_000000_gen.wav', '1963_142776_000041_000000_gen.wav', '196_122150_000003_000002_gen.wav', '196_122152_000002_000001_gen.wav', '1970_26100_000009_000000_gen.wav', '1970_28415_000008_000003_gen.wav', '1992_141719_000014_000013_gen.wav', '2002_139469_000015_000002_gen.wav', '2002_139469_000019_000010_gen.wav', '2007_149877_000036_000001_gen.wav', '200_124140_000022_000000_gen.wav', '200_126784_000006_000000_gen.wav', '200_126784_000026_000002_gen.wav', '200_126784_000032_000000_gen.wav', '200_126784_000033_000000_gen.wav', '200_126784_000037_000000_gen.wav', '201_122255_000007_000005_gen.wav', '201_122255_000016_000002_gen.wav', '201_122255_000044_000000_gen.wav', '2092_145706_000012_000000_gen.wav', '2092_145706_000034_000002_gen.wav', '2092_145706_000045_000000_gen.wav', '2092_145709_000006_000003_gen.wav', '2196_170151_000005_000001_gen.wav', '2196_170379_000011_000003_gen.wav', '226_122538_000009_000001_gen.wav', '2289_152253_000010_000003_gen.wav', '2289_152254_000025_000001_gen.wav', '2289_152254_000030_000000_gen.wav', '2289_152257_000012_000000_gen.wav', '2289_152257_000013_000004_gen.wav', '2289_152258_000006_000002_gen.wav', '250_142276_000014_000001_gen.wav', '250_142276_000014_000005_gen.wav', '250_142286_000003_000004_gen.wav', '250_142286_000011_000007_gen.wav', '250_142286_000035_000000_gen.wav', '2514_149482_000005_000007_gen.wav', '2514_149482_000025_000009_gen.wav', '2518_154826_000035_000001_gen.wav', '254_145458_000014_000005_gen.wav', '2691_156755_000014_000001_gen.wav', '26_495_000056_000001_gen.wav', '26_496_000012_000001_gen.wav', '27_124992_000125_000001_gen.wav', '2817_142371_000023_000000_gen.wav', '2836_5354_000036_000000_gen.wav', '2836_5355_000086_000001_gen.wav', '2843_152918_000000_000003_gen.wav', '2893_139322_000022_000002_gen.wav', '2910_131096_000024_000000_gen.wav', '2910_131096_000026_000001_gen.wav', '302_123504_000020_000001_gen.wav', '302_123516_000031_000000_gen.wav', '302_123523_000013_000000_gen.wav', '3112_9554_000010_000004_gen.wav', '3112_9555_000020_000013_gen.wav', '3112_9555_000022_000008_gen.wav', '3214_167602_000028_000003_gen.wav', '3214_167606_000019_000002_gen.wav', '3235_28433_000015_000000_gen.wav', '3235_28433_000019_000000_gen.wav', '3235_28452_000010_000000_gen.wav', '3235_28452_000011_000002_gen.wav', '3235_28452_000015_000003_gen.wav', '3235_28452_000016_000001_gen.wav', '3240_131232_000027_000001_gen.wav', '3240_131232_000062_000001_gen.wav', '3242_8112_000014_000003_gen.wav', '3242_8112_000044_000004_gen.wav', '3259_158083_000120_000000_gen.wav', '32_21625_000029_000000_gen.wav', '32_21631_000008_000002_gen.wav', '32_21634_000020_000002_gen.wav', '32_4137_000026_000000_gen.wav', '32_4137_000041_000001_gen.wav', '3436_172162_000015_000002_gen.wav', '3486_166424_000009_000000_gen.wav', '3526_176651_000012_000012_gen.wav', '3526_176651_000012_000016_gen.wav', '3526_176653_000001_000004_gen.wav', '3664_11714_000017_000000_gen.wav', '3664_11714_000020_000004_gen.wav', '3664_178355_000021_000001_gen.wav', '3664_178366_000004_000003_gen.wav', '3699_47246_000002_000001_gen.wav', '374_180298_000011_000003_gen.wav', '374_180298_000013_000002_gen.wav', '374_180298_000035_000005_gen.wav', '3830_12529_000012_000003_gen.wav', '3830_12530_000012_000002_gen.wav', '3830_12531_000012_000003_gen.wav', '3830_12531_000036_000004_gen.wav', '3830_12535_000015_000000_gen.wav', '3830_12535_000015_000001_gen.wav', '3830_12535_000027_000001_gen.wav', '3830_12535_000030_000004_gen.wav', '3857_180923_000003_000003_gen.wav', '3857_182317_000028_000002_gen.wav', '3879_174923_000032_000002_gen.wav', '3982_178459_000056_000025_gen.wav', '4018_107312_000032_000000_gen.wav', '4018_107338_000017_000000_gen.wav', '4018_107338_000020_000001_gen.wav', '403_126855_000037_000000_gen.wav', '403_128339_000011_000000_gen.wav', '4051_11217_000021_000000_gen.wav', '4051_11218_000037_000000_gen.wav', '405_130894_000065_000000_gen.wav', '405_130894_000072_000001_gen.wav', '405_130895_000020_000000_gen.wav', '405_130895_000041_000002_gen.wav', '40_121026_000033_000000_gen.wav', '40_121026_000042_000001_gen.wav', '40_121026_000165_000001_gen.wav', '40_121026_000176_000000_gen.wav', '40_121026_000178_000001_gen.wav', '40_121026_000190_000005_gen.wav', '40_121026_000221_000003_gen.wav', '40_121026_000224_000001_gen.wav', '40_121026_000227_000005_gen.wav', '40_121026_000237_000000_gen.wav', '40_222_000002_000009_gen.wav', '412_126975_000006_000001_gen.wav', '412_126975_000011_000000_gen.wav', '412_126975_000022_000000_gen.wav', '412_126975_000042_000002_gen.wav', '412_126975_000055_000003_gen.wav', '412_126975_000080_000001_gen.wav', '4137_11701_000030_000002_gen.wav', '4137_11701_000055_000000_gen.wav', '4137_11702_000077_000001_gen.wav', '4160_14187_000015_000005_gen.wav', '4195_186237_000010_000001_gen.wav', '4214_7146_000009_000002_gen.wav', '4214_7146_000028_000007_gen.wav', '4267_287369_000005_000000_gen.wav', '4267_72637_000034_000000_gen.wav', '4267_78186_000003_000005_gen.wav', '4267_78186_000003_000008_gen.wav', '4297_13006_000012_000003_gen.wav', '4397_15666_000003_000004_gen.wav', '4397_15668_000007_000000_gen.wav', '4397_15678_000006_000003_gen.wav', '4397_15678_000006_000006_gen.wav', '4406_16882_000018_000019_gen.wav', '4406_16882_000018_000025_gen.wav', '4406_16882_000018_000034_gen.wav', '4406_16883_000002_000015_gen.wav', '4406_16883_000014_000011_gen.wav', '4406_16883_000014_000019_gen.wav', '4406_16883_000016_000008_gen.wav', '4406_16883_000016_000018_gen.wav', '4406_16883_000027_000007_gen.wav', '446_123502_000019_000001_gen.wav', '446_123502_000030_000003_gen.wav', '458_126294_000005_000000_gen.wav', '460_172357_000008_000000_gen.wav', '460_172357_000008_000006_gen.wav', '460_172357_000012_000004_gen.wav', '460_172359_000023_000001_gen.wav', '4640_19187_000003_000000_gen.wav', '4640_19187_000026_000005_gen.wav', '4640_19189_000037_000000_gen.wav', '4680_16041_000017_000004_gen.wav', '4680_16041_000024_000002_gen.wav', '4680_16041_000029_000000_gen.wav', '4788_294466_000046_000003_gen.wav', '4788_91208_000009_000007_gen.wav', '4813_248638_000006_000004_gen.wav', '4813_248638_000023_000002_gen.wav', '4813_248641_000004_000003_gen.wav', '4813_248641_000010_000007_gen.wav', '4830_25898_000015_000000_gen.wav', '4830_25898_000021_000006_gen.wav', '5104_33406_000042_000000_gen.wav', '5104_33406_000056_000000_gen.wav', '5163_18515_000042_000002_gen.wav', '5163_39921_000024_000001_gen.wav', '5163_39921_000044_000005_gen.wav', '5322_7678_000007_000004_gen.wav', '5322_7680_000061_000001_gen.wav', '5339_14134_000042_000002_gen.wav', '5390_24512_000046_000001_gen.wav', '5390_30102_000026_000000_gen.wav', '5393_19218_000027_000001_gen.wav', '5393_19218_000029_000005_gen.wav', '5393_19218_000030_000007_gen.wav', '5393_19218_000069_000000_gen.wav', '5393_19219_000012_000001_gen.wav', '5393_19219_000047_000014_gen.wav', '5393_19219_000054_000010_gen.wav', '5456_62043_000015_000003_gen.wav', '5463_39174_000071_000000_gen.wav', '5514_19193_000008_000006_gen.wav', '5514_19193_000023_000000_gen.wav', '5514_19193_000051_000000_gen.wav', '5561_41615_000026_000001_gen.wav', '5561_41615_000028_000000_gen.wav', '5561_41616_000004_000003_gen.wav', '5561_41616_000029_000000_gen.wav', '5652_19215_000009_000009_gen.wav', '5652_39938_000004_000000_gen.wav', '5678_43301_000005_000000_gen.wav', '5703_47198_000058_000000_gen.wav', '5703_47198_000064_000003_gen.wav', '5703_47212_000022_000000_gen.wav', '5703_47212_000042_000000_gen.wav', '5750_100289_000028_000004_gen.wav', '5778_12761_000002_000006_gen.wav', '5778_12761_000003_000000_gen.wav', '5778_12761_000008_000000_gen.wav', '5778_54535_000008_000007_gen.wav', '5778_54535_000012_000003_gen.wav', '5778_54535_000018_000003_gen.wav', '5789_70653_000033_000008_gen.wav', '5867_48852_000005_000001_gen.wav', '5867_48852_000035_000005_gen.wav', '587_54108_000020_000000_gen.wav', '6019_3185_000012_000006_gen.wav', '6019_3185_000014_000008_gen.wav', '6019_3185_000016_000004_gen.wav', '6019_3185_000029_000007_gen.wav', '6064_300880_000029_000002_gen.wav', '6064_300880_000045_000006_gen.wav', '6064_56165_000003_000001_gen.wav', '6064_56165_000025_000000_gen.wav', '6078_54007_000036_000001_gen.wav', '6078_54007_000038_000002_gen.wav', '6078_54007_000040_000002_gen.wav', '6078_54007_000044_000000_gen.wav', '6081_41997_000005_000004_gen.wav', '6081_42010_000005_000003_gen.wav', '60_121082_000005_000005_gen.wav', '60_121082_000005_000006_gen.wav', '60_121082_000096_000004_gen.wav', '6147_34605_000004_000004_gen.wav', '6147_34605_000005_000005_gen.wav', '6147_34605_000007_000004_gen.wav', '6147_34605_000028_000002_gen.wav', '6147_34605_000030_000002_gen.wav', '6147_34605_000039_000006_gen.wav', '6147_34606_000007_000009_gen.wav', '6147_34606_000008_000004_gen.wav', '6147_34607_000007_000003_gen.wav', '6147_34607_000018_000000_gen.wav', '6181_216552_000008_000002_gen.wav', '6181_216552_000025_000001_gen.wav', '6181_216552_000026_000000_gen.wav', '6181_216552_000048_000000_gen.wav', '6209_34599_000008_000003_gen.wav', '6209_34599_000013_000000_gen.wav', '6209_34600_000007_000003_gen.wav', '6209_34601_000096_000062_gen.wav', '625_132118_000006_000009_gen.wav', '6272_70191_000002_000019_gen.wav', '6272_70191_000024_000006_gen.wav', '6367_65536_000004_000000_gen.wav', '6367_65536_000022_000000_gen.wav', '6367_65536_000025_000000_gen.wav', '6367_74004_000016_000006_gen.wav', '6367_74004_000029_000000_gen.wav', '6385_34655_000014_000000_gen.wav', '6385_34669_000021_000002_gen.wav', '6385_34669_000027_000001_gen.wav', '6385_34669_000028_000002_gen.wav', '6415_100596_000017_000000_gen.wav', '6415_111615_000005_000000_gen.wav', '6415_111615_000006_000000_gen.wav', '6415_111615_000010_000001_gen.wav', '6415_116629_000015_000004_gen.wav', '6437_66172_000010_000003_gen.wav', '6437_66173_000056_000000_gen.wav', '6454_107462_000010_000002_gen.wav', '6454_107462_000024_000000_gen.wav', '6454_120342_000024_000002_gen.wav', '6476_57446_000006_000001_gen.wav', '6476_57446_000040_000002_gen.wav', '6476_57446_000068_000003_gen.wav', '6529_62554_000017_000004_gen.wav', '6529_62554_000021_000000_gen.wav', '6529_62554_000025_000001_gen.wav', '6818_76332_000011_000000_gen.wav', '6818_76332_000028_000000_gen.wav', '6836_61803_000060_000000_gen.wav', '6836_61804_000048_000000_gen.wav', '6836_76549_000002_000003_gen.wav', '6836_76549_000005_000010_gen.wav', '6848_76049_000023_000002_gen.wav', '6880_216547_000019_000000_gen.wav', '6880_216547_000050_000002_gen.wav', '6880_216547_000051_000001_gen.wav', '6880_216547_000053_000006_gen.wav', '696_92939_000023_000001_gen.wav', '696_93314_000006_000003_gen.wav', '696_93314_000044_000003_gen.wav', '696_93314_000059_000000_gen.wav', '7059_77897_000010_000000_gen.wav', '7059_77897_000019_000000_gen.wav', '7059_77900_000017_000000_gen.wav', '7059_77900_000029_000005_gen.wav', '7059_77900_000041_000002_gen.wav', '7067_76047_000003_000000_gen.wav', '7067_76048_000017_000000_gen.wav', '7067_76048_000074_000002_gen.wav', '7067_76048_000076_000000_gen.wav', '7067_76048_000076_000001_gen.wav', '7078_271888_000030_000008_gen.wav', '7113_86041_000003_000008_gen.wav', '7113_86041_000004_000001_gen.wav', '7178_34645_000012_000013_gen.wav', '7178_34645_000028_000009_gen.wav', '7178_34645_000035_000009_gen.wav', '7178_34645_000041_000003_gen.wav', '7278_246956_000016_000000_gen.wav', '7278_91083_000025_000003_gen.wav', '7302_86814_000002_000001_gen.wav', '7302_86814_000006_000005_gen.wav', '7302_86814_000006_000007_gen.wav', '7302_86814_000053_000000_gen.wav', '730_358_000004_000004_gen.wav', '730_358_000006_000003_gen.wav', '730_360_000018_000003_gen.wav', '7367_86737_000049_000000_gen.wav', '7367_86737_000090_000000_gen.wav', '7367_86737_000120_000000_gen.wav', '7367_86737_000132_000012_gen.wav', '7367_86737_000132_000013_gen.wav', '7367_86737_000132_000020_gen.wav', '7402_59171_000010_000011_gen.wav', '7402_90848_000011_000000_gen.wav', '7402_90848_000041_000003_gen.wav', '7402_90848_000059_000003_gen.wav', '7447_91186_000015_000003_gen.wav', '7447_91186_000018_000006_gen.wav', '7447_91186_000028_000004_gen.wav', '7447_91187_000004_000000_gen.wav', '7447_91187_000010_000004_gen.wav', '7447_91187_000018_000003_gen.wav', '7505_258958_000006_000004_gen.wav', '7505_258958_000027_000002_gen.wav', '7505_258958_000027_000015_gen.wav', '7505_258964_000023_000005_gen.wav', '7505_83618_000010_000000_gen.wav', '7511_102420_000009_000007_gen.wav', '7511_102420_000012_000000_gen.wav', '7511_102420_000017_000003_gen.wav', '7517_100429_000006_000010_gen.wav', '7635_105409_000015_000001_gen.wav', '7780_274562_000004_000010_gen.wav', '7794_295955_000002_000041_gen.wav', '7800_283478_000025_000000_gen.wav', '7800_283492_000040_000000_gen.wav', '7800_283492_000045_000000_gen.wav', '7800_283492_000058_000000_gen.wav', '7800_283493_000053_000001_gen.wav', '7859_102519_000022_000002_gen.wav', '78_368_000011_000013_gen.wav', '78_369_000017_000004_gen.wav', '78_369_000061_000006_gen.wav', '8014_112602_000008_000003_gen.wav', '8051_118101_000012_000004_gen.wav', '8051_118101_000018_000005_gen.wav', '8051_119902_000006_000002_gen.wav', '8051_119902_000010_000000_gen.wav', '8051_119902_000019_000003_gen.wav', '8051_295385_000010_000000_gen.wav', '8051_295385_000013_000001_gen.wav', '8088_284756_000055_000004_gen.wav', '8088_284756_000099_000002_gen.wav', '8088_284756_000105_000001_gen.wav', '8088_284756_000110_000001_gen.wav', '8098_275181_000037_000000_gen.wav', '8098_278278_000010_000001_gen.wav', '8098_278278_000019_000006_gen.wav', '8108_274318_000016_000004_gen.wav', '8108_274318_000017_000003_gen.wav', '8108_274318_000019_000002_gen.wav', '8108_274318_000020_000001_gen.wav', '8108_280354_000017_000004_gen.wav', '8108_280359_000009_000010_gen.wav', '8123_275209_000007_000002_gen.wav', '8123_275209_000033_000000_gen.wav', '8123_275209_000043_000001_gen.wav', '8123_275209_000046_000000_gen.wav', '8123_275216_000004_000000_gen.wav', '8123_275216_000055_000002_gen.wav', '8238_274553_000013_000005_gen.wav', '8238_274553_000028_000002_gen.wav', '8238_274553_000028_000005_gen.wav', '8238_283452_000025_000001_gen.wav', '8238_283452_000030_000004_gen.wav', '8312_279790_000002_000008_gen.wav', '8312_279790_000047_000000_gen.wav', '8312_279791_000008_000001_gen.wav', '8312_279791_000014_000003_gen.wav', '831_130746_000038_000007_gen.wav', '8324_286682_000036_000001_gen.wav', '8465_246947_000006_000000_gen.wav', '8468_294887_000019_000004_gen.wav', '8580_287363_000004_000000_gen.wav', '8580_287364_000014_000002_gen.wav', '8580_287364_000019_000000_gen.wav', '8580_287364_000031_000001_gen.wav', '8580_287364_000075_000000_gen.wav', '8609_283227_000027_000000_gen.wav', '8629_261139_000039_000003_gen.wav', '8630_305212_000009_000001_gen.wav', '8630_305212_000011_000005_gen.wav', '8630_305213_000003_000002_gen.wav', '8630_305213_000011_000004_gen.wav', '8747_293952_000004_000002_gen.wav', '8747_293952_000031_000001_gen.wav', '8747_293952_000062_000000_gen.wav', '8747_293952_000097_000007_gen.wav', '8770_295462_000027_000000_gen.wav', '8770_295463_000024_000001_gen.wav', '8770_295465_000017_000003_gen.wav', '8770_295465_000021_000000_gen.wav', '8770_295465_000050_000002_gen.wav', '87_121553_000042_000000_gen.wav', '87_121553_000043_000000_gen.wav', '87_121553_000062_000000_gen.wav', '87_121553_000070_000000_gen.wav', '87_121553_000086_000000_gen.wav', '87_121553_000101_000000_gen.wav', '87_121553_000185_000000_gen.wav', '8838_298545_000000_000000_gen.wav', '8838_298545_000051_000001_gen.wav', '8838_298546_000011_000000_gen.wav', '887_123289_000014_000000_gen.wav', '887_123289_000038_000001_gen.wav', '887_123290_000007_000000_gen.wav', '887_123290_000023_000002_gen.wav', '887_123291_000031_000002_gen.wav']\n",
            "\n",
            "\n",
            "\n",
            " Class wavegrad: Files: ['1040_133433_000072_000001_gen.wav', '1069_133699_000066_000006_gen.wav', '1088_129236_000006_000007_gen.wav', '1088_129236_000020_000013_gen.wav', '1088_129236_000031_000005_gen.wav', '1088_134318_000019_000001_gen.wav', '1098_133695_000003_000003_gen.wav', '1098_133695_000045_000002_gen.wav', '1116_132847_000023_000000_gen.wav', '1116_132851_000013_000000_gen.wav', '1116_137572_000004_000001_gen.wav', '1116_137572_000038_000000_gen.wav', '1183_133255_000021_000002_gen.wav', '1183_133256_000051_000002_gen.wav', '1246_124550_000012_000002_gen.wav', '1246_124550_000028_000003_gen.wav', '1246_135815_000017_000003_gen.wav', '125_121124_000046_000000_gen.wav', '125_121124_000049_000000_gen.wav', '1263_138246_000005_000000_gen.wav', '1263_141777_000009_000000_gen.wav', '1263_141777_000033_000002_gen.wav', '1263_141777_000034_000003_gen.wav', '1263_141777_000037_000002_gen.wav', '1334_135589_000007_000000_gen.wav', '1355_39947_000002_000006_gen.wav', '1355_39947_000004_000002_gen.wav', '1355_39947_000005_000019_gen.wav', '1355_39947_000006_000009_gen.wav', '1355_39947_000013_000009_gen.wav', '1355_39947_000016_000007_gen.wav', '1355_39947_000018_000001_gen.wav', '1355_39947_000022_000010_gen.wav', '1355_39947_000024_000011_gen.wav', '1355_39947_000024_000014_gen.wav', '1363_139304_000010_000002_gen.wav', '1363_139304_000018_000001_gen.wav', '1447_17506_000015_000001_gen.wav', '1502_122615_000047_000005_gen.wav', '1502_122619_000033_000000_gen.wav', '1502_122619_000033_000001_gen.wav', '1502_122619_000043_000001_gen.wav', '1502_122619_000054_000003_gen.wav', '1553_140048_000002_000003_gen.wav', '1553_140048_000032_000000_gen.wav', '1553_140048_000057_000004_gen.wav', '1624_142933_000013_000001_gen.wav', '1624_168623_000011_000001_gen.wav', '1737_148989_000013_000000_gen.wav', '1743_142914_000007_000003_gen.wav', '1743_142914_000018_000003_gen.wav', '1841_150351_000008_000000_gen.wav', '1841_159771_000064_000002_gen.wav', '1841_179183_000015_000003_gen.wav', '1867_154071_000011_000002_gen.wav', '1867_154071_000013_000000_gen.wav', '1963_142393_000005_000008_gen.wav', '196_122150_000003_000005_gen.wav', '196_122150_000009_000001_gen.wav', '196_122152_000009_000008_gen.wav', '196_122159_000008_000001_gen.wav', '1970_26100_000020_000003_gen.wav', '1970_26100_000037_000001_gen.wav', '2002_139469_000012_000001_gen.wav', '2002_139469_000013_000003_gen.wav', '2002_139469_000022_000001_gen.wav', '2002_139469_000024_000005_gen.wav', '200_124140_000019_000000_gen.wav', '200_126784_000091_000000_gen.wav', '201_122255_000011_000000_gen.wav', '201_122255_000050_000003_gen.wav', '2092_145706_000004_000001_gen.wav', '2092_145706_000007_000000_gen.wav', '2092_145706_000029_000002_gen.wav', '2092_145706_000046_000000_gen.wav', '2136_5143_000024_000001_gen.wav', '2159_179154_000012_000006_gen.wav', '2196_170379_000010_000001_gen.wav', '2289_152253_000019_000000_gen.wav', '2289_152254_000025_000000_gen.wav', '2289_152257_000015_000002_gen.wav', '2436_2477_000017_000003_gen.wav', '250_142276_000013_000001_gen.wav', '250_142276_000014_000004_gen.wav', '250_142286_000022_000000_gen.wav', '250_142286_000031_000004_gen.wav', '2518_154826_000017_000000_gen.wav', '26_495_000052_000000_gen.wav', '26_496_000004_000000_gen.wav', '26_496_000023_000000_gen.wav', '26_496_000029_000000_gen.wav', '27_123349_000001_000001_gen.wav', '27_124992_000034_000001_gen.wav', '27_124992_000105_000001_gen.wav', '2817_142380_000007_000000_gen.wav', '2836_5354_000015_000002_gen.wav', '2843_152918_000018_000004_gen.wav', '2893_139322_000009_000003_gen.wav', '2910_131096_000014_000001_gen.wav', '2910_131096_000039_000000_gen.wav', '2911_12359_000011_000002_gen.wav', '2911_15045_000005_000003_gen.wav', '2911_15045_000006_000002_gen.wav', '298_126791_000022_000000_gen.wav', '298_126791_000039_000000_gen.wav', '298_126791_000078_000001_gen.wav', '302_123516_000008_000000_gen.wav', '302_123516_000009_000001_gen.wav', '302_123516_000017_000000_gen.wav', '3112_9555_000020_000007_gen.wav', '3168_173564_000018_000000_gen.wav', '3168_173565_000019_000003_gen.wav', '3168_173565_000020_000004_gen.wav', '3168_173565_000024_000004_gen.wav', '3235_28452_000004_000001_gen.wav', '3235_28452_000007_000000_gen.wav', '3240_131231_000058_000000_gen.wav', '3242_67153_000010_000001_gen.wav', '3242_67153_000016_000007_gen.wav', '3242_67153_000020_000004_gen.wav', '3259_158083_000022_000002_gen.wav', '3259_158083_000068_000000_gen.wav', '3259_158083_000083_000010_gen.wav', '32_21631_000009_000001_gen.wav', '32_21634_000020_000002_gen.wav', '32_4137_000006_000003_gen.wav', '32_4137_000023_000005_gen.wav', '3436_172162_000012_000005_gen.wav', '3436_172171_000005_000003_gen.wav', '3440_171009_000013_000000_gen.wav', '3526_176651_000012_000016_gen.wav', '3526_176653_000001_000006_gen.wav', '3526_176653_000002_000007_gen.wav', '3526_176653_000062_000002_gen.wav', '3526_176653_000083_000004_gen.wav', '3526_176653_000089_000001_gen.wav', '3664_178355_000014_000000_gen.wav', '3664_178366_000010_000004_gen.wav', '3664_178366_000019_000002_gen.wav', '3699_47246_000003_000003_gen.wav', '374_180298_000011_000003_gen.wav', '374_180298_000025_000000_gen.wav', '374_180298_000057_000001_gen.wav', '374_180299_000041_000005_gen.wav', '3830_12529_000021_000000_gen.wav', '3830_12530_000043_000000_gen.wav', '3830_12530_000051_000000_gen.wav', '3830_12530_000051_000001_gen.wav', '3830_12531_000009_000002_gen.wav', '3830_12531_000010_000002_gen.wav', '3830_12531_000035_000004_gen.wav', '3830_12535_000016_000002_gen.wav', '3830_12535_000027_000006_gen.wav', '3830_12535_000033_000002_gen.wav', '3857_182315_000036_000002_gen.wav', '3879_174923_000002_000004_gen.wav', '3879_174923_000003_000005_gen.wav', '3879_174923_000020_000006_gen.wav', '3982_178459_000062_000000_gen.wav', '3982_182255_000015_000000_gen.wav', '3983_5331_000049_000000_gen.wav', '3983_5371_000062_000000_gen.wav', '4014_186175_000045_000000_gen.wav', '4018_103416_000017_000000_gen.wav', '4018_107338_000014_000004_gen.wav', '4051_10927_000010_000000_gen.wav', '4051_11217_000004_000002_gen.wav', '4051_11217_000020_000002_gen.wav', '4051_11218_000037_000001_gen.wav', '405_130894_000076_000000_gen.wav', '405_130894_000077_000000_gen.wav', '405_130894_000087_000000_gen.wav', '405_130895_000007_000000_gen.wav', '4088_158077_000111_000001_gen.wav', '40_121026_000014_000000_gen.wav', '40_121026_000054_000002_gen.wav', '40_121026_000069_000000_gen.wav', '40_121026_000169_000001_gen.wav', '40_121026_000184_000001_gen.wav', '40_121026_000190_000002_gen.wav', '40_121026_000197_000000_gen.wav', '40_222_000012_000001_gen.wav', '40_222_000017_000000_gen.wav', '40_222_000041_000004_gen.wav', '412_126975_000024_000003_gen.wav', '412_126975_000046_000003_gen.wav', '412_126975_000054_000003_gen.wav', '412_126975_000059_000001_gen.wav', '412_126975_000065_000000_gen.wav', '412_126975_000069_000001_gen.wav', '412_126975_000070_000001_gen.wav', '4137_11702_000016_000004_gen.wav', '4160_11550_000021_000000_gen.wav', '4160_14187_000038_000004_gen.wav', '4195_17507_000046_000000_gen.wav', '4195_186237_000043_000000_gen.wav', '4267_287369_000041_000002_gen.wav', '4267_72637_000026_000001_gen.wav', '4267_72637_000039_000000_gen.wav', '4267_78186_000005_000001_gen.wav', '4297_13006_000057_000000_gen.wav', '4397_15666_000004_000001_gen.wav', '4397_15668_000007_000000_gen.wav', '4397_15668_000009_000004_gen.wav', '4397_15668_000013_000002_gen.wav', '4406_16882_000005_000003_gen.wav', '4406_16882_000017_000007_gen.wav', '4406_16883_000001_000003_gen.wav', '4406_16883_000009_000001_gen.wav', '4406_16883_000009_000003_gen.wav', '4406_16883_000014_000017_gen.wav', '4406_16883_000019_000021_gen.wav', '4406_16883_000021_000004_gen.wav', '446_123501_000002_000002_gen.wav', '446_123502_000003_000001_gen.wav', '460_172359_000001_000000_gen.wav', '460_172359_000013_000001_gen.wav', '4640_19187_000023_000003_gen.wav', '4640_19188_000021_000054_gen.wav', '4680_16026_000013_000000_gen.wav', '4680_16026_000062_000001_gen.wav', '4680_16026_000136_000000_gen.wav', '4680_16041_000011_000000_gen.wav', '4680_16042_000018_000005_gen.wav', '4788_294466_000006_000001_gen.wav', '4788_91208_000006_000004_gen.wav', '4788_91208_000008_000005_gen.wav', '4788_91208_000009_000005_gen.wav', '4788_94904_000005_000009_gen.wav', '4813_248638_000006_000004_gen.wav', '4813_248638_000023_000002_gen.wav', '4813_248641_000015_000003_gen.wav', '4830_25898_000006_000001_gen.wav', '5163_18515_000027_000002_gen.wav', '5322_7678_000006_000014_gen.wav', '5322_7679_000002_000016_gen.wav', '5322_7679_000018_000002_gen.wav', '5322_7679_000020_000001_gen.wav', '5322_7679_000021_000001_gen.wav', '5322_7680_000013_000000_gen.wav', '5322_7680_000029_000000_gen.wav', '5322_7680_000055_000004_gen.wav', '5339_14133_000018_000006_gen.wav', '5339_14133_000020_000002_gen.wav', '5339_14133_000020_000005_gen.wav', '5339_14134_000041_000006_gen.wav', '5339_14134_000051_000000_gen.wav', '5339_14134_000091_000009_gen.wav', '5390_24512_000046_000003_gen.wav', '5393_19218_000029_000007_gen.wav', '5393_19219_000012_000002_gen.wav', '5514_19193_000028_000000_gen.wav', '5561_41615_000017_000001_gen.wav', '5561_41615_000022_000001_gen.wav', '5561_41616_000015_000000_gen.wav', '5652_39938_000003_000001_gen.wav', '5652_39938_000014_000005_gen.wav', '5678_43301_000020_000000_gen.wav', '5678_43302_000025_000006_gen.wav', '5703_47212_000044_000000_gen.wav', '5750_100289_000007_000004_gen.wav', '5750_100289_000037_000005_gen.wav', '5750_100289_000039_000002_gen.wav', '5778_12761_000013_000003_gen.wav', '5867_48852_000005_000001_gen.wav', '5867_48852_000083_000006_gen.wav', '5867_48852_000085_000001_gen.wav', '587_54108_000035_000003_gen.wav', '6019_3185_000014_000007_gen.wav', '6019_3185_000026_000005_gen.wav', '6019_3185_000028_000000_gen.wav', '6019_3185_000029_000008_gen.wav', '6019_3185_000032_000003_gen.wav', '6064_56165_000014_000001_gen.wav', '6064_56168_000002_000000_gen.wav', '6078_54007_000015_000001_gen.wav', '6078_54007_000046_000001_gen.wav', '6078_54013_000027_000004_gen.wav', '6081_41997_000021_000000_gen.wav', '6081_41997_000022_000000_gen.wav', '6081_42010_000034_000000_gen.wav', '60_121082_000039_000000_gen.wav', '60_121082_000066_000000_gen.wav', '6147_34605_000006_000007_gen.wav', '6147_34606_000012_000006_gen.wav', '6147_34607_000005_000003_gen.wav', '6181_216552_000041_000003_gen.wav', '6209_34599_000023_000001_gen.wav', '6209_34600_000004_000002_gen.wav', '6272_70168_000047_000000_gen.wav', '6272_70168_000050_000006_gen.wav', '6272_70191_000025_000001_gen.wav', '6367_65536_000004_000002_gen.wav', '6367_65536_000015_000001_gen.wav', '6367_65536_000017_000004_gen.wav', '6367_65536_000026_000002_gen.wav', '6367_65536_000033_000003_gen.wav', '6367_74004_000019_000002_gen.wav', '6415_100596_000067_000001_gen.wav', '6415_116629_000015_000004_gen.wav', '6415_116629_000031_000004_gen.wav', '6437_66172_000024_000000_gen.wav', '6437_66173_000005_000000_gen.wav', '6437_66173_000005_000002_gen.wav', '6437_66173_000058_000003_gen.wav', '6454_120342_000015_000005_gen.wav', '6454_120342_000024_000002_gen.wav', '6454_120342_000024_000003_gen.wav', '6454_93938_000032_000000_gen.wav', '6476_57446_000023_000000_gen.wav', '6476_57446_000045_000000_gen.wav', '6476_96661_000002_000002_gen.wav', '6476_96661_000005_000000_gen.wav', '6476_96661_000018_000005_gen.wav', '6476_96661_000019_000001_gen.wav', '6529_62554_000015_000001_gen.wav', '6529_62554_000023_000000_gen.wav', '6529_62554_000057_000002_gen.wav', '6529_62554_000075_000001_gen.wav', '6529_62556_000097_000004_gen.wav', '6818_68772_000033_000002_gen.wav', '6818_76332_000014_000003_gen.wav', '6818_76332_000025_000001_gen.wav', '6818_76332_000036_000000_gen.wav', '6818_76332_000038_000001_gen.wav', '6836_61803_000050_000001_gen.wav', '6836_61804_000030_000000_gen.wav', '6848_252323_000034_000001_gen.wav', '6848_252323_000050_000001_gen.wav', '6848_76049_000004_000000_gen.wav', '696_92939_000012_000004_gen.wav', '696_92939_000016_000001_gen.wav', '696_93314_000005_000010_gen.wav', '696_93314_000018_000004_gen.wav', '696_93314_000027_000002_gen.wav', '696_93314_000043_000002_gen.wav', '7059_88364_000004_000000_gen.wav', '7059_88364_000007_000003_gen.wav', '7078_271888_000030_000000_gen.wav', '7078_271888_000118_000001_gen.wav', '7113_86041_000045_000000_gen.wav', '7113_86041_000051_000002_gen.wav', '7113_86041_000052_000001_gen.wav', '7178_34644_000048_000005_gen.wav', '7178_34644_000102_000000_gen.wav', '7178_34645_000004_000002_gen.wav', '7178_34645_000009_000000_gen.wav', '7178_34645_000009_000003_gen.wav', '7178_34645_000027_000000_gen.wav', '7178_34645_000028_000010_gen.wav', '7178_34645_000040_000001_gen.wav', '7178_34645_000041_000001_gen.wav', '7178_34645_000042_000002_gen.wav', '7178_34645_000043_000001_gen.wav', '7190_90542_000093_000000_gen.wav', '7278_246956_000010_000000_gen.wav', '7278_91083_000011_000002_gen.wav', '7302_86815_000021_000004_gen.wav', '7302_86815_000056_000000_gen.wav', '7302_86815_000056_000001_gen.wav', '730_358_000010_000007_gen.wav', '7367_86737_000125_000001_gen.wav', '7367_86737_000132_000012_gen.wav', '7402_59171_000010_000010_gen.wav', '7402_59171_000019_000002_gen.wav', '7402_59171_000020_000004_gen.wav', '7402_59171_000021_000001_gen.wav', '7402_59171_000022_000000_gen.wav', '7402_90848_000006_000001_gen.wav', '7402_90848_000021_000000_gen.wav', '7402_90848_000046_000001_gen.wav', '7447_91186_000016_000001_gen.wav', '7447_91186_000017_000004_gen.wav', '7447_91186_000018_000002_gen.wav', '7447_91186_000018_000005_gen.wav', '7447_91186_000024_000000_gen.wav', '7447_91187_000005_000001_gen.wav', '7447_91187_000016_000004_gen.wav', '7447_91187_000020_000000_gen.wav', '7505_258958_000022_000002_gen.wav', '7505_258958_000022_000003_gen.wav', '7505_258958_000033_000007_gen.wav', '7505_258964_000004_000002_gen.wav', '7505_258964_000005_000000_gen.wav', '7505_258964_000005_000002_gen.wav', '7505_258964_000030_000005_gen.wav', '7505_258964_000034_000001_gen.wav', '7505_83618_000015_000004_gen.wav', '7511_102419_000006_000005_gen.wav', '7511_102419_000021_000001_gen.wav', '7511_102419_000024_000002_gen.wav', '7511_102420_000009_000007_gen.wav', '7511_102420_000019_000000_gen.wav', '7511_102420_000027_000005_gen.wav', '7517_100429_000006_000006_gen.wav', '7517_100437_000006_000001_gen.wav', '7517_100437_000008_000004_gen.wav', '7517_100442_000003_000002_gen.wav', '7780_274562_000007_000003_gen.wav', '7780_274562_000013_000005_gen.wav', '7794_295955_000003_000004_gen.wav', '7800_283478_000034_000001_gen.wav', '7800_283492_000036_000003_gen.wav', '7800_283492_000043_000000_gen.wav', '7800_283493_000028_000000_gen.wav', '7859_102519_000005_000000_gen.wav', '7859_102519_000015_000006_gen.wav', '7859_102521_000017_000006_gen.wav', '78_368_000011_000013_gen.wav', '78_369_000005_000000_gen.wav', '78_369_000006_000004_gen.wav', '78_369_000011_000002_gen.wav', '8014_112586_000011_000000_gen.wav', '8014_112602_000016_000002_gen.wav', '8051_295385_000013_000001_gen.wav', '8063_274112_000196_000000_gen.wav', '8088_284756_000038_000001_gen.wav', '8088_284756_000138_000001_gen.wav', '8088_284756_000162_000001_gen.wav', '8098_275181_000006_000000_gen.wav', '8098_275181_000025_000002_gen.wav', '8098_278252_000007_000001_gen.wav', '8098_278252_000027_000000_gen.wav', '8098_278278_000007_000000_gen.wav', '8108_280354_000004_000000_gen.wav', '8108_280354_000010_000001_gen.wav', '8108_280354_000015_000001_gen.wav', '8108_280359_000006_000002_gen.wav', '8123_275209_000013_000002_gen.wav', '8123_275209_000025_000000_gen.wav', '8123_275216_000005_000000_gen.wav', '8123_275216_000009_000003_gen.wav', '8123_275216_000010_000000_gen.wav', '8123_275216_000034_000001_gen.wav', '8123_275216_000054_000004_gen.wav', '8226_274371_000017_000003_gen.wav', '8226_274371_000020_000006_gen.wav', '8238_283452_000028_000001_gen.wav', '8238_283452_000033_000009_gen.wav', '8312_279790_000002_000005_gen.wav', '8312_279790_000003_000002_gen.wav', '8312_279790_000048_000004_gen.wav', '8312_279791_000014_000006_gen.wav', '831_130739_000008_000002_gen.wav', '831_130746_000052_000000_gen.wav', '8324_286682_000026_000002_gen.wav', '8324_286683_000008_000006_gen.wav', '8468_286673_000004_000001_gen.wav', '8468_286673_000025_000002_gen.wav', '8468_295198_000009_000002_gen.wav', '8468_295198_000029_000001_gen.wav', '8580_287364_000032_000003_gen.wav', '8609_262281_000052_000000_gen.wav', '8609_283227_000097_000000_gen.wav', '8629_261139_000010_000003_gen.wav', '8630_305212_000006_000003_gen.wav', '8630_305212_000010_000003_gen.wav', '8630_305213_000006_000003_gen.wav', '8770_295465_000004_000002_gen.wav', '8770_295465_000017_000003_gen.wav', '8770_295465_000022_000000_gen.wav', '8797_294123_000006_000000_gen.wav', '8797_294123_000011_000007_gen.wav', '8797_294123_000028_000003_gen.wav', '87_121553_000014_000000_gen.wav', '87_121553_000156_000000_gen.wav', '87_121553_000231_000000_gen.wav', '87_121553_000247_000000_gen.wav', '8838_298545_000013_000001_gen.wav', '8838_298545_000032_000000_gen.wav', '8838_298545_000034_000005_gen.wav', '8838_298546_000021_000011_gen.wav', '8975_270782_000006_000001_gen.wav', '8975_270782_000013_000004_gen.wav', '8975_270782_000024_000003_gen.wav']\n",
            "\n",
            "\n",
            "\n",
            " Class wavenet: Files: ['1034_121119_000028_000001_gen.wav', '1088_129236_000011_000000_gen.wav', '1088_129236_000028_000011_gen.wav', '1088_129236_000031_000005_gen.wav', '1088_134315_000030_000003_gen.wav', '1088_134318_000047_000000_gen.wav', '1098_133695_000013_000012_gen.wav', '1116_132847_000007_000000_gen.wav', '1116_132851_000014_000000_gen.wav', '1116_132851_000038_000003_gen.wav', '1116_137572_000004_000001_gen.wav', '1183_133255_000043_000000_gen.wav', '1183_133256_000075_000000_gen.wav', '118_47824_000071_000004_gen.wav', '1235_135884_000011_000002_gen.wav', '1246_124550_000004_000005_gen.wav', '1246_124550_000017_000004_gen.wav', '1246_124550_000018_000003_gen.wav', '125_121124_000027_000000_gen.wav', '125_121124_000054_000000_gen.wav', '125_121124_000068_000000_gen.wav', '1263_139804_000015_000002_gen.wav', '1263_141777_000016_000000_gen.wav', '1334_135589_000007_000000_gen.wav', '1334_135589_000020_000000_gen.wav', '1334_135589_000038_000000_gen.wav', '1334_135589_000052_000000_gen.wav', '1355_39947_000001_000001_gen.wav', '1355_39947_000016_000003_gen.wav', '1355_39947_000017_000007_gen.wav', '1355_39947_000020_000000_gen.wav', '1355_39947_000021_000011_gen.wav', '1447_17506_000010_000001_gen.wav', '1502_122615_000029_000001_gen.wav', '1502_122615_000036_000007_gen.wav', '1502_122615_000038_000004_gen.wav', '1502_122615_000043_000002_gen.wav', '1502_122615_000048_000000_gen.wav', '1502_122619_000026_000000_gen.wav', '1502_122619_000033_000000_gen.wav', '1502_122619_000050_000000_gen.wav', '150_126107_000025_000000_gen.wav', '1553_140048_000004_000002_gen.wav', '1578_140045_000046_000007_gen.wav', '1624_168623_000008_000000_gen.wav', '1737_142396_000011_000000_gen.wav', '1737_146161_000019_000000_gen.wav', '1743_142912_000009_000001_gen.wav', '1743_142914_000009_000002_gen.wav', '1743_142914_000019_000002_gen.wav', '1743_142914_000023_000005_gen.wav', '1841_150351_000001_000000_gen.wav', '1841_159771_000037_000005_gen.wav', '1841_179183_000011_000002_gen.wav', '1841_179183_000012_000006_gen.wav', '1841_179183_000018_000003_gen.wav', '1867_154075_000080_000002_gen.wav', '1926_147979_000006_000003_gen.wav', '1963_142393_000015_000002_gen.wav', '196_122150_000003_000002_gen.wav', '196_122152_000005_000004_gen.wav', '196_122152_000008_000003_gen.wav', '196_122152_000009_000000_gen.wav', '1970_26100_000009_000000_gen.wav', '1970_28415_000039_000000_gen.wav', '1970_28415_000051_000000_gen.wav', '1992_141719_000016_000015_gen.wav', '2002_139469_000012_000004_gen.wav', '2002_139469_000013_000006_gen.wav', '200_124139_000002_000000_gen.wav', '200_124140_000002_000002_gen.wav', '200_124140_000035_000003_gen.wav', '200_126784_000027_000000_gen.wav', '200_126784_000032_000000_gen.wav', '200_126784_000053_000000_gen.wav', '200_126784_000073_000001_gen.wav', '200_126784_000091_000001_gen.wav', '201_122255_000001_000001_gen.wav', '2136_5140_000018_000000_gen.wav', '2136_5143_000024_000001_gen.wav', '2136_5147_000017_000001_gen.wav', '2136_5147_000043_000001_gen.wav', '2182_181183_000041_000000_gen.wav', '2196_170151_000008_000002_gen.wav', '2196_170151_000013_000002_gen.wav', '2289_152254_000006_000002_gen.wav', '2289_152257_000014_000000_gen.wav', '2289_152257_000015_000000_gen.wav', '2289_152257_000021_000000_gen.wav', '2416_152139_000063_000008_gen.wav', '2416_152139_000063_000009_gen.wav', '2436_2476_000004_000006_gen.wav', '2436_2477_000028_000002_gen.wav', '2436_2481_000000_000002_gen.wav', '250_142286_000019_000001_gen.wav', '2514_149482_000004_000010_gen.wav', '2514_149482_000006_000003_gen.wav', '2514_149482_000006_000006_gen.wav', '2518_154825_000012_000002_gen.wav', '254_145458_000014_000001_gen.wav', '254_27760_000008_000000_gen.wav', '254_27760_000018_000005_gen.wav', '2691_156750_000028_000003_gen.wav', '2691_156755_000010_000002_gen.wav', '26_495_000057_000001_gen.wav', '27_123349_000006_000006_gen.wav', '27_123349_000008_000005_gen.wav', '27_124992_000147_000001_gen.wav', '27_124992_000148_000001_gen.wav', '27_124992_000158_000001_gen.wav', '2817_142380_000003_000002_gen.wav', '2836_5354_000013_000001_gen.wav', '2836_5354_000022_000000_gen.wav', '2836_5354_000031_000000_gen.wav', '2836_5354_000049_000001_gen.wav', '2836_5355_000008_000000_gen.wav', '2843_152918_000001_000003_gen.wav', '2843_152918_000006_000003_gen.wav', '2843_152918_000009_000004_gen.wav', '2843_152918_000010_000001_gen.wav', '2843_152918_000016_000006_gen.wav', '2893_139322_000014_000003_gen.wav', '2910_131096_000026_000001_gen.wav', '2910_131096_000036_000002_gen.wav', '298_126791_000008_000001_gen.wav', '298_126791_000040_000008_gen.wav', '3168_173564_000007_000000_gen.wav', '3168_173565_000022_000003_gen.wav', '3235_28433_000003_000001_gen.wav', '3240_131231_000014_000000_gen.wav', '3240_131231_000056_000000_gen.wav', '3242_67153_000016_000007_gen.wav', '3259_158083_000004_000001_gen.wav', '3259_158083_000077_000004_gen.wav', '3259_158083_000092_000001_gen.wav', '32_4137_000026_000000_gen.wav', '32_4137_000041_000000_gen.wav', '3436_172171_000008_000014_gen.wav', '3440_171009_000078_000000_gen.wav', '3486_166446_000065_000001_gen.wav', '3526_176651_000012_000008_gen.wav', '3526_176653_000080_000007_gen.wav', '3526_176653_000085_000003_gen.wav', '3607_29116_000018_000002_gen.wav', '3664_11714_000032_000000_gen.wav', '3664_178355_000003_000000_gen.wav', '3664_178355_000008_000000_gen.wav', '3699_19401_000009_000000_gen.wav', '374_180299_000045_000002_gen.wav', '3830_12529_000018_000000_gen.wav', '3830_12531_000008_000001_gen.wav', '3830_12535_000005_000000_gen.wav', '3830_12535_000008_000002_gen.wav', '3830_12535_000010_000001_gen.wav', '3857_182315_000028_000003_gen.wav', '3857_182315_000033_000000_gen.wav', '3857_182317_000019_000001_gen.wav', '3879_173592_000007_000007_gen.wav', '3879_173592_000021_000004_gen.wav', '3879_173592_000025_000002_gen.wav', '3879_173592_000026_000004_gen.wav', '3879_174923_000002_000002_gen.wav', '3879_174923_000017_000004_gen.wav', '3879_174923_000035_000010_gen.wav', '3982_178459_000048_000001_gen.wav', '3982_178459_000056_000005_gen.wav', '3982_178459_000056_000008_gen.wav', '3982_182255_000049_000004_gen.wav', '4014_186175_000045_000000_gen.wav', '4018_103416_000070_000003_gen.wav', '4018_107312_000032_000001_gen.wav', '4051_11218_000021_000003_gen.wav', '405_130894_000076_000000_gen.wav', '4088_158079_000157_000003_gen.wav', '40_121026_000006_000000_gen.wav', '40_121026_000018_000002_gen.wav', '40_121026_000054_000003_gen.wav', '40_121026_000089_000002_gen.wav', '40_121026_000184_000001_gen.wav', '40_121026_000212_000001_gen.wav', '40_222_000002_000009_gen.wav', '40_222_000011_000005_gen.wav', '412_126975_000003_000001_gen.wav', '412_126975_000005_000000_gen.wav', '412_126975_000022_000001_gen.wav', '412_126975_000022_000002_gen.wav', '412_126975_000025_000002_gen.wav', '412_126975_000042_000008_gen.wav', '412_126975_000080_000001_gen.wav', '412_126975_000081_000000_gen.wav', '412_126975_000084_000000_gen.wav', '4137_11701_000003_000001_gen.wav', '4137_11702_000006_000002_gen.wav', '4137_11702_000035_000000_gen.wav', '4160_11549_000035_000001_gen.wav', '4160_11550_000043_000001_gen.wav', '4160_14187_000050_000000_gen.wav', '4195_186236_000003_000003_gen.wav', '4195_186237_000010_000001_gen.wav', '4195_186238_000053_000003_gen.wav', '4267_287369_000031_000001_gen.wav', '4267_72637_000024_000001_gen.wav', '4267_78186_000002_000002_gen.wav', '4267_78186_000007_000014_gen.wav', '4267_78186_000012_000000_gen.wav', '426_122821_000053_000013_gen.wav', '4297_13006_000021_000000_gen.wav', '4297_13006_000055_000001_gen.wav', '4397_15678_000004_000002_gen.wav', '4406_16883_000002_000002_gen.wav', '4406_16883_000017_000006_gen.wav', '4406_16883_000021_000002_gen.wav', '446_123501_000017_000000_gen.wav', '446_123501_000032_000000_gen.wav', '446_123502_000005_000001_gen.wav', '460_172357_000004_000005_gen.wav', '460_172357_000010_000003_gen.wav', '460_172359_000034_000002_gen.wav', '460_172359_000056_000003_gen.wav', '4640_19188_000021_000043_gen.wav', '4640_19188_000021_000054_gen.wav', '4640_19189_000011_000000_gen.wav', '4788_294466_000013_000004_gen.wav', '4788_91208_000007_000007_gen.wav', '4788_91208_000009_000005_gen.wav', '4788_94904_000004_000003_gen.wav', '4788_94904_000004_000005_gen.wav', '4788_94904_000008_000004_gen.wav', '4813_248638_000010_000005_gen.wav', '4813_248638_000021_000001_gen.wav', '4813_248638_000022_000002_gen.wav', '4813_248638_000022_000004_gen.wav', '5163_18515_000036_000000_gen.wav', '5163_39921_000014_000000_gen.wav', '5163_39921_000026_000007_gen.wav', '5163_39921_000044_000005_gen.wav', '5322_7678_000004_000016_gen.wav', '5322_7678_000007_000002_gen.wav', '5322_7679_000002_000000_gen.wav', '5322_7679_000002_000010_gen.wav', '5322_7679_000003_000000_gen.wav', '5322_7680_000024_000001_gen.wav', '5339_14133_000017_000002_gen.wav', '5339_14133_000028_000000_gen.wav', '5339_14134_000007_000002_gen.wav', '5339_14134_000010_000001_gen.wav', '5339_14134_000042_000002_gen.wav', '5339_14134_000062_000000_gen.wav', '5339_14134_000071_000000_gen.wav', '5393_19218_000021_000001_gen.wav', '5393_19219_000047_000086_gen.wav', '5514_19192_000006_000006_gen.wav', '5561_39621_000029_000000_gen.wav', '5561_41615_000033_000002_gen.wav', '5561_41616_000033_000001_gen.wav', '5652_39938_000015_000010_gen.wav', '5652_39938_000024_000003_gen.wav', '5678_43301_000006_000000_gen.wav', '5703_47198_000055_000002_gen.wav', '5750_100289_000018_000002_gen.wav', '5750_100289_000020_000008_gen.wav', '5778_12761_000012_000000_gen.wav', '5778_54535_000002_000004_gen.wav', '5778_54535_000010_000004_gen.wav', '5789_70653_000033_000008_gen.wav', '5867_48852_000063_000003_gen.wav', '5867_48852_000084_000006_gen.wav', '587_54108_000006_000000_gen.wav', '6019_3185_000024_000003_gen.wav', '6019_3185_000025_000001_gen.wav', '6019_3185_000031_000000_gen.wav', '6019_3185_000031_000009_gen.wav', '6019_3185_000031_000015_gen.wav', '6064_56165_000003_000004_gen.wav', '6064_56168_000002_000002_gen.wav', '6078_54007_000039_000004_gen.wav', '6078_54007_000046_000000_gen.wav', '6078_54007_000051_000001_gen.wav', '6078_54013_000020_000000_gen.wav', '60_121082_000016_000000_gen.wav', '6147_34605_000004_000004_gen.wav', '6147_34605_000005_000005_gen.wav', '6147_34605_000009_000020_gen.wav', '6147_34606_000021_000000_gen.wav', '6147_34607_000007_000003_gen.wav', '6181_216552_000032_000001_gen.wav', '6181_216552_000033_000000_gen.wav', '6181_216552_000040_000001_gen.wav', '6209_34599_000013_000005_gen.wav', '6209_34599_000023_000001_gen.wav', '6209_34600_000009_000004_gen.wav', '6272_70168_000027_000011_gen.wav', '6272_70171_000035_000001_gen.wav', '6272_70171_000038_000002_gen.wav', '6272_70191_000026_000003_gen.wav', '6367_65536_000003_000001_gen.wav', '6367_65536_000041_000000_gen.wav', '6367_74004_000003_000003_gen.wav', '6385_220959_000017_000001_gen.wav', '6385_220959_000019_000004_gen.wav', '6415_111615_000012_000004_gen.wav', '6415_116629_000014_000000_gen.wav', '6415_116629_000035_000002_gen.wav', '6437_66172_000018_000000_gen.wav', '6437_66173_000010_000000_gen.wav', '6454_107462_000006_000001_gen.wav', '6454_120342_000020_000000_gen.wav', '6454_93938_000015_000002_gen.wav', '6454_93938_000025_000000_gen.wav', '6476_57446_000023_000000_gen.wav', '6476_57446_000024_000000_gen.wav', '6476_57446_000053_000000_gen.wav', '6476_96661_000007_000000_gen.wav', '6529_62554_000077_000000_gen.wav', '6529_62554_000083_000002_gen.wav', '6818_76332_000036_000001_gen.wav', '6836_61803_000061_000000_gen.wav', '6836_61804_000026_000000_gen.wav', '6836_61804_000026_000001_gen.wav', '6848_76049_000004_000000_gen.wav', '6880_216547_000031_000000_gen.wav', '696_92939_000006_000000_gen.wav', '696_92939_000016_000001_gen.wav', '696_93314_000006_000002_gen.wav', '7059_77897_000013_000000_gen.wav', '7059_77897_000013_000001_gen.wav', '7059_77900_000030_000000_gen.wav', '7059_88364_000003_000003_gen.wav', '7059_88364_000008_000002_gen.wav', '7059_88364_000013_000000_gen.wav', '7067_76048_000024_000003_gen.wav', '7067_76048_000048_000000_gen.wav', '7067_76048_000058_000002_gen.wav', '7067_76048_000062_000003_gen.wav', '7078_271888_000004_000001_gen.wav', '7078_271888_000006_000001_gen.wav', '7078_271888_000034_000001_gen.wav', '7078_271888_000040_000002_gen.wav', '7078_271888_000062_000000_gen.wav', '7078_271888_000085_000000_gen.wav', '7178_34645_000009_000000_gen.wav', '7178_34645_000009_000003_gen.wav', '7178_34645_000022_000008_gen.wav', '7178_34645_000040_000001_gen.wav', '7190_90543_000009_000003_gen.wav', '7278_104730_000003_000002_gen.wav', '7302_86814_000002_000005_gen.wav', '7302_86815_000016_000004_gen.wav', '7302_86815_000021_000001_gen.wav', '7302_86815_000070_000008_gen.wav', '7312_92432_000007_000000_gen.wav', '7402_90848_000049_000000_gen.wav', '7402_90848_000056_000000_gen.wav', '7447_91186_000005_000003_gen.wav', '7447_91186_000017_000007_gen.wav', '7447_91186_000018_000002_gen.wav', '7447_91186_000019_000003_gen.wav', '7447_91186_000033_000000_gen.wav', '7447_91186_000035_000000_gen.wav', '7447_91186_000036_000000_gen.wav', '7447_91186_000038_000000_gen.wav', '7447_91187_000005_000001_gen.wav', '7447_91187_000006_000000_gen.wav', '7447_91187_000021_000001_gen.wav', '7505_258958_000010_000002_gen.wav', '7505_258964_000005_000000_gen.wav', '7505_258964_000011_000004_gen.wav', '7505_83618_000007_000005_gen.wav', '7505_83618_000008_000003_gen.wav', '7505_83618_000013_000000_gen.wav', '7511_102419_000011_000000_gen.wav', '7511_102420_000007_000001_gen.wav', '7511_102420_000024_000001_gen.wav', '7511_102420_000027_000003_gen.wav', '7511_102420_000027_000005_gen.wav', '7517_100429_000002_000001_gen.wav', '7517_100437_000007_000003_gen.wav', '7517_100442_000005_000002_gen.wav', '7517_100442_000005_000003_gen.wav', '7780_274562_000009_000001_gen.wav', '7780_274562_000012_000005_gen.wav', '7794_295947_000030_000001_gen.wav', '7794_295948_000009_000003_gen.wav', '7794_295955_000002_000004_gen.wav', '7794_295955_000002_000018_gen.wav', '7794_295955_000002_000031_gen.wav', '7794_295955_000002_000036_gen.wav', '7800_283478_000034_000000_gen.wav', '7800_283492_000041_000000_gen.wav', '7800_283492_000042_000000_gen.wav', '7800_283492_000045_000000_gen.wav', '7800_283493_000026_000001_gen.wav', '7800_283493_000044_000000_gen.wav', '7800_283493_000067_000000_gen.wav', '7859_102519_000005_000000_gen.wav', '7859_102519_000022_000000_gen.wav', '7859_102519_000024_000002_gen.wav', '78_368_000007_000000_gen.wav', '78_368_000011_000013_gen.wav', '78_369_000014_000002_gen.wav', '78_369_000016_000003_gen.wav', '8014_112586_000013_000000_gen.wav', '8014_112602_000003_000005_gen.wav', '8014_112602_000004_000003_gen.wav', '8014_112602_000005_000000_gen.wav', '8051_118101_000012_000004_gen.wav', '8051_118101_000014_000002_gen.wav', '8051_119902_000023_000000_gen.wav', '8051_295385_000014_000001_gen.wav', '8088_284756_000008_000000_gen.wav', '8088_284756_000015_000000_gen.wav', '8088_284756_000025_000001_gen.wav', '8088_284756_000025_000003_gen.wav', '8088_284756_000052_000000_gen.wav', '8088_284756_000134_000001_gen.wav', '8098_275181_000020_000006_gen.wav', '8098_278252_000022_000001_gen.wav', '8098_278278_000017_000004_gen.wav', '8098_278278_000024_000001_gen.wav', '8108_274318_000008_000003_gen.wav', '8108_280354_000018_000000_gen.wav', '8108_280359_000005_000000_gen.wav', '8108_280359_000013_000001_gen.wav', '8123_275193_000014_000000_gen.wav', '8123_275209_000004_000004_gen.wav', '8123_275209_000037_000002_gen.wav', '8123_275209_000046_000000_gen.wav', '8123_275216_000054_000004_gen.wav', '8226_274371_000020_000000_gen.wav', '8238_274553_000012_000000_gen.wav', '8238_274553_000028_000002_gen.wav', '8238_283452_000026_000007_gen.wav', '8238_283452_000026_000009_gen.wav', '8312_279790_000019_000004_gen.wav', '8312_279791_000025_000000_gen.wav', '8312_279791_000028_000001_gen.wav', '8312_279791_000037_000000_gen.wav', '8312_279791_000038_000000_gen.wav', '831_130739_000013_000000_gen.wav', '831_130739_000015_000003_gen.wav', '831_130739_000015_000008_gen.wav', '8324_286682_000007_000001_gen.wav', '8324_286682_000025_000006_gen.wav', '8324_286683_000005_000000_gen.wav', '8465_246942_000005_000006_gen.wav', '8465_246943_000019_000007_gen.wav', '8468_295198_000024_000003_gen.wav', '8580_287363_000016_000000_gen.wav', '8580_287363_000046_000001_gen.wav', '8580_287364_000027_000000_gen.wav', '8580_287364_000032_000000_gen.wav', '8609_262281_000057_000002_gen.wav', '8609_262281_000064_000000_gen.wav', '8609_283227_000009_000002_gen.wav', '8609_283227_000009_000004_gen.wav', '8609_283227_000103_000002_gen.wav', '8629_261139_000018_000001_gen.wav', '8629_261139_000033_000008_gen.wav', '8629_261139_000034_000003_gen.wav', '8630_305212_000009_000003_gen.wav', '8630_305213_000009_000000_gen.wav', '8747_293952_000010_000002_gen.wav', '8747_293952_000017_000004_gen.wav', '8770_295465_000022_000001_gen.wav', '8770_295465_000031_000000_gen.wav', '8797_294123_000003_000000_gen.wav', '8797_294123_000036_000000_gen.wav', '87_121553_000166_000000_gen.wav', '8838_298546_000011_000000_gen.wav', '887_123290_000004_000005_gen.wav', '887_123290_000019_000005_gen.wav', '8975_270782_000014_000001_gen.wav', '89_218_000012_000006_gen.wav', '89_218_000012_000010_gen.wav', '909_131041_000013_000000_gen.wav']\n",
            "\n",
            "\n",
            "\n",
            " Class wavernn: Files: ['103_1241_000042_000001_gen.wav', '1069_133699_000051_000000_gen.wav', '1069_133699_000067_000002_gen.wav', '1088_129236_000005_000001_gen.wav', '1088_129236_000008_000014_gen.wav', '1088_129236_000014_000005_gen.wav', '1088_129236_000026_000001_gen.wav', '1088_129236_000026_000005_gen.wav', '1088_129236_000028_000015_gen.wav', '1088_134315_000030_000001_gen.wav', '1088_134315_000036_000000_gen.wav', '1088_134315_000038_000000_gen.wav', '1088_134315_000096_000001_gen.wav', '1098_133695_000014_000004_gen.wav', '1098_133695_000015_000003_gen.wav', '1116_132851_000045_000000_gen.wav', '1116_137572_000020_000002_gen.wav', '1116_137572_000044_000003_gen.wav', '1183_133255_000032_000000_gen.wav', '1183_133256_000036_000001_gen.wav', '1183_133256_000040_000000_gen.wav', '1235_135884_000005_000004_gen.wav', '1246_124550_000018_000002_gen.wav', '1246_135815_000001_000000_gen.wav', '125_121124_000027_000000_gen.wav', '125_121124_000087_000000_gen.wav', '125_121342_000056_000003_gen.wav', '1263_138246_000005_000000_gen.wav', '1263_138246_000023_000001_gen.wav', '1263_138246_000055_000001_gen.wav', '1263_139804_000015_000002_gen.wav', '1334_135589_000019_000002_gen.wav', '1334_135589_000061_000000_gen.wav', '1355_39947_000012_000001_gen.wav', '1355_39947_000016_000004_gen.wav', '1355_39947_000024_000008_gen.wav', '1355_39947_000025_000003_gen.wav', '1447_17506_000052_000002_gen.wav', '1502_122615_000001_000000_gen.wav', '1502_122615_000013_000004_gen.wav', '1502_122615_000017_000004_gen.wav', '1502_122615_000022_000000_gen.wav', '1502_122615_000026_000000_gen.wav', '1502_122615_000043_000011_gen.wav', '1502_122619_000004_000001_gen.wav', '1502_122619_000052_000002_gen.wav', '1502_122619_000056_000003_gen.wav', '1502_122619_000057_000005_gen.wav', '1553_140047_000018_000001_gen.wav', '1553_140048_000003_000000_gen.wav', '1553_140048_000030_000000_gen.wav', '1594_135914_000010_000003_gen.wav', '1624_142933_000036_000003_gen.wav', '1737_142397_000030_000001_gen.wav', '1737_142397_000036_000002_gen.wav', '1743_142914_000008_000009_gen.wav', '1743_142914_000023_000001_gen.wav', '1841_150351_000019_000000_gen.wav', '1841_150351_000019_000001_gen.wav', '1841_159771_000037_000005_gen.wav', '1841_179183_000019_000001_gen.wav', '1841_179183_000022_000001_gen.wav', '1867_154075_000027_000002_gen.wav', '1963_142776_000050_000002_gen.wav', '196_122150_000003_000006_gen.wav', '196_122150_000006_000005_gen.wav', '196_122152_000010_000000_gen.wav', '196_122159_000002_000003_gen.wav', '196_122159_000011_000009_gen.wav', '2002_139469_000022_000002_gen.wav', '2002_139469_000023_000002_gen.wav', '200_124139_000031_000000_gen.wav', '200_126784_000007_000000_gen.wav', '200_126784_000022_000001_gen.wav', '200_126784_000068_000000_gen.wav', '200_126784_000091_000000_gen.wav', '201_122255_000050_000003_gen.wav', '2092_145706_000007_000000_gen.wav', '2092_145706_000009_000001_gen.wav', '2092_145706_000025_000000_gen.wav', '2092_145706_000029_000000_gen.wav', '2092_145709_000008_000000_gen.wav', '2092_145709_000012_000000_gen.wav', '2136_5140_000005_000003_gen.wav', '2136_5140_000021_000000_gen.wav', '2136_5143_000004_000000_gen.wav', '2136_5143_000012_000001_gen.wav', '2136_5147_000037_000000_gen.wav', '2196_170151_000013_000002_gen.wav', '2196_170379_000017_000001_gen.wav', '226_122538_000026_000002_gen.wav', '2289_152254_000009_000002_gen.wav', '2289_152254_000020_000000_gen.wav', '2289_152257_000002_000000_gen.wav', '2289_152257_000013_000004_gen.wav', '2289_152257_000020_000001_gen.wav', '2436_2481_000019_000002_gen.wav', '250_142276_000015_000002_gen.wav', '250_142276_000015_000008_gen.wav', '250_142286_000011_000008_gen.wav', '250_142286_000056_000000_gen.wav', '2514_149482_000004_000002_gen.wav', '2518_154826_000018_000000_gen.wav', '2518_154826_000027_000001_gen.wav', '254_27760_000013_000004_gen.wav', '2691_156750_000009_000000_gen.wav', '26_496_000011_000001_gen.wav', '26_496_000012_000001_gen.wav', '26_496_000013_000000_gen.wav', '27_123349_000006_000000_gen.wav', '27_123349_000011_000000_gen.wav', '27_123349_000015_000001_gen.wav', '27_124992_000062_000001_gen.wav', '2817_142371_000016_000001_gen.wav', '2836_5354_000007_000002_gen.wav', '2836_5354_000007_000005_gen.wav', '2836_5354_000026_000000_gen.wav', '2836_5355_000026_000000_gen.wav', '2836_5355_000094_000004_gen.wav', '2843_152918_000011_000002_gen.wav', '2843_152918_000013_000001_gen.wav', '2893_139310_000031_000000_gen.wav', '2893_139322_000006_000002_gen.wav', '2893_139322_000017_000003_gen.wav', '2910_131096_000022_000000_gen.wav', '2911_15045_000002_000001_gen.wav', '298_126790_000104_000000_gen.wav', '298_126791_000053_000000_gen.wav', '302_123516_000015_000000_gen.wav', '3112_9554_000001_000002_gen.wav', '3112_9554_000006_000001_gen.wav', '3112_9555_000015_000008_gen.wav', '3112_9555_000020_000016_gen.wav', '3168_173564_000017_000002_gen.wav', '322_124146_000005_000000_gen.wav', '3235_28433_000012_000002_gen.wav', '3235_28433_000015_000001_gen.wav', '3240_131231_000018_000004_gen.wav', '3242_67153_000018_000000_gen.wav', '3242_67153_000024_000002_gen.wav', '3242_8112_000050_000003_gen.wav', '3259_158083_000090_000004_gen.wav', '3259_158083_000092_000001_gen.wav', '32_21631_000011_000001_gen.wav', '32_4137_000005_000003_gen.wav', '32_4137_000007_000000_gen.wav', '32_4137_000025_000000_gen.wav', '332_128985_000004_000004_gen.wav', '3374_298032_000004_000002_gen.wav', '3436_172171_000006_000000_gen.wav', '3440_171009_000074_000000_gen.wav', '3526_175658_000011_000008_gen.wav', '3526_176653_000071_000003_gen.wav', '3526_176653_000080_000007_gen.wav', '3526_176653_000089_000000_gen.wav', '3607_29116_000055_000002_gen.wav', '3664_178355_000024_000000_gen.wav', '3664_178366_000011_000003_gen.wav', '3664_178366_000015_000000_gen.wav', '3664_178366_000016_000000_gen.wav', '3664_178366_000019_000006_gen.wav', '3664_178366_000019_000011_gen.wav', '374_180298_000020_000000_gen.wav', '374_180298_000024_000000_gen.wav', '3830_12530_000011_000001_gen.wav', '3830_12531_000010_000000_gen.wav', '3830_12531_000024_000000_gen.wav', '3830_12531_000039_000001_gen.wav', '3830_12535_000031_000001_gen.wav', '3830_12535_000032_000001_gen.wav', '3857_180923_000007_000000_gen.wav', '3857_182315_000028_000002_gen.wav', '3857_182317_000010_000002_gen.wav', '3857_182317_000025_000004_gen.wav', '3857_182317_000026_000002_gen.wav', '3879_173592_000011_000001_gen.wav', '3879_173592_000014_000001_gen.wav', '3879_173592_000037_000000_gen.wav', '3879_174923_000019_000013_gen.wav', '3879_174923_000020_000001_gen.wav', '3879_174923_000033_000005_gen.wav', '3982_178459_000040_000001_gen.wav', '3982_182255_000018_000000_gen.wav', '3982_182255_000024_000002_gen.wav', '3982_182255_000066_000002_gen.wav', '3983_5371_000051_000000_gen.wav', '4018_107338_000014_000003_gen.wav', '4018_107338_000028_000000_gen.wav', '403_126855_000013_000001_gen.wav', '4051_10927_000020_000001_gen.wav', '4051_10927_000023_000000_gen.wav', '405_130894_000084_000000_gen.wav', '405_130894_000087_000001_gen.wav', '405_130895_000005_000001_gen.wav', '40_121026_000026_000000_gen.wav', '40_121026_000058_000001_gen.wav', '40_121026_000131_000000_gen.wav', '40_121026_000184_000000_gen.wav', '40_121026_000217_000001_gen.wav', '40_121026_000234_000000_gen.wav', '40_222_000009_000000_gen.wav', '40_222_000027_000000_gen.wav', '412_126975_000005_000003_gen.wav', '412_126975_000045_000000_gen.wav', '412_126975_000057_000000_gen.wav', '412_126975_000057_000001_gen.wav', '412_126975_000087_000009_gen.wav', '412_126975_000089_000002_gen.wav', '4195_17507_000047_000000_gen.wav', '4195_186236_000016_000001_gen.wav', '4195_186237_000043_000000_gen.wav', '4267_287369_000051_000000_gen.wav', '426_122821_000053_000013_gen.wav', '4362_15663_000035_000002_gen.wav', '4397_15678_000002_000002_gen.wav', '4397_15678_000007_000001_gen.wav', '4397_15678_000012_000004_gen.wav', '4397_15678_000013_000003_gen.wav', '4406_16882_000018_000004_gen.wav', '4406_16882_000025_000003_gen.wav', '4406_16883_000002_000005_gen.wav', '4406_16883_000023_000009_gen.wav', '446_123502_000003_000001_gen.wav', '446_123502_000013_000002_gen.wav', '446_123502_000019_000001_gen.wav', '460_172357_000012_000005_gen.wav', '460_172359_000018_000001_gen.wav', '460_172359_000064_000000_gen.wav', '460_172359_000065_000000_gen.wav', '4640_19187_000037_000000_gen.wav', '4640_19188_000021_000042_gen.wav', '4640_19188_000021_000054_gen.wav', '4640_19188_000035_000000_gen.wav', '4680_16042_000005_000000_gen.wav', '4788_91208_000009_000005_gen.wav', '4788_91208_000009_000006_gen.wav', '4788_94904_000008_000006_gen.wav', '4788_94904_000008_000011_gen.wav', '4813_248641_000007_000008_gen.wav', '4813_248641_000016_000000_gen.wav', '481_123720_000043_000003_gen.wav', '4830_25898_000015_000000_gen.wav', '5104_33406_000089_000001_gen.wav', '5163_18515_000053_000000_gen.wav', '5163_39921_000012_000000_gen.wav', '5163_39921_000012_000002_gen.wav', '5163_39921_000038_000001_gen.wav', '5322_7679_000001_000002_gen.wav', '5322_7679_000002_000007_gen.wav', '5322_7679_000018_000004_gen.wav', '5339_14133_000018_000008_gen.wav', '5339_14133_000020_000002_gen.wav', '5339_14133_000025_000001_gen.wav', '5339_14133_000035_000000_gen.wav', '5339_14134_000010_000001_gen.wav', '5390_30102_000003_000000_gen.wav', '5393_19218_000021_000001_gen.wav', '5393_19219_000017_000003_gen.wav', '5393_19219_000054_000002_gen.wav', '5561_41616_000028_000001_gen.wav', '5678_43303_000051_000000_gen.wav', '5750_100289_000006_000000_gen.wav', '5750_100289_000018_000000_gen.wav', '5750_100289_000026_000005_gen.wav', '5750_100289_000035_000000_gen.wav', '5778_12761_000005_000002_gen.wav', '5778_12761_000013_000012_gen.wav', '5778_54535_000020_000002_gen.wav', '5867_48852_000021_000001_gen.wav', '5867_48852_000086_000000_gen.wav', '587_54108_000014_000004_gen.wav', '587_54108_000071_000001_gen.wav', '6000_55211_000048_000001_gen.wav', '6019_3185_000011_000001_gen.wav', '6019_3185_000027_000001_gen.wav', '6064_300880_000016_000000_gen.wav', '6064_300880_000077_000001_gen.wav', '6064_56168_000002_000001_gen.wav', '6064_56168_000037_000003_gen.wav', '6078_54007_000010_000000_gen.wav', '6078_54013_000060_000001_gen.wav', '6081_41998_000029_000004_gen.wav', '6081_42010_000027_000005_gen.wav', '6081_42010_000033_000002_gen.wav', '60_121082_000015_000000_gen.wav', '60_121082_000089_000000_gen.wav', '6147_34605_000005_000009_gen.wav', '6147_34605_000022_000001_gen.wav', '6209_34599_000007_000004_gen.wav', '6209_34599_000010_000001_gen.wav', '6209_34599_000013_000001_gen.wav', '6272_70168_000021_000000_gen.wav', '6272_70168_000050_000007_gen.wav', '6272_70191_000002_000021_gen.wav', '6367_65536_000018_000004_gen.wav', '6367_74004_000033_000000_gen.wav', '6385_220959_000004_000002_gen.wav', '6415_100596_000008_000000_gen.wav', '6415_100596_000066_000001_gen.wav', '6415_111615_000008_000005_gen.wav', '6415_116629_000025_000003_gen.wav', '6437_66172_000021_000003_gen.wav', '6454_107462_000005_000003_gen.wav', '6454_107462_000024_000002_gen.wav', '6454_120342_000013_000003_gen.wav', '6454_120342_000019_000000_gen.wav', '6454_93938_000017_000002_gen.wav', '6454_93938_000026_000002_gen.wav', '6454_93938_000029_000001_gen.wav', '6454_93938_000031_000005_gen.wav', '6476_57446_000032_000000_gen.wav', '6476_57446_000071_000000_gen.wav', '6476_96661_000006_000003_gen.wav', '6529_62554_000017_000004_gen.wav', '6529_62554_000021_000000_gen.wav', '6529_62554_000025_000000_gen.wav', '6818_76332_000022_000002_gen.wav', '6818_76332_000034_000002_gen.wav', '6836_61803_000012_000000_gen.wav', '6836_61803_000044_000003_gen.wav', '6836_61803_000050_000001_gen.wav', '6848_252323_000034_000002_gen.wav', '6848_76049_000005_000010_gen.wav', '6848_76049_000024_000004_gen.wav', '6880_216547_000035_000001_gen.wav', '6880_216547_000050_000002_gen.wav', '6880_216547_000054_000004_gen.wav', '696_92939_000005_000001_gen.wav', '696_92939_000022_000004_gen.wav', '7059_77897_000016_000000_gen.wav', '7059_88364_000003_000004_gen.wav', '7067_76048_000044_000001_gen.wav', '7067_76048_000068_000003_gen.wav', '7078_271888_000004_000003_gen.wav', '7078_271888_000030_000000_gen.wav', '7113_86041_000009_000006_gen.wav', '7113_86041_000034_000000_gen.wav', '7178_34644_000048_000005_gen.wav', '7178_34644_000082_000000_gen.wav', '7178_34644_000099_000000_gen.wav', '7178_34645_000007_000018_gen.wav', '7178_34645_000021_000001_gen.wav', '7178_34645_000021_000002_gen.wav', '7178_34645_000023_000002_gen.wav', '7178_34645_000025_000003_gen.wav', '7190_90542_000098_000000_gen.wav', '7190_90543_000017_000003_gen.wav', '7190_90543_000040_000004_gen.wav', '7190_90543_000045_000000_gen.wav', '7278_104730_000001_000031_gen.wav', '7278_246956_000012_000001_gen.wav', '7278_91083_000012_000000_gen.wav', '7302_86814_000020_000000_gen.wav', '7302_86815_000016_000004_gen.wav', '7302_86815_000017_000000_gen.wav', '730_359_000013_000000_gen.wav', '730_360_000009_000000_gen.wav', '7312_92432_000005_000002_gen.wav', '7312_92432_000008_000005_gen.wav', '7367_86737_000056_000000_gen.wav', '7367_86737_000062_000001_gen.wav', '7367_86737_000074_000000_gen.wav', '7367_86737_000084_000000_gen.wav', '7367_86737_000121_000006_gen.wav', '7367_86737_000122_000011_gen.wav', '7402_90848_000018_000000_gen.wav', '7447_91186_000004_000002_gen.wav', '7447_91186_000015_000004_gen.wav', '7447_91186_000018_000002_gen.wav', '7447_91186_000019_000000_gen.wav', '7447_91186_000031_000002_gen.wav', '7447_91186_000032_000000_gen.wav', '7447_91186_000035_000005_gen.wav', '7447_91187_000009_000001_gen.wav', '7447_91187_000019_000001_gen.wav', '7505_258958_000013_000001_gen.wav', '7505_258958_000029_000004_gen.wav', '7505_258964_000009_000003_gen.wav', '7505_258964_000024_000003_gen.wav', '7505_258964_000028_000002_gen.wav', '7505_83618_000015_000005_gen.wav', '7511_102419_000009_000008_gen.wav', '7511_102420_000007_000005_gen.wav', '7511_102420_000009_000006_gen.wav', '7511_102420_000018_000000_gen.wav', '7511_102420_000029_000000_gen.wav', '7517_100437_000006_000005_gen.wav', '7517_100442_000008_000001_gen.wav', '7635_105409_000109_000000_gen.wav', '7780_274562_000007_000000_gen.wav', '7780_274562_000009_000001_gen.wav', '7780_274562_000013_000005_gen.wav', '7794_295955_000002_000011_gen.wav', '7800_283492_000037_000001_gen.wav', '7800_283492_000039_000001_gen.wav', '7800_283492_000045_000000_gen.wav', '7859_102519_000005_000000_gen.wav', '7859_102519_000016_000001_gen.wav', '78_368_000007_000008_gen.wav', '78_368_000011_000010_gen.wav', '78_368_000011_000013_gen.wav', '78_368_000016_000003_gen.wav', '78_369_000016_000000_gen.wav', '78_369_000073_000002_gen.wav', '8014_112602_000000_000003_gen.wav', '8051_118101_000010_000000_gen.wav', '8051_118101_000014_000007_gen.wav', '8051_119902_000009_000003_gen.wav', '8051_295385_000014_000000_gen.wav', '8051_295385_000016_000001_gen.wav', '8063_274116_000034_000002_gen.wav', '8088_284756_000015_000000_gen.wav', '8088_284756_000038_000004_gen.wav', '8088_284756_000049_000000_gen.wav', '8088_284756_000055_000004_gen.wav', '8088_284756_000059_000000_gen.wav', '8088_284756_000093_000002_gen.wav', '8098_275181_000020_000004_gen.wav', '8098_278252_000017_000000_gen.wav', '8098_278278_000009_000003_gen.wav', '8098_278278_000017_000002_gen.wav', '8108_274318_000004_000002_gen.wav', '8108_274318_000010_000000_gen.wav', '8108_274318_000012_000003_gen.wav', '8108_280354_000011_000000_gen.wav', '8108_280354_000015_000002_gen.wav', '8108_280359_000014_000001_gen.wav', '8123_275193_000004_000004_gen.wav', '8123_275193_000014_000000_gen.wav', '8123_275193_000015_000000_gen.wav', '8123_275216_000010_000000_gen.wav', '8123_275216_000015_000001_gen.wav', '8123_275216_000059_000000_gen.wav', '8226_274371_000025_000000_gen.wav', '8238_274553_000008_000000_gen.wav', '8238_274553_000012_000002_gen.wav', '8238_274553_000027_000001_gen.wav', '8238_274553_000028_000002_gen.wav', '8312_279790_000011_000002_gen.wav', '8312_279790_000018_000003_gen.wav', '8312_279790_000021_000000_gen.wav', '8312_279790_000035_000001_gen.wav', '8312_279790_000051_000002_gen.wav', '8312_279791_000011_000001_gen.wav', '8312_279791_000037_000000_gen.wav', '8312_279791_000053_000001_gen.wav', '831_130739_000009_000000_gen.wav', '831_130739_000011_000007_gen.wav', '8324_286681_000013_000001_gen.wav', '8324_286683_000004_000000_gen.wav', '8468_286673_000013_000003_gen.wav', '8468_286673_000015_000001_gen.wav', '8468_294887_000018_000002_gen.wav', '8468_294887_000023_000002_gen.wav', '8580_287364_000055_000000_gen.wav', '8609_283227_000009_000005_gen.wav', '8609_283227_000011_000001_gen.wav', '8630_305212_000015_000004_gen.wav', '8747_293952_000064_000000_gen.wav', '8747_293952_000098_000004_gen.wav', '8770_295462_000021_000003_gen.wav', '8770_295465_000017_000003_gen.wav', '8770_295465_000022_000001_gen.wav', '8797_294123_000009_000002_gen.wav', '87_121553_000010_000000_gen.wav', '8838_298545_000069_000001_gen.wav', '887_123290_000019_000003_gen.wav', '887_123291_000012_000001_gen.wav', '887_123291_000014_000001_gen.wav', '8975_270782_000005_000005_gen.wav', '8975_270782_000016_000000_gen.wav', '8975_270782_000018_000002_gen.wav', '8975_270782_000019_000009_gen.wav', '89_218_000012_000006_gen.wav', '909_131041_000011_000000_gen.wav']\n",
            "\n",
            "\n",
            " Total files found: 3550 \n",
            " Updated class counts: {'diffwave': 475, 'gt': 700, 'melgan': 475, 'parallel_wave_gan': 475, 'wavegrad': 475, 'wavenet': 475, 'wavernn': 475} \n",
            " \n",
            "----------------------------- File Dictionary Setup Complete ------------------------------ \n",
            "\n",
            "\n",
            "=============================== Setting Up Data Loaders ===============================\n",
            "\n",
            "Total dataset size: 3550 samples\n",
            "Split ratios - Train: 0.7, Valid: 0.15, Test: 0.15\n",
            "\n",
            "Class 'diffwave' (index 0) has 475 samples.\n",
            "Class 'gt' (index 1) has 700 samples.\n",
            "Class 'melgan' (index 2) has 475 samples.\n",
            "Class 'parallel_wave_gan' (index 3) has 475 samples.\n",
            "Class 'wavegrad' (index 4) has 475 samples.\n",
            "Class 'wavenet' (index 5) has 475 samples.\n",
            "Class 'wavernn' (index 6) has 475 samples.\n",
            "\n",
            "Split sizes - Train: 2485, Valid: 532, Test: 533\n",
            "Training labels distribution: [333 490 333 332 332 332 333]\n",
            "Validation labels distribution: [ 71 105  71  71  72  71  71]\n",
            "Testing labels distribution: [ 71 105  71  72  71  72  71]\n",
            "\n",
            "Class weights for loss function: [0.866667, 1.3, 1.05, 1.05, 0.866667, 1.0, 0.866666]\n",
            "\n",
            "\n",
            "=============================== Fitting StandardScaler on Training Data ===============================\n",
            "\n",
            "Using 100 samples (out of 2485) for scaler fitting\n",
            "Fitting scaler on 9900 feature vectors (shape: (9900, 40))\n",
            "StandardScaler fitted on 100 training samples\n",
            "\n",
            "----------------------------- StandardScaler Fitting Complete ------------------------------\n",
            "\n",
            "DataLoaders created successfully!\n",
            "  Training batches: 156\n",
            "  Validation batches: 34\n",
            "  Testing batches: 34\n",
            "\n",
            "----------------------------- Data Loaders Setup Complete -----------------------------\n",
            "\n",
            "\n",
            "=============================== Plotting Training Curves ===============================\n",
            "\n",
            "No training metrics found. Please train the model first.\n",
            " \n",
            "=============================== Sample Count Diagramming =============================== \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgYNJREFUeJzs3Xd4FNXbxvF7U6kJPaEJKDX0IiEUQaqAAlIFVFS6IL0EpIuAKEUU6VWUXlR6kd57F5DeEkAggQAJSc77h2/2lyWgCWbZJHw/17UX7MyZ3WdydpO9d86csRhjjAAAAAAAQLxzcnQBAAAAAAAkVYRuAAAAAADshNANAAAAAICdELoBAAAAALATQjcAAAAAAHZC6AYAAAAAwE4I3QAAAAAA2AmhGwAAAAAAOyF0AwAAAABgJ4RuAIDDDBo0SBaLxXrLmTOno0tK9KL/PC0Wi2bOnOnokmJt06ZNMeq/cOGCTZuPPvrIZn2lSpUcUuvzypkzp039gwYNcnRJAAA7c3F0AQCAxO/UqVOaO3eutm3bptOnT+v27dsKCwuTp6en8uTJozJlyqhOnTqqWLGiLBaLo8tNMAYNGqTBgwfHWO7q6ip3d3d5enrK29tbefLkkZ+fn5o2baqMGTM6oNK/XbhwIUaI79Kli9KkSeOQehKCTZs2adOmTdb7adKkUZcuXRxWDwAg4SF0AwCeW0BAgD799FMtW7ZMxpgY62/duqVbt25p586dGjNmjBo0aKBFixY5oNLE5fHjx3r8+LHu37+vq1evav/+/Zo3b5569eqlFi1aaNSoUUqVKtULr+vChQsxviT46KOPXvrQHf1nkiNHDkI3AMAGoRsA8Fz27dun2rVr68aNG7He5tatW3asKOkLDQ3V5MmTtXnzZq1cuVKvvvpqjDbnz5+3uZ8hQ4YXVd5/VqZMmRj1Z8uWzUHV2Me2bdsUHh5uvf8yf2EBAC8LQjcAIM4uXrz41MCdJUsWderUSW+88YYyZMig4OBgHT16VCtXrtSyZcscU2wiM3fuXJUpU0YhISG6dOmS1q1bp2nTpik4ONja5tSpU6pdu7Z27dolT09Pm+0T83nxyZIlS9T1x0ZS+xIBAPDvmEgNABBnPXr0iBG433jjDZ04cUK9e/eWn5+f8uTJo5IlS+qjjz7SggULdPbsWb377rtxfq7du3dr2LBhatiwoYoWLaps2bIpefLkSpYsmby8vPTGG29owIABunTp0jMfIzw8XDNnztQ777yjHDlyKEWKFHJzc1PmzJlVpEgRNW3aVGPGjNGhQ4dibHvnzh0NGzZMb7zxhry8vOTu7q4UKVIoR44cKl26tNq0aaOpU6fqypUrcd63p/H29lbOnDlVsGBB1axZU6NHj9axY8dUqFAhm3Z//PGHhg4dGmP72EykdurUKXXp0kUlSpRQ2rRp5erqKk9PT+XOnVuVKlVSjx49tGDBAoWEhEiSZs6cKYvFojfffDPGY+XKlcvm+T766CPrumdNerZgwQJVqVJF6dOnt5lMLDYTqT3L77//rrfffluZMmVS8uTJVaBAAQ0YMMC6D0+KzYRm/zTRX9S+PTnc/uLFi//YB3GZSG3z5s1q2bKlChQoIE9PT7m5uSlTpkyqWLGihg4dqps3bz5z26fV8OjRI40cOVLFixdXqlSplDp1apUtW1Y//fTTMx8HABAPDAAAcXDmzBkjyeaWPn16c/PmzTg/1sCBA20eJ0eOHDHa1K1bN8bzPe2WMmVKM2/evBjbP3z40JQvXz5Wj1GjRg2bbU+dOmUyZ84cq22HDx/+n/dfktm4ceNT2549e9a4ubnZtE2ePLkJDg62affk482YMcNm/eLFi2M8zrNuO3fuNMYYM2PGjFi1l2RatGhhfa4WLVrYrKtYsaJp3bp1jG0GDhxojDFm48aNMdadP3/epv6nPeaQIUOMxWJ5aj358uUzV69ejfHzzJEjx1Nr+Kf+if76fLKOf7pF74PYPO/t27dNnTp1YvWanzVrVoztn/Y6GDx4sClQoMAzH+tpdQAA4gdHugEAcbJixYoYy1q3bu3wc4dDQkL04Ycf6uTJkzbLx48fr23btj3XY3bv3l3Xr1+Pj/L+s1dffVWNGze2Wfbw4UP9/vvvsX6MsLAwtW7dWmFhYfFdXqxs375dU6ZMidfH3Lt3rwYMGPDUifykv4/qN2rUSJGRkfH6vPYSGhqqd955R7/++uu/tg0JCVGLFi1idaR60KBBMd4b0X3xxRc6ffp0nGoFAMQOoRsAECcHDx6MsaxKlSp2e740adKoUaNGmjp1qtauXatDhw7p9OnT2rVrl0aPHm0zEVVYWJi+/fZbm+03b95sc79Zs2basWOHzpw5o8OHD2vZsmXq16+ffH195eTk9I/bDhs2TAcPHtSZM2e0d+9e/fTTT+rQoYNee+21+N3pZ3jaNamf1h/PcuzYMd2+fdt6P126dPrpp590/PhxnTp1Slu3btWkSZP0/vvvK126dNZ2DRs21Pnz5zV37twYj7l161adP3/eevvmm2+e+fxRE4h16tRJu3fv1vHjx7Vw4UKVLl061vvwpAcPHih16tSaOHGiDh8+rF9++UX58+e3abNjx454nzX/m2++0fnz59W5c2eb5VmzZrX5eZw/f14NGzaM9eN+99132r59u82yChUqaPXq1Tp8+LC+++47pUyZ0mZ9x44ddffu3X98XGOMSpYsqXXr1unQoUPq0KGDzfrIyEjNnz8/1nUCAGKPidQAAHHytPNI7Tk51NPOSY7i6+uryMhI9ejRw7rsyaAcfaZo6e/A5+vra71fpEgR1a1bV1988YXu3bv3zG09PDzUvXt3ubm5WZeVKlVKzZo1k6QY29pD1qxZYyz7p/N6n/Tkz6J06dLW+iUpb968Kl++vNq0aaPHjx8rIiJCkpQqVSqlSpXqqedXZ8uWLU6Tn/Xo0UNff/219b6Pj0+st32WWbNmWecLKFKkiF5//XXlypVLoaGh1jY//vhjjJEC/0WGDBmUIUOGGLOPu7i4/KfJ4CZMmGBzP1euXNqwYYNcXV0l/b1/GTJkUNOmTa1t7t69q7lz56p9+/bPfNxUqVJpzZo1Sp8+vSTp+++/16ZNm3T8+HFrmyNHjjx33QCAZ+NINwAgwdu6davat2+vkiVLKn369HJ3d7dOEBU9cEuKMaFZyZIlbe7Xrl1bH374oYYPH67Fixfrjz/+sA5NTp069TO3DQ4OVuHChfXpp59q7NixWrVqla5evWpd/+S29vC0IdQWiyXW2/v4+Ch58uTW+6tXr1aFChXUo0cP66XIgoKCJEmurq5KlizZfy86GldXV/n7+8frY6ZLl05169a1WZY5c2bVrFnTZtmuXbvi9Xnt4cqVKzp37pzNso8//tgauKM0btxYadOmtVm2ZcuWf3zs9957zxq4ozw5IuDOnTtxLRkAEAsc6QYAxEnGjBljLLty5UqMD/DxITIyUp988olmzZoV623u379vc79z586aO3euzp49K0n666+/9OOPP9q0SZ8+vZo0aaL+/fvL29vbunzEiBGqVq2aHj58KEk6ffp0jPNe8+TJo5YtW6pLly5yd3eP0/7FVfSQH+Vp/fEsqVKl0pdffqlu3bpZl23bts3mnHcnJyf5+vqqS5cu8XpkWJKyZ88eI/j9Vzly5IhxWoD09xHi6P766y9FRETI2dk5Xp8/Pl27di3GsqeduuDk5KQcOXLYhOSnbRvd096f0b+AkWKOhAAAxA+OdAMA4qR48eIxlm3YsMEuzzV16tQ4Be6nyZAhgw4cOKAvvvhCRYsWfeqR4b/++ks//PCDSpcubXNubLly5XTkyBF9+umnypEjx1Mf/8yZM/L391ejRo3+U52xsXHjxhjLntYf/6Rr167auHGjGjZsGONoqfT3Fx07d+5UkyZNNHr06Oeu9WmyZMkSr48XF8aYZ062Jsk6lD66W7du2bOkF+ppX3Yk5C8gACApIXQDAOKkdu3aMZZNnTpVf/31V7w/15MTd6VNm1YTJ07UoUOHrJNUPe1a1U/y8PBQv379dOjQIYWEhOjw4cNavHix+vbtKw8PD2u7y5cvxwj5uXPn1vjx43XhwgX99ddf2rVrl3788Ue1bNnSJsD/9ttvOnz48H/c42c7e/ZsjMnAkidP/tRrZ/+bSpUqaeHChbp9+7YuX76sTZs2aeLEiapcubJNuy+//DJeZ/22R8i7ePHiU2s8f/68zf0MGTLIxeV/A/yi/1/6e0K2J73o2byf9qVE1AiN6CIjI3Xx4kWbZZkzZ7ZbXQCA/4bQDQCIk9y5c8eYjfnWrVtq1KjRP04mdvny5Rgzi/+bJ4dTf/DBB2rbtq2KFi2qnDlzKmfOnP96rm5AQIDNEc7kyZOrSJEiql+/vr788kt9/PHHNu2jX1bpySG76dKlk6+vr95//31NnTpVRYoUeea28eny5cuqV69ejEt9dejQIU7nkkdERCgwMNBmWbZs2VSxYkW1bdtWixcvtll3+/Zt3bhxw3o/+iRyUaKG3jvK7du3tWzZMptl169f16pVq2yWRZ88T1KMCdCe7LtTp07FagTHkz+T//LzyJYtm1599VWbZTNmzNDjx49tli1YsCDG+ddvvPHGcz8vAMC+OKcbABBn33zzjbZs2WITyDZu3CgfHx916tRJb7zxhtKnT6+goCAdO3ZMK1as0LJly1S2bNkYl1j6JxkzZtSZM2es9xcuXKiKFSuqYMGCunbtmsaPH6/ly5f/a62LFi3SO++8Iz8/P+XJk0dp0qRRWFiYDhw4EONoeqpUqaz/j5qgq2bNmipZsqRy5sypVKlSKTg4WCtXrtSxY8eeue3zCggI0IULF/TgwQNdunRJa9as0bRp02J8oZE/f37169cvTo/98OFDZcuWTVWrVlXVqlVVpEgRZcmSRe7u7goMDNTEiRNjbBP98lRPO3987Nix6tSpk7Wdt7d3vE/A9m8++ugj3bx5U2XLltWFCxfUq1cvm5nLpb+/sImuSJEi2r9/v/X+6tWrNXjwYDVo0EDnz59Xt27dYnWU/8mfyY0bNzRp0iS9+eab1kAel9nM27dvr549e1rvnz9/XlWqVNHnn3+uzJkza+vWrerdu7fNNmnSpLGZhR4AkLAQugEAcZYjRw6tWLFCtWrVsrlk1ZUrV9SrV694e5769etrx44d1vvXr19XgwYNbNpkzpxZ169f/8fHuXjxor7//nt9//33//qc0YfPG2O0f/9+7du371+3S506dbwcbYx+KahnyZ8/v1asWCFPT884P354eLhWr16t1atX/2vbihUr2hxJf+2115QxY0abPp88ebImT55svb9x48anXk/cXlxcXHTv3j21a9fumW3KlCkTY3RGs2bNNGPGDOt9Y4wGDRqkQYMGWZdZLJZ/PA9ckvz8/GIse7KWf3uM6D777DMtXbrU5nW/detWvfXWW8/c5vvvv49x5B4AkHAwvBwA8FxKlSqlw4cPq169erG+bFWGDBni9BwdO3ZUxYoVn7m+atWqGjhwYJwe85/06dPnuc6RTp48uX788Ueb88PtIVmyZGrfvr327dsXYxhyfMuRI4emTJlis8zJyUl9+vSx6/PGVbly5dSpU6dnrs+TJ48WLlwY43zyqlWr6sMPP3zmdmXKlFHHjh3/9fkLFSqkOnXqxL7gf+Hu7q7ly5frnXfe+de2KVKk0KxZs9S8efN4e34AQPzjSDcA4LllzpxZS5cu1R9//KG5c+dq27ZtOnXqlO7cuaOwsDClSZNGuXPnVpkyZVSnTp04HwF1d3fX2rVrNXbsWM2ZM0enT5+Wm5ub8uXLpw8//FCffvppjMt/PalPnz4qW7astm/frr179+r69eu6ceOGQkJClDJlSuXMmVN+fn76+OOPY5z3O3/+fG3ZskXbt2/XkSNHFBgYqJs3byo8PFyenp7KkyePKleurLZt2yp79uxx/fE9k4uLi9zd3ZUmTRp5e3srT548Klu2rJo1a/afLrmVMmVK7dmzR9u3b9f27dt1+vRp3bx5U7du3ZKTk5MyZMigggULqnbt2mrZsqXN0PIoXbt2VaZMmTRp0iQdOXJEwcHBcTqSaw/ffvutqlWrpu+//1779u3T/fv3lSNHDjVu3Fi9e/d+5rD/GTNm6PXXX9e0adN06tQpOTs7y8fHRx9++KHatm0bq0n6pL/Psf7qq6+0aNEinT179qmTssVF2rRp9euvv2rjxo368ccftWPHDl27dk0PHz5UmjRpVKBAAVWrVk1t27ZVpkyZ/tNzAQDsz2Ic/ZcSAAAAAIAkiuHlAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBOu0y0pMjJS165dU+rUqWWxWBxdDgAAAAAggTPG6N69e8qSJYucnJ59PJvQLenatWvKnj27o8sAAAAAACQyly9fVrZs2Z65ntAtKXXq1JL+/mF5eHg4uBoAAAAAQEIXHBys7NmzW/PksxC6JeuQcg8PD0I3AAAAACDW/u0UZSZSAwAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnDg3dOXPmlMViiXHr0KGDJOnRo0fq0KGD0qdPr1SpUqlBgwYKDAy0eYxLly6pdu3aSpEihTJlyqSePXsqPDzcEbsDAAAAAIANh4buvXv36vr169bbunXrJEmNGjWSJHXt2lW//fabFi5cqM2bN+vatWuqX7++dfuIiAjVrl1bYWFh2rFjh2bNmqWZM2dqwIABDtkfAAAAAACisxhjjKOLiNKlSxctX75cZ86cUXBwsDJmzKiff/5ZDRs2lCT98ccfKlCggHbu3KkyZcpo1apVevvtt3Xt2jV5eXlJkiZOnKjevXvr5s2bcnNzi9XzBgcHy9PTU0FBQfLw8LDb/gEAAAAAkobY5sgEc053WFiY5syZo08++UQWi0X79+/X48ePVbVqVWub/Pnz65VXXtHOnTslSTt37lThwoWtgVuSatSooeDgYB0/fvyF7wMAAAAAANG5OLqAKMuWLdPdu3f10UcfSZICAgLk5uamNGnS2LTz8vJSQECAtU30wB21Pmrds4SGhio0NNR6Pzg4OB72AAAAAAAAWwkmdE+bNk01a9ZUlixZ7P5cw4cP1+DBg+3+PMDzyOm/wtElQNKFEbUdXQIAAACSgAQxvPzixYtav369WrVqZV3m7e2tsLAw3b1716ZtYGCgvL29rW2enM086n5Um6fp06ePgoKCrLfLly/H054AAAAAAPA/CSJ0z5gxQ5kyZVLt2v87slSyZEm5urpqw4YN1mWnTp3SpUuX5OfnJ0ny8/PT0aNHdePGDWubdevWycPDQz4+Ps98Pnd3d3l4eNjcAAAAAACIbw4fXh4ZGakZM2aoRYsWcnH5Xzmenp5q2bKlunXrpnTp0snDw0OfffaZ/Pz8VKZMGUlS9erV5ePjow8++EAjR45UQECA+vXrpw4dOsjd3d1RuwQAAAAAgKQEELrXr1+vS5cu6ZNPPomxbsyYMXJyclKDBg0UGhqqGjVq6IcffrCud3Z21vLly9W+fXv5+fkpZcqUatGihYYMGfIidwEAAAAAgKdKUNfpdhSu042EhInUEgYmUgMAAMA/SXTX6QYAAAAAIKkhdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB24vDQffXqVb3//vtKnz69kidPrsKFC2vfvn3W9cYYDRgwQJkzZ1by5MlVtWpVnTlzxuYxbt++rebNm8vDw0Np0qRRy5Ytdf/+/Re9KwAAAAAA2HBo6L5z547KlSsnV1dXrVq1SidOnNCoUaOUNm1aa5uRI0dq3Lhxmjhxonbv3q2UKVOqRo0aevTokbVN8+bNdfz4ca1bt07Lly/Xli1b1KZNG0fsEgAAAAAAVhZjjHHUk/v7+2v79u3aunXrU9cbY5QlSxZ1795dPXr0kCQFBQXJy8tLM2fO1HvvvaeTJ0/Kx8dHe/fuValSpSRJq1evVq1atXTlyhVlyZLlX+sIDg6Wp6engoKC5OHhEX87CDyHnP4rHF0CJF0YUdvRJQAAACABi22OdOiR7l9//VWlSpVSo0aNlClTJhUvXlxTpkyxrj9//rwCAgJUtWpV6zJPT0/5+vpq586dkqSdO3cqTZo01sAtSVWrVpWTk5N279791OcNDQ1VcHCwzQ0AAAAAgPjm0NB97tw5TZgwQXny5NGaNWvUvn17derUSbNmzZIkBQQESJK8vLxstvPy8rKuCwgIUKZMmWzWu7i4KF26dNY2Txo+fLg8PT2tt+zZs8f3rgEAAAAA4NjQHRkZqRIlSmjYsGEqXry42rRpo9atW2vixIl2fd4+ffooKCjIert8+bJdnw8AAAAA8HJyaOjOnDmzfHx8bJYVKFBAly5dkiR5e3tLkgIDA23aBAYGWtd5e3vrxo0bNuvDw8N1+/Zta5snubu7y8PDw+YGAAAAAEB8c2joLleunE6dOmWz7PTp08qRI4ckKVeuXPL29taGDRus64ODg7V79275+flJkvz8/HT37l3t37/f2ub3339XZGSkfH19X8BeAAAAAADwdC6OfPKuXbuqbNmyGjZsmBo3bqw9e/Zo8uTJmjx5siTJYrGoS5cuGjp0qPLkyaNcuXKpf//+ypIli+rVqyfp7yPjb731lnVY+uPHj9WxY0e99957sZq5HAAAAAAAe3Fo6H799de1dOlS9enTR0OGDFGuXLk0duxYNW/e3NqmV69eCgkJUZs2bXT37l2VL19eq1evVrJkyaxtfvrpJ3Xs2FFVqlSRk5OTGjRooHHjxjlilwAAAAAAsHLodboTCq7TjYSE63QnDFynGwAAAP8kUVynGwAAAACApIzQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOHBq6Bw0aJIvFYnPLnz+/df2jR4/UoUMHpU+fXqlSpVKDBg0UGBho8xiXLl1S7dq1lSJFCmXKlEk9e/ZUeHj4i94VAAAAAABicHF0AQULFtT69eut911c/ldS165dtWLFCi1cuFCenp7q2LGj6tevr+3bt0uSIiIiVLt2bXl7e2vHjh26fv26PvzwQ7m6umrYsGEvfF8AAAAAAIjO4aHbxcVF3t7eMZYHBQVp2rRp+vnnn1W5cmVJ0owZM1SgQAHt2rVLZcqU0dq1a3XixAmtX79eXl5eKlasmL744gv17t1bgwYNkpub24veHQAAAAAArBx+TveZM2eUJUsWvfrqq2revLkuXbokSdq/f78eP36sqlWrWtvmz59fr7zyinbu3ClJ2rlzpwoXLiwvLy9rmxo1aig4OFjHjx9/5nOGhoYqODjY5gYAAAAAQHxzaOj29fXVzJkztXr1ak2YMEHnz59XhQoVdO/ePQUEBMjNzU1p0qSx2cbLy0sBAQGSpICAAJvAHbU+at2zDB8+XJ6entZb9uzZ43fHAAAAAACQg4eX16xZ0/r/IkWKyNfXVzly5NCCBQuUPHlyuz1vnz591K1bN+v94OBggjcAAAAAIN45fHh5dGnSpFHevHn1559/ytvbW2FhYbp7965Nm8DAQOs54N7e3jFmM4+6/7TzxKO4u7vLw8PD5gYAAAAAQHxLUKH7/v37Onv2rDJnzqySJUvK1dVVGzZssK4/deqULl26JD8/P0mSn5+fjh49qhs3bljbrFu3Th4eHvLx8Xnh9QMAAAAAEJ1Dh5f36NFD77zzjnLkyKFr165p4MCBcnZ2VtOmTeXp6amWLVuqW7duSpcunTw8PPTZZ5/Jz89PZcqUkSRVr15dPj4++uCDDzRy5EgFBASoX79+6tChg9zd3R25awAAAAAAODZ0X7lyRU2bNtVff/2ljBkzqnz58tq1a5cyZswoSRozZoycnJzUoEEDhYaGqkaNGvrhhx+s2zs7O2v58uVq3769/Pz8lDJlSrVo0UJDhgxx1C4BAAAAAGBlMcYYRxfhaMHBwfL09FRQUBDnd8PhcvqvcHQJkHRhRG1HlwAAAIAELLY5Ms7ndF++fFlXrlyx3t+zZ4+6dOmiyZMnP1+lAAAAAAAkUXEO3c2aNdPGjRsl/X0t7GrVqmnPnj36/PPPGdYNAAAAAEA0cQ7dx44dU+nSpSVJCxYsUKFChbRjxw799NNPmjlzZnzXBwAAAABAohXn0P348WPrzODr169XnTp1JEn58+fX9evX47c6AAAAAAASsTiH7oIFC2rixInaunWr1q1bp7feekuSdO3aNaVPnz7eCwQAAAAAILGKc+j+6quvNGnSJFWqVElNmzZV0aJFJUm//vqrddg5AAAAAAB4jut0V6pUSbdu3VJwcLDSpk1rXd6mTRulSJEiXosDAAAAACAxi3PoliRjjPbv36+zZ8+qWbNmSp06tdzc3Ajddsb1mxMGrt+M+MJ72vFexPuZfk4Y7N3X9HPCQD+/HPjd/XJISp+54xy6L168qLfeekuXLl1SaGioqlWrptSpU+urr75SaGioJk6caI86AQAAAABIdOJ8Tnfnzp1VqlQp3blzR8mTJ7cuf/fdd7Vhw4Z4LQ4AAAAAgMQszke6t27dqh07dsjNzc1mec6cOXX16tV4KwwAAAAAgMQuzke6IyMjFREREWP5lStXlDp16ngpCgAAAACApCDOobt69eoaO3as9b7FYtH9+/c1cOBA1apVKz5rAwAAAAAgUYvz8PJRo0apRo0a8vHx0aNHj9SsWTOdOXNGGTJk0Ny5c+1RIwAAAAAAiVKcQ3e2bNl0+PBhzZs3T0eOHNH9+/fVsmVLNW/e3GZiNQAAAAAAXnbPdZ1uFxcXvf/++/FdCwAAAAAASUqsQvevv/4a6wesU6fOcxcDAAAAAEBSEqvQXa9evVg9mMVieerM5gAAAAAAvIxiFbojIyPtXQcAAAAAAElOnC8ZBgAAAAAAYue5QveGDRv09ttv67XXXtNrr72mt99+W+vXr4/v2gAAAAAASNTiHLp/+OEHvfXWW0qdOrU6d+6szp07y8PDQ7Vq1dL48ePtUSMAAAAAAIlSnC8ZNmzYMI0ZM0YdO3a0LuvUqZPKlSunYcOGqUOHDvFaIAAAAAAAiVWcj3TfvXtXb731Vozl1atXV1BQULwUBQAAAABAUhDn0F2nTh0tXbo0xvJffvlFb7/9drwUBQAAAABAUhDn4eU+Pj768ssvtWnTJvn5+UmSdu3ape3bt6t79+4aN26ctW2nTp3ir1IAAAAAABKZOIfuadOmKW3atDpx4oROnDhhXZ4mTRpNmzbNet9isRC6AQAAAAAvtTiH7vPnz9ujDgAAAAAAkpznuk43AAAAAAD4d3E+0m2M0aJFi7Rx40bduHFDkZGRNuuXLFkSb8UBAAAAAJCYxTl0d+nSRZMmTdKbb74pLy8vWSwWe9QFAAAAAECiF+fQ/eOPP2rJkiWqVauWPeoBAAAAACDJiPM53Z6ennr11VftUQsAAAAAAElKnEP3oEGDNHjwYD18+NAe9QAAAAAAkGTEeXh548aNNXfuXGXKlEk5c+aUq6urzfoDBw7EW3EAAAAAACRmcQ7dLVq00P79+/X+++8zkRoAAAAAAP8gzqF7xYoVWrNmjcqXL2+PegAAAAAASDLifE539uzZ5eHhYY9aAAAAAABIUuIcukeNGqVevXrpwoULdigHAAAAAICkI87Dy99//309ePBAr732mlKkSBFjIrXbt2/HW3EAAAAAACRmcQ7dY8eOtUMZAAAAAAAkPc81ezkAAAAAAPh3cQ7d0T169EhhYWE2y5hkDQAAAACAv8V5IrWQkBB17NhRmTJlUsqUKZU2bVqbGwAAAAAA+FucQ3evXr30+++/a8KECXJ3d9fUqVM1ePBgZcmSRbNnz7ZHjQAAAAAAJEpxDt2//fabfvjhBzVo0EAuLi6qUKGC+vXrp2HDhumnn3567kJGjBghi8WiLl26WJc9evRIHTp0UPr06ZUqVSo1aNBAgYGBNttdunRJtWvXVooUKZQpUyb17NlT4eHhz10HAAAAAADxJc6h+/bt23r11Vcl/X3+dtQlwsqXL68tW7Y8VxF79+7VpEmTVKRIEZvlXbt21W+//aaFCxdq8+bNunbtmurXr29dHxERodq1ayssLEw7duzQrFmzNHPmTA0YMOC56gAAAAAAID7FOXS/+uqrOn/+vCQpf/78WrBggaS/j4CnSZMmzgXcv39fzZs315QpU2zOCQ8KCtK0adM0evRoVa5cWSVLltSMGTO0Y8cO7dq1S5K0du1anThxQnPmzFGxYsVUs2ZNffHFFxo/fnyMCd4AAAAAAHjR4hy6P/74Yx0+fFiS5O/vr/HjxytZsmTq2rWrevbsGecCOnTooNq1a6tq1ao2y/fv36/Hjx/bLM+fP79eeeUV7dy5U5K0c+dOFS5cWF5eXtY2NWrUUHBwsI4fP/7M5wwNDVVwcLDNDQAAAACA+BbnS4Z17drV+v+qVavq5MmTOnDggHLnzh1jePi/mTdvng4cOKC9e/fGWBcQECA3N7cYR8+9vLwUEBBgbRM9cEetj1r3LMOHD9fgwYPjVCsAAAAAAHH1n67TLUk5c+ZUzpw547zd5cuX1blzZ61bt07JkiX7r2XESZ8+fdStWzfr/eDgYGXPnv2F1gAAAAAASPpiPbx8586dWr58uc2y2bNnK1euXMqUKZPatGmj0NDQWD/x/v37dePGDZUoUUIuLi5ycXHR5s2bNW7cOLm4uMjLy0thYWG6e/euzXaBgYHy9vaWJHl7e8eYzTzqflSbp3F3d5eHh4fNDQAAAACA+Bbr0D1kyBCb86SPHj2qli1bqmrVqvL399dvv/2m4cOHx/qJq1SpoqNHj+rQoUPWW6lSpdS8eXPr/11dXbVhwwbrNqdOndKlS5fk5+cnSfLz89PRo0d148YNa5t169bJw8NDPj4+sa4FAAAAAAB7iPXw8kOHDumLL76w3p83b558fX01ZcoUSVL27Nk1cOBADRo0KFaPlzp1ahUqVMhmWcqUKZU+fXrr8pYtW6pbt25Kly6dPDw89Nlnn8nPz09lypSRJFWvXl0+Pj764IMPNHLkSAUEBKhfv37q0KGD3N3dY7trAAAAAADYRaxD9507d2wmLdu8ebNq1qxpvf/666/r8uXL8VrcmDFj5OTkpAYNGig0NFQ1atTQDz/8YF3v7Oys5cuXq3379vLz81PKlCnVokULDRkyJF7rAAAAAADgecQ6dHt5een8+fPKnj27wsLCdODAAZsZwO/duydXV9f/VMymTZts7idLlkzjx4/X+PHjn7lNjhw5tHLlyv/0vAAAAAAA2EOsz+muVauW/P39tXXrVvXp00cpUqRQhQoVrOuPHDmi1157zS5FAgAAAACQGMX6SPcXX3yh+vXrq2LFikqVKpVmzZolNzc36/rp06erevXqdikSAAAAAIDEKNahO0OGDNqyZYuCgoKUKlUqOTs726xfuHChUqVKFe8FAgAAAACQWMU6dEfx9PR86vJ06dL952IAAAAAAEhKYn1ONwAAAAAAiBtCNwAAAAAAdkLoBgAAAADATmIVukuUKKE7d+5IkoYMGaIHDx7YtSgAAAAAAJKCWIXukydPKiQkRJI0ePBg3b9/365FAQAAAACQFMRq9vJixYrp448/Vvny5WWM0TfffPPMy4MNGDAgXgsEAAAAACCxilXonjlzpgYOHKjly5fLYrFo1apVcnGJuanFYiF0AwAAAADw/2IVuvPly6d58+ZJkpycnLRhwwZlypTJroUBAAAAAJDYxSp0RxcZGWmPOgAAAAAASHLiHLol6ezZsxo7dqxOnjwpSfLx8VHnzp312muvxWtxAAAAAAAkZnG+TveaNWvk4+OjPXv2qEiRIipSpIh2796tggULat26dfaoEQAAAACARCnOR7r9/f3VtWtXjRgxIsby3r17q1q1avFWHAAAAAAAiVmcj3SfPHlSLVu2jLH8k08+0YkTJ+KlKAAAAAAAkoI4h+6MGTPq0KFDMZYfOnSIGc0BAAAAAIgmzsPLW7durTZt2ujcuXMqW7asJGn79u366quv1K1bt3gvEAAAAACAxCrOobt///5KnTq1Ro0apT59+kiSsmTJokGDBqlTp07xXiAAAAAAAIlVnEO3xWJR165d1bVrV927d0+SlDp16ngvDAAAAACAxO65rtMdhbANAAAAAMCzxXkiNQAAAAAAEDuEbgAAAAAA7ITQDQAAAACAncQpdD9+/FhVqlTRmTNn7FUPAAAAAABJRpxCt6urq44cOWKvWgAAAAAASFLiPLz8/fff17Rp0+xRCwAAAAAASUqcLxkWHh6u6dOna/369SpZsqRSpkxps3706NHxVhwAAAAAAIlZnEP3sWPHVKJECUnS6dOnbdZZLJb4qQoAAAAAgCQgzqF748aN9qgDAAAAAIAk57kvGfbnn39qzZo1evjwoSTJGBNvRQEAAAAAkBTEOXT/9ddfqlKlivLmzatatWrp+vXrkqSWLVuqe/fu8V4gAAAAAACJVZxDd9euXeXq6qpLly4pRYoU1uVNmjTR6tWr47U4AAAAAAASszif07127VqtWbNG2bJls1meJ08eXbx4Md4KAwAAAAAgsYvzke6QkBCbI9xRbt++LXd393gpCgAAAACApCDOobtChQqaPXu29b7FYlFkZKRGjhypN998M16LAwAAAAAgMYvz8PKRI0eqSpUq2rdvn8LCwtSrVy8dP35ct2/f1vbt2+1RIwAAAAAAiVKcj3QXKlRIp0+fVvny5VW3bl2FhISofv36OnjwoF577TV71AgAAAAAQKIU5yPdkuTp6anPP/88vmsBAAAAACBJea7QfefOHU2bNk0nT56UJPn4+Ojjjz9WunTp4rU4AAAAAAASszgPL9+yZYty5sypcePG6c6dO7pz547GjRunXLlyacuWLfaoEQAAAACARCnOR7o7dOigJk2aaMKECXJ2dpYkRURE6NNPP1WHDh109OjReC8SAAAAAIDEKM5Huv/88091797dGrglydnZWd26ddOff/4Zr8UBAAAAAJCYxTl0lyhRwnoud3QnT55U0aJF46UoAAAAAACSgliF7iNHjlhvnTp1UufOnfXNN99o27Zt2rZtm7755ht17dpVXbt2jdOTT5gwQUWKFJGHh4c8PDzk5+enVatWWdc/evRIHTp0UPr06ZUqVSo1aNBAgYGBNo9x6dIl1a5dWylSpFCmTJnUs2dPhYeHx6kOAAAAAADsIVbndBcrVkwWi0XGGOuyXr16xWjXrFkzNWnSJNZPni1bNo0YMUJ58uSRMUazZs1S3bp1dfDgQRUsWFBdu3bVihUrtHDhQnl6eqpjx46qX7++tm/fLunvc8lr164tb29v7dixQ9evX9eHH34oV1dXDRs2LNZ1AAAAAABgD7EK3efPn7fLk7/zzjs297/88ktNmDBBu3btUrZs2TRt2jT9/PPPqly5siRpxowZKlCggHbt2qUyZcpo7dq1OnHihNavXy8vLy8VK1ZMX3zxhXr37q1BgwbJzc3NLnUDAAAAABAbsQrdOXLksHcdioiI0MKFCxUSEiI/Pz/t379fjx8/VtWqVa1t8ufPr1deeUU7d+5UmTJltHPnThUuXFheXl7WNjVq1FD79u11/PhxFS9e/KnPFRoaqtDQUOv94OBg++0YAAAAAOClFedLhknStWvXtG3bNt24cUORkZE26zp16hSnxzp69Kj8/Pz06NEjpUqVSkuXLpWPj48OHTokNzc3pUmTxqa9l5eXAgICJEkBAQE2gTtqfdS6Zxk+fLgGDx4cpzoBAAAAAIirOIfumTNnqm3btnJzc1P69OllsVis6ywWS5xDd758+XTo0CEFBQVp0aJFatGihTZv3hzXsuKkT58+6tatm/V+cHCwsmfPbtfnBAAAAAC8fOIcuvv3768BAwaoT58+cnKK8xXHYnBzc1Pu3LklSSVLltTevXv17bffqkmTJgoLC9Pdu3dtjnYHBgbK29tbkuTt7a09e/bYPF7U7OZRbZ7G3d1d7u7u/7l2AAAAAAD+SZxT84MHD/Tee+/FS+B+msjISIWGhqpkyZJydXXVhg0brOtOnTqlS5cuyc/PT5Lk5+eno0eP6saNG9Y269atk4eHh3x8fOxSHwAAAAAAsRXnI90tW7bUwoUL5e/v/5+fvE+fPqpZs6ZeeeUV3bt3Tz///LM2bdqkNWvWyNPTUy1btlS3bt2ULl06eXh46LPPPpOfn5/KlCkjSapevbp8fHz0wQcfaOTIkQoICFC/fv3UoUMHjmQDAAAAABwuzqF7+PDhevvtt7V69WoVLlxYrq6uNutHjx4d68e6ceOGPvzwQ12/fl2enp4qUqSI1qxZo2rVqkmSxowZIycnJzVo0EChoaGqUaOGfvjhB+v2zs7OWr58udq3by8/Pz+lTJlSLVq00JAhQ+K6WwAAAAAAxLvnCt1r1qxRvnz5JCnGRGpxMW3atH9cnyxZMo0fP17jx49/ZpscOXJo5cqVcXpeAAAAAABehDiH7lGjRmn69On66KOP7FAOAAAAAABJR5xnQ3N3d1e5cuXsUQsAAAAAAElKnEN3586d9d1339mjFgAAAAAAkpQ4Dy/fs2ePfv/9dy1fvlwFCxaMMZHakiVL4q04AAAAAAASsziH7jRp0qh+/fr2qAUAAAAAgCQlzqF7xowZ9qgDAAAAAIAkJ87ndAMAAAAAgNiJ85HuXLly/eP1uM+dO/efCgIAAAAAIKmIc+ju0qWLzf3Hjx/r4MGDWr16tXr27BlfdQEAAAAAkOjFOXR37tz5qcvHjx+vffv2/eeCAAAAAABIKuLtnO6aNWtq8eLF8fVwAAAAAAAkevEWuhctWqR06dLF18MBAAAAAJDoxXl4efHixW0mUjPGKCAgQDdv3tQPP/wQr8UBAAAAAJCYxTl016tXz+a+k5OTMmbMqEqVKil//vzxVRcAAAAAAIlenEP3wIED7VEHAAAAAABJTryd0w0AAAAAAGzF+ki3k5OTzbncT2OxWBQeHv6fiwIAAAAAICmIdeheunTpM9ft3LlT48aNU2RkZLwUBQAAAABAUhDr0F23bt0Yy06dOiV/f3/99ttvat68uYYMGRKvxQEAAAAAkJg91znd165dU+vWrVW4cGGFh4fr0KFDmjVrlnLkyBHf9QEAAAAAkGjFKXQHBQWpd+/eyp07t44fP64NGzbot99+U6FChexVHwAAAAAAiVash5ePHDlSX331lby9vTV37tynDjcHAAAAAAD/E+vQ7e/vr+TJkyt37tyaNWuWZs2a9dR2S5YsibfiAAAAAABIzGIduj/88MN/vWQYAAAAAAD4n1iH7pkzZ9qxDAAAAAAAkp7nmr0cAAAAAAD8O0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANgJoRsAAAAAADshdAMAAAAAYCeEbgAAAAAA7ITQDQAAAACAnRC6AQAAAACwE0I3AAAAAAB2QugGAAAAAMBOCN0AAAAAANiJQ0P38OHD9frrryt16tTKlCmT6tWrp1OnTtm0efTokTp06KD06dMrVapUatCggQIDA23aXLp0SbVr11aKFCmUKVMm9ezZU+Hh4S9yVwAAAAAAiMGhoXvz5s3q0KGDdu3apXXr1unx48eqXr26QkJCrG26du2q3377TQsXLtTmzZt17do11a9f37o+IiJCtWvXVlhYmHbs2KFZs2Zp5syZGjBggCN2CQAAAAAAKxdHPvnq1att7s+cOVOZMmXS/v379cYbbygoKEjTpk3Tzz//rMqVK0uSZsyYoQIFCmjXrl0qU6aM1q5dqxMnTmj9+vXy8vJSsWLF9MUXX6h3794aNGiQ3NzcHLFrAAAAAAAkrHO6g4KCJEnp0qWTJO3fv1+PHz9W1apVrW3y58+vV155RTt37pQk7dy5U4ULF5aXl5e1TY0aNRQcHKzjx48/9XlCQ0MVHBxscwMAAAAAIL4lmNAdGRmpLl26qFy5cipUqJAkKSAgQG5ubkqTJo1NWy8vLwUEBFjbRA/cUeuj1j3N8OHD5enpab1lz549nvcGAAAAAIAEFLo7dOigY8eOad68eXZ/rj59+igoKMh6u3z5st2fEwAAAADw8nHoOd1ROnbsqOXLl2vLli3Kli2bdbm3t7fCwsJ09+5dm6PdgYGB8vb2trbZs2ePzeNFzW4e1eZJ7u7ucnd3j+e9AAAAAADAlkOPdBtj1LFjRy1dulS///67cuXKZbO+ZMmScnV11YYNG6zLTp06pUuXLsnPz0+S5Ofnp6NHj+rGjRvWNuvWrZOHh4d8fHxezI4AAAAAAPAUDj3S3aFDB/3888/65ZdflDp1aus52J6enkqePLk8PT3VsmVLdevWTenSpZOHh4c+++wz+fn5qUyZMpKk6tWry8fHRx988IFGjhypgIAA9evXTx06dOBoNgAAAADAoRwauidMmCBJqlSpks3yGTNm6KOPPpIkjRkzRk5OTmrQoIFCQ0NVo0YN/fDDD9a2zs7OWr58udq3by8/Pz+lTJlSLVq00JAhQ17UbgAAAAAA8FQODd3GmH9tkyxZMo0fP17jx49/ZpscOXJo5cqV8VkaAAAAAAD/WYKZvRwAAAAAgKSG0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADAThwaurds2aJ33nlHWbJkkcVi0bJly2zWG2M0YMAAZc6cWcmTJ1fVqlV15swZmza3b99W8+bN5eHhoTRp0qhly5a6f//+C9wLAAAAAACezqGhOyQkREWLFtX48eOfun7kyJEaN26cJk6cqN27dytlypSqUaOGHj16ZG3TvHlzHT9+XOvWrdPy5cu1ZcsWtWnT5kXtAgAAAAAAz+TiyCevWbOmatas+dR1xhiNHTtW/fr1U926dSVJs2fPlpeXl5YtW6b33ntPJ0+e1OrVq7V3716VKlVKkvTdd9+pVq1a+uabb5QlS5YXti8AAAAAADwpwZ7Tff78eQUEBKhq1arWZZ6envL19dXOnTslSTt37lSaNGmsgVuSqlatKicnJ+3evfuZjx0aGqrg4GCbGwAAAAAA8S3Bhu6AgABJkpeXl81yLy8v67qAgABlypTJZr2Li4vSpUtnbfM0w4cPl6enp/WWPXv2eK4eAAAAAIAEHLrtqU+fPgoKCrLeLl++7OiSAAAAAABJUIIN3d7e3pKkwMBAm+WBgYHWdd7e3rpx44bN+vDwcN2+fdva5mnc3d3l4eFhcwMAAAAAIL4l2NCdK1cueXt7a8OGDdZlwcHB2r17t/z8/CRJfn5+unv3rvbv329t8/vvvysyMlK+vr4vvGYAAAAAAKJz6Ozl9+/f159//mm9f/78eR06dEjp0qXTK6+8oi5dumjo0KHKkyePcuXKpf79+ytLliyqV6+eJKlAgQJ666231Lp1a02cOFGPHz9Wx44d9d577zFzOQAAAADA4Rwauvft26c333zTer9bt26SpBYtWmjmzJnq1auXQkJC1KZNG929e1fly5fX6tWrlSxZMus2P/30kzp27KgqVarIyclJDRo00Lhx4174vgAAAAAA8CSHhu5KlSrJGPPM9RaLRUOGDNGQIUOe2SZdunT6+eef7VEeAAAAAAD/SYI9pxsAAAAAgMSO0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATgjdAAAAAADYCaEbAAAAAAA7IXQDAAAAAGAnhG4AAAAAAOyE0A0AAAAAgJ0QugEAAAAAsBNCNwAAAAAAdkLoBgAAAADATpJM6B4/frxy5sypZMmSydfXV3v27HF0SQAAAACAl1ySCN3z589Xt27dNHDgQB04cEBFixZVjRo1dOPGDUeXBgAAAAB4iSWJ0D169Gi1bt1aH3/8sXx8fDRx4kSlSJFC06dPd3RpAAAAAICXWKIP3WFhYdq/f7+qVq1qXebk5KSqVatq586dDqwMAAAAAPCyc3F0Af/VrVu3FBERIS8vL5vlXl5e+uOPP566TWhoqEJDQ633g4KCJEnBwcH2KzQeRIY+cHQJkP1fJ/RzwvAifh/Q145HP788+N39cqCfXw787n45JPRsJv2vRmPMP7ZL9KH7eQwfPlyDBw+OsTx79uwOqAaJjedYR1eAF4F+fjnQzy8P+vrlQD+/HOjnl0Ni6ud79+7J09PzmesTfejOkCGDnJ2dFRgYaLM8MDBQ3t7eT92mT58+6tatm/V+ZGSkbt++rfTp08tisdi13pdZcHCwsmfPrsuXL8vDw8PR5cBO6OeXB339cqCfXw7088uBfn550NcvhjFG9+7dU5YsWf6xXaIP3W5ubipZsqQ2bNigevXqSfo7RG/YsEEdO3Z86jbu7u5yd3e3WZYmTRo7V4ooHh4evPlfAvTzy4O+fjnQzy8H+vnlQD+/POhr+/unI9xREn3olqRu3bqpRYsWKlWqlEqXLq2xY8cqJCREH3/8saNLAwAAAAC8xJJE6G7SpIlu3rypAQMGKCAgQMWKFdPq1atjTK4GAAAAAMCLlCRCtyR17NjxmcPJkTC4u7tr4MCBMYb2I2mhn18e9PXLgX5+OdDPLwf6+eVBXycsFvNv85sDAAAAAIDn4uToAgAAAAAASKoI3QAAAAAA2AmhGwAAAAAAOyF0AwAAAABgJ4RuAHYVERHh6BIAAC/I1KlTdfr0aUeXATvi7zoQd4RuAPHm/PnzCgsLkyR98803evjwoZydnR1cFQDgRVi5cqUGDRqk77//XufOnXN0OYhn9+7dkyQ5Oztr3759Cg0NdXBFeBG40FX8IHQjUYj+ho+MjHRgJXiWHTt2qFq1alq5cqU6d+6sXr166fLly44uCwnE0963/CHHf/GsvwW8rhynVq1a6t27t7Zt26axY8fqzz//dHRJiCdXrlzRRx99pLVr12rx4sUqXbq0Dhw44OiyYEc3btzQX3/9xe/UeMJ1upHgGWNksVi0fv16rVq1SseOHdN7772n0qVLq2DBgo4uD9E0atRImzdv1sOHD7VhwwaVLl1akZGRcnLi+72XWfTXwNWrV5UiRQqlTZs2xjogtqK/blasWKGwsDClS5dOFStWjLEeL0ZYWJjc3NwkSV999ZWWLl2q119/XT169FCOHDkcXB3+q9OnT6tt27a6e/euTp48qSlTpuiDDz7gvZZELV26VF9++aUCAgJUv359NWzYUG+88Yajy0rUeJcgwbNYLFq6dKnq16+vkJAQlSpVSv3795e/v78uXLjg6PJeesYY67egb775powxSp8+vS5fvqyQkBA5OTnxLelLLuoD2cCBA/Xmm2+qSpUqatGihXUdo1cQF8YY62uqe/fu+uSTT/Tpp5+qY8eO6tq1qyReVy+aMcYauMeOHauAgABdvHhRkydP1tdff63z5887uEL8F8YY5c2bV61atdLRo0f16quvKn369JJ4ryVFR44cUbt27dS4cWN17NhRe/bs0YgRI7R8+XJHl5aoEbqR4F26dEkDBw7U119/rYkTJ2ro0KEKCgpSwYIFlTNnTkeX91KLGoVgsVj0yy+/6Pjx49qzZ48qV66szz//XEuWLNGDBw9ksVhstuMP9Mshej/PmzdPEyZMUL9+/VS3bl3t379fpUuXlsSHNsRN1O+TP//8U3v27NH69eu1adMmtWrVSitWrFDr1q0l8bp6kaL6ZMSIERo4cKCqVKmihQsXqmvXrlqzZo1Gjx7Nl+SJWNQX556enpowYYJy5cql0aNHa+HChZJ4ryUlp0+f1i+//KJ27dqpV69e8vf315gxYyRJ33//PcH7vzBAAnfp0iVTokQJExISYk6fPm2yZs1qWrdubV2/Z88eExwc7MAKX04RERHW/x89etQULVrUlCpVyqxcudIYY8wHH3xg8uXLZ37++Wfz6NEjY4wxnTp1Mg8fPnRIvXCcxYsXm+nTp5sff/zRGGNMeHi42bZtm8mTJ495/fXXre2iv6aAfzJt2jTz1ltvmRYtWpjw8HBjjDF37941EydONLlz57b5GxEZGemoMl8akZGR5sGDB6ZixYpmwIABNutGjhxpMmbMaDp27GjOnz/vmALxXKLeO7du3TKPHj0yISEhxhhjTp48aWrUqGGqVKliFi1aZG2/fPly6997JD6BgYGmdOnSJm3atKZt27Y263bs2GHeeustU7t2bZs+R+xxpBsJjvn/b1QfPnwoSfrrr79069Yt7d+/XzVr1lStWrU0ceJESdLhw4c1evRonT171mH1vqyihnf27NlTgwYNUsqUKXXu3Dl99tlnWrJkiWbPni1fX18NGTJEPXv2VI0aNTR79my5uLg4uHK8SKdOnVL79u3VsmVL65EQZ2dn+fn5aebMmQoODlaZMmUkifMCESv379/XH3/8oePHj+vs2bPWKyR4enqqadOm6tmzp7Zs2aJGjRpJUoyRNoh/FotFyZIlU7JkyXT//n1JUnh4uKS//0ZUqVJFCxYs0IABA3TlyhVHlopYMv8/km358uWqV6+eypYtq+LFi2vevHnKnz+/vvvuO7m4uGjSpEkaNWqUBg0apHfeeUc3btxwdOmIo6jP3ZkyZdLnn3+uXLlyaffu3dq+fbu1jZ+fnwYOHKg7d+5o7ty51vc5Yo9POEhwLBaL9uzZo6JFi+rRo0cqVqyYypcvr4oVK6pUqVKaPHmy9cP5/Pnzde7cOXl7ezu46pfTzJkzNXXqVPXt21fLly/X8ePH9dprr2n48OFatmyZZs2apXfffVdXrlxR6tSpdePGDbm4uHCNz5dI9uzZ9f333ytPnjyaPXu2dbmTk5PKlCmjGTNm6I8//lCrVq0cWCUSMvPEnBCpUqVS586d1bp1ax07dkz9+vWzrvPw8NB7772ntm3bMuTVjp7sE+nvv9158uTRwoULFRAQIBcXF2u7HDlyKHPmzEqdOrWyZMnyosvFc7BYLFq5cqUaN26sevXqacaMGapcubKaNWum7du3K0+ePBo3bpwyZMigefPmacGCBdq3b5+yZ8/u6NIRR1EHuSSpTp06GjRokFxdXTV+/Hjt3LnTuq5MmTIaO3asxowZo1SpUjmi1ESN2cuRIF2+fFnVq1dX586d1a5dO23fvl1DhgzRpUuX9MMPP+ju3bvatm2bpkyZom3btqlIkSKOLvml1K9fP23evFmbN2+W9HeQunr1qho0aKDAwECNGjVK9evXlzFGkZGRcnZ2Vnh4OEe7k6hnzWJ7//59rV27Vl26dFGJEiW0bNkym21OnDihAgUKcE13xBD9NXX37l2lSJFCkuTm5qarV69q6tSpmj9/vho1aqTBgwdbtwsJCVGKFClksViYXTmeRf953rp1SxEREcqYMaP1S47XX39dERERWrRokTJmzKhUqVKpSZMmatiwoZo0aUKfJBLh4eF6//33lTt3bg0dOlSXLl1S1apVValSJU2ePNl6JPz27dsKCwuTi4uLMmTI4OiyEUcrV67Ut99+Kw8PD5UoUUJ9+vSRJC1ZskRfffWVXn31VXXp0kW+vr4OrjTx4zceEqQMGTKoZMmSWrVqlSSpXLly6t27t4oWLap3331XAwYM0OHDhwncDhL1XZ27u7sePXqksLAwOTk56fHjx8qaNauGDx+uGzdu6LvvvtOCBQtksVjk7OwsYwyBO4mK/iF64cKFGjFihEaOHKmzZ88qVapUqlGjhsaMGaMjR46ofv361u2cnJxUqFAhOTs7MwICNqK/pkaNGqXGjRurcuXK6tSpk27evKmsWbPq448/VpMmTbRw4UINGTLEum3KlCllsVhsZjrHfxe9T7744gs1bNhQ+fPnV5cuXbRixQo5OTlp6dKlSpYsmcqVK6eKFSuqaNGiOnLkiBo2bEjgTkTCw8N14sQJVa5cWffu3ZOfn5/efPNNTZo0SZI0ceJEXb58WenSpZO3tzeBOxHasWOH6tWrp/z58+vRo0dauHChGjZsKEmqX7++/P39denSJQ0ZMkR79+51cLWJH0e64XBR35Y+fPhQyZMnty4/fvy4SpYsqYkTJ+qjjz6yLj979qy8vLxkjFHq1KkdUDGiHD16VMWLF1f//v01cOBA6/I1a9ZoypQpunPnjpycnLRixQrr5WSQ9ES9hyWpd+/emj9/vnLmzKnkyZNr//79Wr16tUqUKKEHDx5o9erV6t27tzJnzqwtW7Y4uHIkBn379tW0adM0aNAghYeHa/r06UqWLJmWLVsmLy8vXbp0SbNmzdLYsWM1cuRItWzZ0tElJ3n9+/fXxIkTNW7cOCVPnlwjR45UZGSkevToYf3QPmXKFAUHBysiIkLdunWznlrEiJbEo1WrVnrw4IG2bt2qd955R99++61cXV0VEhKipk2bqlKlSuratSvzJiRCJ0+e1J49e3T79m117dpVISEhWrp0qb766ivlzp1bS5culfT3lUemTp2qWbNmKWvWrA6uOpF70TO3AU+zYcMGU7duXTN27Fib5Z06dTKNGjUyN2/etM5szEy0CcuMGTOMq6ur6dmzp9m3b585e/asqV27tvnyyy/NiRMnjMViMevWrXN0mXgBxo8fb7JmzWr27t1rjDFm9uzZxmKxmNSpU5stW7YYY4wJCQkxc+bMMQ0bNmS2cvyrZcuWmUKFCpldu3YZY4z59ddfTapUqcwrr7xifHx8TGBgoDHGmHPnzplp06ZZZzKH/axfv97kz5/f7NixwxhjzJYtW4ybm5t5/fXXzeuvv24WLlz41O3om4Qr6nNVcHCwuXPnjnX5jBkzTM6cOY2vr6/NlUf69OljcufObc6dO/eiS0U8OHv2rPHz8zPp0qUzEydOtC5/8OCBmTNnjilUqJBp0KCBdfm9e/ccUWaSQ+hGgnDgwAHTsGFDU6hQIVOkSBEza9YsExAQYHbs2GHSpUtn9u3bZ4whcCdUixYtMpkyZTLZsmUzWbNmNcWLFzcPHz40Fy5cMHny5DGHDx92dImws9u3b5tOnTqZWbNmGWOM+e2330zq1KnN119/bRo0aGDSpEljdu/ebYwxNh/eCN6I7snf8StWrDC9evUyxvx9OaL06dOb77//3qxdu9Z4enoaX19fc+3aNZttCHfxK/p79ObNm+b8+fNmxIgRxhhjVq5cadKlS2emT59ujhw5Yry9vU2JEiXMtGnTHFUuntPSpUtNhQoVjI+Pj+nTp4+5deuWiYiIML169TKFCxc2VatWNd27dzeNGjUyadOmNQcPHnR0yXgOGzZsMN9++60ZMmSIyZEjh024Nubvv88///yzyZo1q2nevLkxhs/e8YXh5XAIE204atT/Q0JCFBwcrL59++rUqVMKCAjQmDFjNHjwYKVPn16//vqrzfBzJCxXr17V5cuX9fjxY5UrV05OTk7q06ePli1bpo0bNzLDfBLztPMyd+3aJS8vLz18+FB16tRR165d1aFDB82fP19NmzaVJB04cEDFihVzQMVITO7fv2+dHff69etKkyaNatasqcqVK2vAgAEKDg7Wm2++qRMnTqhu3bqaN2+ezd8VxL9evXopIiJCffv2laurq9zd3VW/fn35+vqqX79+cnJyUrVq1XT58mXVqFFD3377raNLRizt3LlTtWvX1ieffKKUKVNq1KhRql69usaMGaNs2bJp3rx5Wr16tW7cuKECBQqoXbt2yp8/v6PLRhzt2LFDVapU0eLFi/X666/rxx9/1IQJE1SzZk2NGzfO2u7hw4davny5SpYsqVdffdWBFScthG68cFEfjHbv3q29e/fq3r17qlu3rnx8fKxtjh8/rqVLl2ratGkKCAhQ5syZtX//fqVNm9aBlSO2jh8/rq+++korV67U+vXrCVlJTPRws3DhQnl6eqp69erW9fPmzdOECRP0yy+/KE2aNFq3bp0WL16svHnzqlOnTkymhxiif4kzfPhwnTp1SoMHD1aOHDkkSWfOnFGlSpU0Z84cvfnmmwoICFCXLl3Upk0bVapUiYm57CD6+3z37t167733NH/+fJUuXVqSdO/ePZUuXVqtWrVS9+7dde/ePbVr10516tRRo0aN6JNE4ty5c9qwYYP++usv+fv7S5IOHTqkWrVqqXTp0ho1apRee+01B1eJ/+rs2bNau3atrl+/bp108u7du5o2bZpmzpypN9980yZ4I/7xyQcvVNQf8SVLlujTTz9V7ty55e7ursGDB2vx4sWqUaOGXFxcVLBgQRUsWFD169fX9u3bVbFiRQJ3IhEeHq6wsDBlypRJmzdvVsGCBR1dEuJR9HD0559/qk2bNqpYsaJSpkypcuXKSZJu376trVu3KigoSJL0/fffK2vWrOrWrZskcdk42Ij+mjpx4oRu3bql2bNnK2PGjOrWrZsyZ86szJkzK1u2bBoxYoRCQ0M1atQoSbIGbiboin9RgXv06NG6deuW3n33XWvgNsYoLCxMBQoU0KZNmxQWFqZNmzYpKCjIGriZpTxhM8bo9u3byp07t5ycnNSrVy/rumLFimn58uWqXbu2+vTpoz59+qh48eIOrBbPK6qf8+TJI0nq2rWrdV2aNGn0ySefSJLmzJmjTz75RNOnT3dInS8FR4xpx8tt27ZtJmPGjGbKlCnGGGMuXLhgnWxpzpw5MdpzLkniFBYW5ugSYEf+/v7m008/NXnz5jXu7u6mYsWKZuvWrcYYY+7cuWMqV65sLBaLyZs3rylYsCCvB/yr7t27m1dffdV0797d1KxZ0zg5OZl27dqZ69evG2P+njuidOnS5rXXXjOVK1e2vqaYFyB+Pfk3t1mzZsZisZgqVarYzMdgjDFr1qwx7777rilRooR5++236ZNEInofr1u3zqRIkcJUr17dXLp0yWb9wYMHjaurq/nwww9NaGioQ2rF84vez+vXrzcpUqQw5cuXN2fPnrVpd+fOHTNkyBBTtmxZExAQ8KLLfGkQuvFChYaGmjFjxpgBAwYYY4y5dOmSyZ49u2nfvr3p3LmzSZYsmVm8eLGDqwTwpOgfor/77juTJk0as2fPHnPmzBmzZ88ekz17dlOtWjXrjMZBQUHmp59+Mj/99JN1YqvHjx87pHYkfBs2bDBp0qQxO3futC5bvHixcXJyMm3btjV//fWXMebvSX7OnDljfT3ymrKfoKAg6/+7d+9uXF1dnzoz+b1798z9+/etH/Dpk4Qrqo8ePXpkjPnfpJarV682zs7Opk2bNtaJCaPaHj582Jw6dcoB1eK/erKf16xZY5ydnU2rVq2sX2ZGuXPnjvX3LOyD0A27i/rF/eDBA2OMMfv37zd79+419+/fNxUqVDCtW7c2ERER5uTJkyZZsmTGYrGYBQsWOLJkAP9v0aJF1kvIRAWdli1bmsaNGxtj/vf+PnHihMmYMaOpVKmS9Yh3dMwojX+ycuVKkytXLhMQEGAiIyOtr7U5c+YYi8VievToYa5evWqzDUdT41f0n+dXX31l6tWrZ/7880/rslatWpmUKVOalStX2mwX/WgafZJwRfXTmjVrTIsWLUzt2rVNq1atrJf9ih68owIZIw0Tr7j0M14MTraB3VksFu3du1dFixZVRESESpQooVKlSunChQu6f/++WrVqJScnJ7m5ualJkyb6/PPPVahQIUeXDbz0pk+frm7dumnChAkKDg62njv76NEjhYSESPr7fLHQ0FAVKFBAw4YN07Zt2/Ttt9/qwIED1vWSON8W/yhNmjS6cOGCTp8+LYvFosjISElShQoV5OXlpdGjR2vs2LGS/vea4nzh+BP9/OtDhw7p/v37+uWXX/T111/r4sWLkqQpU6bovffeU5MmTbRq1SrrttFnjKdPEi6LxaJly5apXr16ypYtm958802dOnVKxYoVU2BgoGrUqKFVq1Zp9uzZ6tatmwIDA7kaQCIV137GC+Lg0I8kLupb0uDgYJM7d27TpUsX67rff//dWCwWs3XrVvPgwQPTv39/U6lSpRjnjAFwnC5dupjXX3/dfPnll+bu3bvGGGOWLVtmLBaLmTdvnk3bWbNmmYYNG5ps2bKZFi1aOKBaJGYtWrQwefPmNXv37rUuCwwMNN26dTMzZswwFovFrFq1yoEVJn09evQwr7zyiunbt6+pX7++cXNzM02bNjUXL160tmndurWxWCw2pwIg4fvrr79M2bJlzZgxY4wx/zu9r1WrVsaY/41S+OWXX0z69Omtw8yRuNDPCRehG3YRFbbv3btnXTZx4kRTuXJls3nzZuuy999/31gsFlOkSBHj4eFhDhw48MJrBRBT9OHgnTt3NqVKlTJDhw61DjXv0aOHcXNzM9OnTzc3btwwN2/eNG+//baZOXOmWb16tbFYLObIkSMOqh6J0e7du03Dhg1N5syZzeTJk83cuXNN9erVTcWKFc2jR49MwYIFzcCBAx1dZpK1detWkzZtWpvTQzZs2GCSJUtmmjVrZs6fP29dPnz4cM7dTmQuXLhgcuTIYa5cuWKuX79usmbNatq0aWNdP3/+fHP79m1jjDH37993VJn4j+jnhItxQIg3Jtol3y0WizZv3qxs2bLpxx9/1MWLF9W8eXM9fvxYM2fOtLabNWuWfvrpJ3Xr1k0HDhzgkhRAAmCMkbOzs8LDwyVJY8eOlZ+fn5YuXaoffvhBISEhGjx4sPr27at27drJ19dXJUqU0Pnz59W0aVN5enoqV65cXOYPcVK6dGkNGjRIzZs3V9++ffXll18qPDxc69atk7u7u5InTy5vb29Hl5lkPX78WKlTp1bOnDklSREREapcubIWLVqk+fPn2ww19/f3l4uLi/V3BBKuqD7LnDmzChYsqFWrVsnX11dvv/22xo8fL0m6fPmyfv31V+3cuVOSlCJFCofVi+dDPycCjk79SLrGjBljLBaLqV69umnXrp1ZtGiROXfunEmWLNlTLw0GwPGenAgp+ukeXbp0McWKFTNffvmldRTLwYMHzfz5883ixYutR8d79OhhSpYsaW7duvXiCkei9uSETQEBATYjpfz9/U2OHDmskwHhv4n6eUf/uR86dMg4OTmZX3/91Rjzv9EuV69eNa+88opxcnKyOWKGhO/48ePmjTfeMIcOHTJhYWGmUaNGxmKxmEaNGtm069WrlylatGiMyQqRONDPiYPFmGiHJ4Hn0L59e6VPn15Dhw6VJD18+FDJkyeXJL3zzju6fv26OnfurMGDB6tixYq6d++eLl++rJkzZypfvnyOLB1ANNEnUxo/frx27NihwMBAvfnmm/r8888lSV27dtWWLVvUoEEDtW/f3uZo9unTp/X1119r8eLF2rhxo4oWLeqQ/UDCYYyRxWKx/ht92T+Jei3u27dPM2fO1IIFC7RmzRpGQ8WD6O/zoKAgJUuWTBEREUqRIoXatm2rdevWaerUqapcubIk6c6dOxo8eLAqVKigxo0ba+7cuWrcuLEjdwGxdPr0afn5+alfv37q2rWrgoODVbFiRUlS06ZNlTlzZm3fvl1z587Vli1b+J2dSNHPiQPDy/Gf/PDDD1q0aJGaNWsmSdqxY4cGDhyoFStWSJKGDh2qnDlzytPTU9u3b9etW7d08uRJ7d69W2vXrhXf+QAJR9QHcX9/fw0bNkyvvvqqmjZtqv79+6tt27aSpDFjxuiNN97QL7/8oq+++so6i/nDhw915swZPX78WJs3b+aPOhQZGWkN10FBQXr06JEePXoki8WiiIiIZ25njLG+FnPnzi0/Pz/t2LGDwB0Pogfur7/+Wu+9954qVaqkDz/8UJcvX1a/fv1Urlw5NWnSRN98841mzJihxo0ba+/evapTp46KFy9uvTIBEqaomf8jIiKUN29eDR48WN9//72OHDkiDw8Pbdq0ST4+Plq0aJFGjhypwMBAbdu2jd/ZiUzU52f6OfFwcXQBSJyijlScOHFCvr6+8vHx0a5duzRq1Cg9ePBAK1as0IEDB9S6dWvlzJlTO3fuVJ06dTR//nwtX75c8+bNU/Xq1bkcBZDA7N69W4sXL9b8+fNVvnx5bdu2TS4uLvL19bW2GTNmjFq0aKGbN29azwlLnjy5qlWrpsqVK1tHuuDlFT04jxw5Uhs2bNCdO3eUNWtWffXVV8qbN+8zt4v6uzBz5ky98sorat68+QurO6mL6pO+fftqypQpGjVqlFKlSiV/f3+9+eabOn78uPr166e8efNqzJgx8vLyUsaMGbVp0ya5urrKzc1NXl5eDt4L/JOQkBClTp3aepnGsmXL6qefftLhw4dVpEgReXp6avbs2Xr06JEiIiLk7u4ud3d3B1eNuLp//z79nNg4aFg7ErnVq1cbY4z57rvvjK+vr/nkk0+Mk5OT2bdvn7l06ZKZNWuW8fDwME2bNjU9evQwGTJkMEuWLDHG/H0OWVhYmCPLB/AMq1evNmXKlDHGGLNo0SKTKlUqM3HiRGOMMXfu3DEbNmywto06//vJ88CBKH379jUZMmQwc+bMMcuWLTM+Pj4mW7Zs1svPRRf9/OKJEyea5MmTm99+++1FlvtSOHv2rClZsqTZuHGjMcaYX3/91aRJk8Z89913Nu1u3bplHj16ZL3fu3dvkz17dnP27NkXWS7i4ODBg8bb29uMGjXKHD161Lq8Q4cOJnv27CY0NNSB1SG+0M+JE6EbcdazZ0/j5uZm/dD05ptvGicnJ9O4cWObdpcvXzaNGzc2TZs2Nc7OziZbtmzmjz/+cETJAJ7iaWF5x44dpnDhwmb06NHGw8PDTJgwwbpu7dq1pnLlyubUqVP/+BiAMcacP3/elCpVyvz+++/GmP+Fu/HjxxtjbCfzejJwe3h4mMWLF7/4opOgJyep2717t8mYMaN5/PixWb58uUmVKpX1fX7v3j0zfvx4ExQUZG2/d+9e06lTJ+Pl5cVlPRO4o0ePmmHDhplXX33VVKhQwbRr187cvXvXXLp0yVStWtWMGDEixusBic/Ro0fNl19+aXLlymUqVKhg2rdvb4KCgqz9/NVXX9HPCRChG3Gyd+9ekzlzZrNr1y5jjDH79u0zGTNmNBUqVDBvvPGGGTNmjE37e/fumd9++8289dZbJnny5MyYCCQQ0cPyqlWrzLx588yxY8fMnTt3TP369U3y5MlNnz59rG0ePnxo3nnnHdOkSROCNp7qyQ95+/btMxkyZDCPHj2KEe5CQkLM+PHjYxzxnjRpkvHw8DCLFi16YXW/LPbu3WuM+fsIdu3atc2gQYNMqlSpzKRJk6xtDh48aOrXr2927txpXXbz5k2zcOFCZo5PgJ4VrI4dO2amTp1qcufObYoVK2Y+/vhjU6lSJdO0adMXXCHsiX5OXJi9HHFy7tw51alTRz179lTq1Kn1888/q3v37ipSpIg6duyo06dPq0mTJurUqVOMbQMDAzkXDEhg+vTpo++++05ZsmTRhQsXNGnSJFksFk2YMEHp0qVTo0aN5OzsrJ9//lnXr1/XgQMH5OLiYjMhExDdnj17VLp0ad25c0cffvihSpQoodGjR2vUqFFq06aNJOnw4cMaPHiwevToobJly0qSvvvuO33++eeaOXOm6tev78hdSHJWrlypQYMGaenSpcqQIYMaNmyoFStWWCdNlKQHDx6oYcOGcnZ21i+//GLz/jaxmHEeL1ZUn2zdulVbt27VjRs3VKdOHZUuXVqpUqWyths5cqSOHTumOXPmSJJu3LihDBkyOKpsPCf6OfEjdCNWHj9+LFdXV926dUtDhgzR5s2bdfToUf3444/WSW4CAgLUp0+fGME7PDxcLi7M2QckBCbaJZwuXryoDz74QCNHjlS+fPk0bdo09e3bV99++63c3Ny0e/duLVq0SMWKFVPWrFk1Y8YMubq6KiIiwjp5CxDd6tWr1a9fPy1dulTe3t5q3LixfvnlF/Xq1UsjRoyQ9L9w5+TkpF9//VVOTk66cuWK2rRpoxYtWqhJkyYO3ouk59ixY/Lz87N+8XHv3j2VLVtWrq6ueuONN5Q5c2atXr1af/31l/bv3y9XV1e+WEvAon6PL1myRB999JHefvttnTt3Tq6uripbtqz69eun1KlTW9tHRERo+fLlypcvn/Lnz+/AyvE86OckwmHH2JFoDBs2zMydO9c6pPT77783FovF5MuXz8yZM8embUBAgPnoo49MxYoVzYgRIxxRLoBniD4s/K+//jKnT582/v7+Jjw83Lp89OjRxsXFxYwZM8bcu3fP3L5922b948ePX2jNSFxOnjxpPDw8rJNyhYSEmOLFi5siRYqYjh07mqFDh5qKFSuawoUL20yo+fjxYxMYGOiospOU6BMcRkZGWt+/w4YNM0WLFrXOrRIUFGQ+++wzU6lSJVOrVi3TqVMn6/ub93nCt2PHDpMtWzYzdepUY4wxFy5cMClTpjR58+Y1n332mbl3754xxtj8/kbiQz8nHXyFiX914cIFFSpUyPqNt5OTk0aOHClfX19NmjRJU6ZMsbb18vLSiBEjlCFDBm3cuFF37txxVNkAnhD1Hv7888/11ltv6fXXX9fKlSv1559/Wtt07dpVX3/9tXr27Kkvv/xSrq6u1qPaxhhGrcAq6nrA0a8LnD9/fvXv31+TJ0/WiRMnlCJFCm3btk1VqlTRH3/8oZ07d1qv9ezq6qrw8HBJkouLizJlyuSwfUlKot7ngYGBslgsNpcUslgsOnXqlCTJw8ND3377rdavX69ff/1V3377rVxcXBidloCZ/x+cGhoaqlu3bql69epq2bKlzp8/r8qVK6tRo0aqV6+e5s6dqyFDhig4OJhRSYkY/Zy0MLwczzRr1iw5Ozvr/ffflyRt3LhRAQEBatiwoVxdXfXnn3+qf//+unr1qj744AO1bt3auu2NGzcUERGhzJkzO6p8AP8v+jDRefPmqVu3burTp4/OnTunyZMn69NPP1XHjh2VI0cO6zbDhg3TihUrtG3bNs7lxD+6evWqsmbNar2/bds2ffbZZ+rfv7/NudlR4TzqtUi4s58lS5aocePGGjBggKpVqyY/Pz9JUsuWLbV161adPHlSzs7OMc7VfvI+Ep79+/drxowZ6tOnj0JCQpQjRw69/fbbypYtm2bMmKGwsDDly5dPjx49UvPmzfX111/Tp4kQ/Zz0cKQbTxUSEqI5c+Zo/Pjxmj59uiRp+vTp6t69u+bPn6/79+8rd+7cGjp0qLJly6Yff/xR06ZNs26fKVMmAjeQQESFnM2bN2vr1q0aMWKEPvvsM40ZM0Zff/215s2bpwkTJujixYvWbfr27WsN3Hw3i2dZunSpXnnlFQ0YMEDbt2+XJJUvX16+vr7q2bOnwsLCrG2dnJxszhEmcNtPoUKF9MMPP2jJkiX67LPP9MEHH+jy5cvq3LmzcuXKZf17/eSHdD60J3xbt27Vli1bdPPmTeXNm1dnz57VlStX9PHHH0v6e4RD0aJF1bp1a3Xu3Jk+TaTo56SH0I2nSpkypWbPnq3s2bNr1qxZWrhwoX788UfVqFFDQ4cO1dKlS3X//n299tprGjp0qHLkyKFvv/1Ws2fPdnTpAJ4iICBALVu21OzZs21O+/j000/l7++vn376SZMnT9a5c+es66ICN3/M8SyFCxfW1KlT9dtvv6lz585q2rSpLly4oA4dOihPnjw2X8bCPqJGEEh/D/GXpLx586pNmzZauHCh+vTpo4MHD+rdd99V//79de3aNW3bts1R5SKOor70fPjwoSSpS5cuSps2rTp37izp789rkZGR2rFjh27duqVp06bpwYMH6tq1q7Jnz+6wuvF86OckzGFnkyPBioyMtE5wc/z4cVOzZk3j6+trli1bZowx5oMPPjD58+c3s2fPtk7gcPr0adOqVStz4cIFh9UN4J8dPnzY5M2b11SrVs0cOXLEZt0PP/xgnJ2drddRBp4UfSK+JyfaOnv2rFm6dKkpWrSoKV68uHnnnXdMwYIFTbNmzV50mS+V6H0yYcIE07ZtW9O0aVOzePFi69/nKJMmTTKtWrUyFovF+Pj4PPMaz0h4Vq9ebd5//32zZs0aY4wxFy9eNLlz5zZffvmliYyMNB07djSvvfaayZ49u/Hy8jL79+93cMV4HvRz0sY53YjB/P+RrQULFmjx4sW6fPmyDh8+rEyZMmn06NF699139eGHH2rv3r3q16+f6tSpo9SpU1svKwYg4Tp8+LA+/vhjlSpVSp07d1bBggWt65YsWaK6desyIQtiiD4vwIQJE3Tw4EHdvXtXjRs3VvXq1eXh4WFtO3XqVO3bt0+TJ09W/vz5dfz4cUZL2Jm/v7+mTZumTz75RKdOndK1a9dUqVIl9e/f3+aSQpK0ZcsWlS1bVi4uLoxkSQSMMWrbtq2mTp2qtGnT6rPPPlOLFi00d+5cHThwQF999ZUyZ86snTt3KigoSCVKlFDOnDkdXTbiiH5O+gjdeKrdu3ercuXK+u6771SuXDk5OzurdevWCgkJUd++fVWvXj19/PHHWrlypcaNG6fGjRtL4nwwIDE4ePCgWrVqpZIlS6pLly7y8fGxWc91uPEsUeGudevWOnXqlC5duqQ33nhDAwYMkKenp03b7du3y9fXl3BnB9F/ntOnT9eXX36phQsXqkSJEvrtt99Ur149FShQQFWqVNGwYcOUMmXKGBPXMZFdwvXk+2XPnj0aO3asChUqpKVLl6pUqVIKDw/X9u3b1bJlS3Xv3t2B1SK+0M9JG+d046kOHz6snDlzqmnTpsqXL59y586tOXPmyN3dXV26dNFvv/2mGTNmqH79+ipVqpQsFgsfqIBEonjx4po6daoOHTqkgQMH6vz58zbrCdx4mqj5PdasWaNhw4bpk08+0YEDB7R69Wp9/vnnunfvniRZLwNWrlw56yWo+PsQv6J+nvfv31fq1Kn1/vvvq0SJElq2bJlatGihMWPGqFatWpozZ44GDRqk4ODgGAGbwJ1wWSwW/f7775o6daokqVSpUkqfPr3Onj2r33//XUWKFJEk/fHHH+rZs6d27drlyHLxH9DPLw9+4+KpkidProiICN2/f1/JkyfX48ePlTVrVv3www8qW7asevfurYiICE2YMMHRpQJ4DsWLF9f333+viRMn2lwqDIjy5NG20NBQffDBB9Zw98knn2js2LG6du2aJk2aJDc3N/Xv319p06a1eRzCnX3MnTtXW7Zs0cCBA1WxYkVdu3ZNgwYN0ueff65OnTrp6tWrmjNnjubPny8vLy/16NHD0SUjliIiIrR79259/vnn2rJli9q2batx48apVKlSGjt2rPr376/g4GAlS5ZMS5cuVYYMGRxdMp4D/fxyYXg5nurPP/9U4cKF1bNnTw0ZMsS6fP/+/erevbuyZMmiESNG6JVXXnFglQD+q6hgFf2cXSC6ffv2qVSpUnr48KHu3r0rSapVq5aaN2+uHj16KCAgQKVKlZKTk5M6duyoXr16ObbgJOrJL0EGDx6sX3/9VXPnzlXevHm1ceNGtWzZUsuXL5ePj48OHjyo4cOHq1q1amrZsiXv70ToyJEj6tmzp+7fv6/XX39db731liZOnKhevXqpbNmykqS7d+8qTZo0ji0U/wn9/HLgNzCeKnfu3JoyZYpGjBihzz//XBcuXNDdu3f1yy+/KGfOnJo4cSKBG0gCoi4LxgdyPM2GDRvUoUMH7du3T8mTJ1fmzJl17tw53b17V2+99Zakvy9HV65cOQ0YMICjqXYSPXDfvn1bkjRw4EA5OzurQ4cOkiQPDw+5u7vrt99+0x9//KEBAwYoZcqUatWqlZycnKyXE0PiUaRIEc2ePVvt2rXT5s2b1bBhQx05ckQrV660tiGIJX7088uBI914JmOM5s2bpzZt2ihjxoxycnLSnTt3tG7dOpUoUcLR5QEA4tmTIx5Onjypxo0bq27duho6dKgkaceOHWrTpo2aNWumunXrqnfv3kqfPr1mzpwpi8XCRHx2NGzYMG3fvl3t27fX22+/rT/++EPvvvuu2rVrp44dO6pTp05as2aNHjx4oOzZs2vbtm1ydXVlIrsk4PHjx+rdu7e+//57pU2bVn/++WeMmemR+NHPSRehG//qwoULOnLkiB4+fChfX18uUQAASdzhw4eVK1cueXh4aNmyZWrYsKF+/fVX1apVSw8fPlSPHj20bt063b9/X6+88oq2bt1KuLOziIgINW3aVIsWLVLKlCnVqVMnNWzYUIsWLdL58+f1zTffKG3atDpz5oyCgoJUtmxZOTs7M0t5EhD9fbV+/XrlyZOHuTiSIPo5aSN0AwAAq8mTJ6tdu3Zq0qSJhg0bply5cqlnz546cuSIxo0bp3z58unRo0c6e/asgoKC5OvrS7h7QTZu3KiZM2eqTJkyWrBggfLly6c7d+5oz5496tGjh3WoeRRGHSQdfKH1cqCfky5O4gMA4CUWGRkp6e8Pe5KUL18+vfbaazp06JDKli2r2bNnK1u2bHJ3d9euXbsUGRmpZMmSqWDBgtajqREREQRuOxkzZoxGjx4tSapYsaKcnZ21b98+rV27VmXLlpWHh4cuXryozz77TMeOHbPZlsCddBDEXg70c9LFX0gAAF5iUedwP378WG5ubipcuLCqV68uHx8fpUyZUitWrFCKFCm0detWBQYGqm7dujEm9SHc2cfjx4/14MEDDRw4UHv37lXLli01ZcoUlS5dWmPHjlXPnj3VtGlTpU6dWsePH1eBAgUcXTIA4CkYXg4AwEvup59+UqdOnbRgwQJVqlRJhw8fVo0aNfTLL78oX758WrNmjQYPHqwzZ87o888/1xdffOHokl8qx48fV//+/XX16lUVLFhQVapU0bJly9SnTx/rxKZRw1IZUg4ACQ+hGwCAl9yff/6pESNGaO3atapdu7a6dOmikydPaujQoVq4cKFy5cqlK1euaOLEiRo0aBBDyR3g1q1b2rp1q4YNG6YjR44oderU6tKli/r162dtw/mgAJAwEboBAIAk6eeff9by5cu1adMm1a1bV7dv31b58uXVrl07ubq6WtsxaZpj9evXT6NHj5avr682btzo6HIAAP+C0A0AwEvgn46CRr8+95UrV7RlyxZ16dJFt27dUoYMGXTs2DFlypTpRZaLp4jeh3v27FHJkiXl7OzMEW4ASOAI3QAAvCSih+snPRncLl68qEGDBunq1atatWoV5wknEE/2E+dwA0DCR+gGACAJ8/f3V3h4uL755htJ/xy8o0S1CQkJUYoUKZigCwCA/4DrdAMAkETdv39ft27d0vbt2zVkyBBJf18iLOra3M/i5OQkY4xSpkwpi8UiYwyBGwCA50ToBgAgCTLGKFWqVPrqq69Uvnx5rVy5UoMHD5b078H7ySHMnC8MAMDzY+pRAACSIIvFosjISKVPn17+/v6KjIzUqlWrJEkDBw60Bu8nh5pHD9zTpk1TtmzZVKNGjRdePwAASQVHugEASGKijmJHBer06dOrd+/eKleunFasWPHMI97RA/eUKVPUunVrPXr06AVXDwBA0sJEagAAJCHRj14fPHhQYWFhSp48uYoUKaLg4GB98cUX2rJli2rVqqWBAwdK+nsGbCcnJ2vgnjRpknr16qWZM2fq3Xffddi+AACQFDC8HACAJMIYYw3cn3/+uebPn69kyZLp0qVLatGihfr27au+ffsqMjJSq1evlpOTk/r3728zSVpU4J4+fTqBGwCAeMDwcgAAkoioI9WjR4/W1KlTNXv2bB07dkxt2rTRtGnTdPHiRaVNm1Z9+/ZV+fLlNWPGDM2YMcO6/ZgxY+Tv768ZM2aoQYMGjtoNAACSFI50AwCQiF2/fl2ZM2eW9L+h5Xv37pW/v7/Kli2rxYsXa9q0aRo1apTKlCmjR48eKX369OrVq5deeeUVffjhh5KkkJAQrVy5UuPHj1f9+vUduUsAACQpnNMNAEAi1aJFC504cUI///yz8uTJI+nv8Ozn56cxY8YoZcqUqlatmr7++mu1a9dOYWFhGjlypCpWrKgKFSpYHyciIkLOzs569OiRkiVL5qjdAQAgSWJ4OQAAiVTfvn114cIFde7cWWfOnJEka9Bu3769KlWqpPHjx6tdu3aSpHv37mnDhg06ePCgzeNEndNN4AYAIP4RugEASGTWrFmjwMBA5cuXT7t27dLu3bvVqVMnnTp1SpJUr149ZcyYUYUKFdLbb78tSbp165Y++OADhYWFqUOHDo4sHwCAlwqhGwCARGTy5Mlq0KCBlixZolu3bum1117Tnj17tGfPHnXq1EkXLlxQhQoV1KpVK7m5uSlfvnwqW7asatSooRs3bmjTpk1ydnZWRESEo3cFAICXAud0AwCQyHz66adav369unTposaNGytDhgw6e/asSpcurZIlS2ratGnKnj27Tp8+rfXr1ysoKEjZs2dX06ZN5ezsrPDwcLm4MJcqAAAvAqEbAIBEImrCM0lq37691q1bp27duj01eE+aNEm5cuX6x8cAAAD2x/ByAAASiejDwidMmKBq1app9OjRWrBggXWo+e7du3XgwAF17NhRJ06ceOpjAACAF4fQDQBAAhcZGWn9f/TQPGHCBFWpUsUmeOfOnVu7d+/WqlWrNG3aNEeUCwAAomF4OQAACVhkZKScnP7+jnzDhg0KCAhQlixZVLBgQWXKlEmS1LZtW23YsEHdu3dXo0aNlCFDBl29elXe3t4c2QYAwMEI3QAAJFDGGFksFkmSv7+/Zs+ercyZM+vy5cuqU6eOWrRooQoVKkiS2rVrp40bN6pVq1Zq06aNPD09JYlJ0wAAcDCGlwMAkEBFBe6vv/5ac+bM0aJFi7R//3517NhRP/30k8aOHatNmzZJkiZOnKhixYpp79698vDwsD4GgRsAAMfiSDcAAAlM9CHlt27dUteuXVW5cmV9/PHHWrZsmT7++GM1a9ZMq1atUoECBdSrVy9VrFjRZtvoR8kBAIDj8PU3AAAJTFTg/v3331W4cGG1b99e+fLl08GDB9WlSxcNGjRInTt31qhRozRkyBCFhoYqRYoUev311+Xk5GQT2gEAgGPxFxkAgAQi+izlffr0UePGjfXo0SMVL15c6dOn15o1a1SgQAG1adNGkuTq6qpSpUrJx8dHJUuWtG5L4AYAIOHgrzIAAAlEVFgOCAhQRESE5s6dq+zZsytZsmSSpJCQEN27d08XL16U9PeR8Pfff1/jxo2zHuEGAAAJC6EbAIAEZP78+cqSJYuWLFmidOnSSfrfhGplypRRQECAmjRponz58un06dP64IMPJP090zlHuAEASHg4pxsAgATE19dXzZo107x583Tz5k1J/7vsV+3ateXs7KxTp07p4cOH6tGjh1xcXBQREcH1uAEASKCYvRwAAAd51oRnFy5cUOfOnbVjxw5t2bJFBQoUeOb1tgncAAAkbIRuAAAcIHrg3rdvn6S/z+kuUaKEJOnKlStq06aN9u3bpy1btih//vwEbAAAEiFCNwAAL1j0a2j3799fc+fOlZOTkwIDAzVw4EB17txZzs7Ounr1qtq0aaODBw9q7dq1KlSokIMrBwAAccWMKwAAvGBRgXvo0KGaMmWKpk+frkOHDumjjz5Sjx49NGjQIEVERChr1qyaPHmysmfPLn9/fwdXDQAAngcTqQEA4AB//PGHdu3apWnTpumNN97QL7/8otmzZ+vDDz/U8OHDZbFY1K9fP2XNmlXLly9X+vTpHV0yAAB4DoRuAABegCcnTUufPr3eeecdVapUSVu3blWHDh00dOhQdejQQU5OTho6dKiCg4M1evRoZcyY8amPAQAAEj7O6QYAwM6ih+U///xTyZMnV4YMGeTu7i5J+uyzz3T37l1NmTJFyZIlk7+/v/bu3avw8HBt2rTJOhwdAAAkPnxdDgCAHRljrIHb399f77zzjooVK6YaNWpo/PjxkqTjx4/LGKNkyZLp8ePH+uOPP9S9e3dt3rxZFotFfD8OAEDixfByAADsJPoR7nnz5mnWrFmaOHGi7t69q+PHj6tLly5yc3NT7969VbNmTQUHB+vixYsy/9fenYZGebVxGL/GxLjExLhUixBSpsQlGiEohdJSUGM0lZRqVAguIEawxhaNrWlJpfaDQhVR4vZNhFJQ0FGKWxQXFHElica1cUwNhbiGuKEmhvRDYXiLhZf2fR+nidcPBoY55zxz5vn2577PM+3t5OXlAX9+0rkkSep4bC+XJClgx44d46effiIrK4vFixcD8PjxY7Zu3crXX3/Nli1bSEhIYPfu3QwcOJAffviBxMRE/5dbkqROwNAtSVKAbt++zYcffsjdu3cpKyujvLw8NtbU1MTcuXNJT0+noqKClpYWkpKSAHj58iWJiTakSZLU0XmmW5KkAL399ttEIhEGDBhAJBKhuro6Nta3b1/69etHXV0dQCxwAwZuSZI6CUO3JEkBGzlyJJFIhLa2NtatW0dNTQ3wR4v51atXSU9Pj+8GJUlSYGwvlyTpNamurmbmzJk0NTUxevRokpKSqK+v5/Tp0yQlJfnQNEmSOiEr3ZIkvSY5OTls376dHj168PDhQ8aPH09VVRVJSUm0trYauCVJ6oQM3ZIkvUYjRowgEonQ0tJCVVUVN27cAKBr165x3pkkSQqC7eWSJMVBdXU18+fPJxwO89133zF06NB4b0mSJAXASrckSXGQk5PDhg0baGxspHfv3vHejiRJCoiVbkmS4uj58+d079493tuQJEkBMXRLkiRJkhQQ28slSZIkSQqIoVuSJEmSpIAYuiVJkiRJCoihW5IkSZKkgBi6JUl6A4RCIXbv3h3vbUiS9MYxdEuS1Ancvn2bzz//nHA4TLdu3UhPT6egoIDDhw/He2uSJL3REuO9AUmS9L/59ddf+eCDD0hLS2P16tVkZ2fT2tpKZWUlJSUlXLt2Ld5blCTpjWWlW5KkDm7BggWEQiHOnj1LYWEhgwcPZvjw4ZSWlnL69Om/XFNWVsbgwYPp2bMn4XCYZcuW0draGhu/cOECY8aMISUlhdTUVEaNGsX58+cBuHXrFgUFBfTp04fk5GSGDx/Ovn37YmsvXbpEfn4+vXr1YuDAgcyaNYv79+/Hxnfs2EF2djY9evSgX79+5Obm8vTp04DujiRJ8WWlW5KkDqypqYkDBw6wYsUKkpOTXxlPS0v7y3UpKSls3bqVQYMGUVtby7x580hJSWHp0qUAzJgxg5ycHDZv3kxCQgI1NTV07doVgJKSElpaWjh+/DjJyclcuXKFXr16AdDc3MzYsWMpLi5m7dq1PHv2jLKyMqZPn86RI0dobGykqKiIVatWMXnyZB4/fsyJEydob28P5gZJkhRnhm5JkjqwGzdu0N7eztChQ//Wum+//Tb2/p133uHLL79k27ZtsdDd0NDAV199FbtuZmZmbH5DQwOFhYVkZ2cDEA6HY2MbNmwgJyeHlStXxj7bsmUL6enp/PLLLzx58oSXL18yZcoUMjIyAGLXkSSpMzJ0S5LUgf3TCvH27dupqKggGo3GgnBqampsvLS0lOLiYn788Udyc3OZNm0a7777LgBffPEFn332GQcPHiQ3N5fCwkJGjhwJ/NGWfvTo0Vjl+z9Fo1Hy8vIYN24c2dnZTJgwgby8PKZOnUqfPn3+0e+QJOnfzjPdkiR1YJmZmYRCob/1sLRTp04xY8YMPv74Y/bs2UN1dTXl5eW0tLTE5ixfvpzLly8zadIkjhw5QlZWFrt27QKguLiYmzdvMmvWLGpraxk9ejTr168H4MmTJxQUFFBTU/OnV11dHR999BEJCQkcOnSI/fv3k5WVxfr16xkyZAj19fX/3xsjSdK/RKjdQ1SSJHVo+fn51NbWcv369VfOdTc3N5OWlkYoFGLXrl18+umnrFmzhk2bNhGNRmPziouL2bFjB83NzX/5HUVFRTx9+pSff/75lbFvvvmGvXv3cvHiRcrLy9m5cyeXLl0iMfG/N9S1tbWRkZFBaWkppaWlf++HS5LUAVjpliSpg9u4cSNtbW2899577Ny5k7q6Oq5evUpFRQXvv//+K/MzMzNpaGhg27ZtRKNRKioqYlVsgGfPnrFw4UKOHTvGrVu3OHnyJOfOnWPYsGEALFq0iMrKSurr66mqquLo0aOxsZKSEpqamigqKuLcuXNEo1EqKyuZM2cObW1tnDlzhpUrV3L+/HkaGhqIRCLcu3cvtl6SpM7GM92SJHVw4XCYqqoqVqxYwZIlS2hsbOStt95i1KhRbN68+ZX5n3zyCYsXL2bhwoW8ePGCSZMmsWzZMpYvXw5AQkICDx48YPbs2dy5c4f+/fszZcoUvv/+e+CP6nRJSQm//fYbqampTJw4kbVr1wIwaNAgTp48SVlZGXl5ebx48YKMjAwmTpxIly5dSE1N5fjx46xbt45Hjx6RkZHBmjVryM/Pf233S5Kk18n2ckmSJEmSAmJ7uSRJkiRJATF0S5IkSZIUEEO3JEmSJEkBMXRLkiRJkhQQQ7ckSZIkSQExdEuSJEmSFBBDtyRJkiRJATF0S5IkSZIUEEO3JEmSJEkBMXRLkiRJkhQQQ7ckSZIkSQExdEuSJEmSFJDfATcXvcj9A2g/AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "---------------------------- Sample Count Diagramming Complete ---------------------------- \n",
            "\n",
            "\n",
            "=============================== Optimizer, Loss Function, and Model Architecture ===============================\n",
            "\n",
            "Loading model from: /content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth\n",
            "Model loaded successfully.\n",
            "\n",
            "Chosen Optimizer: <class 'torch.optim.adam.Adam'>\n",
            "Chosen Loss Function: CrossEntropyLoss()\n",
            "\n",
            "Model Architecture: DeepFakeDetectorGraphsAndStats(\n",
            "  (_BatchLossAndOptimization__loss): CrossEntropyLoss()\n",
            "  (lstm_1): LSTM(40, 256, batch_first=True, bidirectional=True)\n",
            "  (dropout1): Dropout(p=0.5, inplace=False)\n",
            "  (lstm_2): LSTM(512, 1024, batch_first=True, bidirectional=True)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",
            ")\n",
            "\n",
            "---------------------------- Optimizer, Loss Function, and Architecture Complete ----------------------------\n",
            "\n",
            "\n",
            "=============================== Evaluating Model on Test Set ===============================\n",
            "\n",
            "Loading model from: /content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth\n",
            "Model loaded successfully.\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fdf4d0614844da4aa76f5f9a740a648",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[Testing]:   0%|          | 0/34 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3032530721.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3032530721.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_class_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_optimizer_loss_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msns_scatter_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3611513276.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(self, past_model)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No gradient computation during evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mtest_pbar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"[Testing]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_pbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0;31m# Move data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3921098353.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0mfile_index_within_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcumulative_count\u001b[0m \u001b[0;31m# Calculate the file index within the class by subtracting cumulative count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_index_within_class\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Retrieve the item using setup_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;31m# Update cumulative count for the next iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3921098353.py\u001b[0m in \u001b[0;36msetup_data\u001b[0;34m(self, class_index, file_index_within_class)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0msr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m                 \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sample_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_duration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;31m# Catch errors during audio loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Use numpy to vectorize the resampler along the target axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;31m# This is because soxr does not support ndim>2 generally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         y_hat = np.apply_along_axis(\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0msoxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_shape_base_impl.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;34m'Cannot apply_along_axis when any iteration dimensions are 0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         ) from None\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;31m# build a buffer for storing evaluations of func1d.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soxr/__init__.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, in_rate, out_rate, quality)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivide_proc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# For testing\n",
        "def main() -> None:\n",
        "    # Need to change directory to wherever you extracted LibriSeVoc\n",
        "    if os.path.exists('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/LibriSeVoc'):\n",
        "        detector = DeepFakeDetectorGraphsAndStats(directory='/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/LibriSeVoc', file_extension='.wav', loss='CrossEntropyLoss', optim='Adam', DL_type='RNN')\n",
        "        detector.set_batch_size(16) # Make it 16 samples per batch\n",
        "        detector.set_learning_rate(0.001) # Set learning rate to 0.001\n",
        "        detector.setup_data_loaders() # Setup data loaders\n",
        "\n",
        "        # detector.train_LSTM(num_epochs=100) # Train for 100 epochs\n",
        "        # detector.save_model('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V15.pth') # Save the trained model\n",
        "\n",
        "        detector.plot_training_curves()\n",
        "        detector.plot_class_counts()\n",
        "        detector.print_optimizer_loss_architecture('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')\n",
        "        detector.evaluate_model('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')\n",
        "        detector.sns_scatter_plot('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')\n",
        "        detector.create_confusion_matrix('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')\n",
        "        detector.create_classification_report('/content/drive/My Drive/CYBR_4980_Project/Dataset_Extracted/LibriSeVoc_extracted/Deep_Fake_Detector_LSTM_V9.pth')\n",
        "    else:\n",
        "        print(\"Dataset directory does not exist.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bb6e82cd7e446d1974a340fe06655d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19c439d07fa743b09bfc48ffb224960a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "372500a941a54048ad32bca0acfff0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19c439d07fa743b09bfc48ffb224960a",
            "placeholder": "​",
            "style": "IPY_MODEL_ba9cef4ebf9648e6aaa96dafa28cccf1",
            "value": "[Testing]:  24%"
          }
        },
        "44be0e478b0c4a77925fbff9324c794e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7807bc768334fa0b6d53e744096bd2f",
            "max": 34,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bb6e82cd7e446d1974a340fe06655d9",
            "value": 8
          }
        },
        "4d6d2ed705c94661891f9907d36d199a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fc8b0ac423d45329bb789eaeac3296e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fdf4d0614844da4aa76f5f9a740a648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_372500a941a54048ad32bca0acfff0af",
              "IPY_MODEL_44be0e478b0c4a77925fbff9324c794e",
              "IPY_MODEL_fc46f8f811a84b8899000a364940dab3"
            ],
            "layout": "IPY_MODEL_e3615020852143a1b0b438179510e6a2"
          }
        },
        "ba9cef4ebf9648e6aaa96dafa28cccf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7807bc768334fa0b6d53e744096bd2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3615020852143a1b0b438179510e6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc46f8f811a84b8899000a364940dab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d6d2ed705c94661891f9907d36d199a",
            "placeholder": "​",
            "style": "IPY_MODEL_5fc8b0ac423d45329bb789eaeac3296e",
            "value": " 8/34 [01:39&lt;05:24, 12.47s/it, test_loss=0.4565]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
